{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discrete Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrete Uniform Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package scipy.stats in scipy:\n",
      "\n",
      "NAME\n",
      "    scipy.stats - .. _statsrefmanual:\n",
      "\n",
      "DESCRIPTION\n",
      "    ==========================================\n",
      "    Statistical functions (:mod:`scipy.stats`)\n",
      "    ==========================================\n",
      "    \n",
      "    .. currentmodule:: scipy.stats\n",
      "    \n",
      "    This module contains a large number of probability distributions as\n",
      "    well as a growing library of statistical functions.\n",
      "    \n",
      "    Each univariate distribution is an instance of a subclass of `rv_continuous`\n",
      "    (`rv_discrete` for discrete distributions):\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       rv_continuous\n",
      "       rv_discrete\n",
      "       rv_histogram\n",
      "    \n",
      "    Continuous distributions\n",
      "    ========================\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       alpha             -- Alpha\n",
      "       anglit            -- Anglit\n",
      "       arcsine           -- Arcsine\n",
      "       argus             -- Argus\n",
      "       beta              -- Beta\n",
      "       betaprime         -- Beta Prime\n",
      "       bradford          -- Bradford\n",
      "       burr              -- Burr (Type III)\n",
      "       burr12            -- Burr (Type XII)\n",
      "       cauchy            -- Cauchy\n",
      "       chi               -- Chi\n",
      "       chi2              -- Chi-squared\n",
      "       cosine            -- Cosine\n",
      "       crystalball       -- Crystalball\n",
      "       dgamma            -- Double Gamma\n",
      "       dweibull          -- Double Weibull\n",
      "       erlang            -- Erlang\n",
      "       expon             -- Exponential\n",
      "       exponnorm         -- Exponentially Modified Normal\n",
      "       exponweib         -- Exponentiated Weibull\n",
      "       exponpow          -- Exponential Power\n",
      "       f                 -- F (Snecdor F)\n",
      "       fatiguelife       -- Fatigue Life (Birnbaum-Saunders)\n",
      "       fisk              -- Fisk\n",
      "       foldcauchy        -- Folded Cauchy\n",
      "       foldnorm          -- Folded Normal\n",
      "       frechet_r         -- Deprecated. Alias for weibull_min\n",
      "       frechet_l         -- Deprecated. Alias for weibull_max\n",
      "       genlogistic       -- Generalized Logistic\n",
      "       gennorm           -- Generalized normal\n",
      "       genpareto         -- Generalized Pareto\n",
      "       genexpon          -- Generalized Exponential\n",
      "       genextreme        -- Generalized Extreme Value\n",
      "       gausshyper        -- Gauss Hypergeometric\n",
      "       gamma             -- Gamma\n",
      "       gengamma          -- Generalized gamma\n",
      "       genhalflogistic   -- Generalized Half Logistic\n",
      "       geninvgauss       -- Generalized Inverse Gaussian\n",
      "       gilbrat           -- Gilbrat\n",
      "       gompertz          -- Gompertz (Truncated Gumbel)\n",
      "       gumbel_r          -- Right Sided Gumbel, Log-Weibull, Fisher-Tippett, Extreme Value Type I\n",
      "       gumbel_l          -- Left Sided Gumbel, etc.\n",
      "       halfcauchy        -- Half Cauchy\n",
      "       halflogistic      -- Half Logistic\n",
      "       halfnorm          -- Half Normal\n",
      "       halfgennorm       -- Generalized Half Normal\n",
      "       hypsecant         -- Hyperbolic Secant\n",
      "       invgamma          -- Inverse Gamma\n",
      "       invgauss          -- Inverse Gaussian\n",
      "       invweibull        -- Inverse Weibull\n",
      "       johnsonsb         -- Johnson SB\n",
      "       johnsonsu         -- Johnson SU\n",
      "       kappa4            -- Kappa 4 parameter\n",
      "       kappa3            -- Kappa 3 parameter\n",
      "       ksone             -- Kolmogorov-Smirnov one-sided (no stats)\n",
      "       kstwobign         -- Kolmogorov-Smirnov two-sided test for Large N (no stats)\n",
      "       laplace           -- Laplace\n",
      "       levy              -- Levy\n",
      "       levy_l\n",
      "       levy_stable\n",
      "       logistic          -- Logistic\n",
      "       loggamma          -- Log-Gamma\n",
      "       loglaplace        -- Log-Laplace (Log Double Exponential)\n",
      "       lognorm           -- Log-Normal\n",
      "       loguniform        -- Log-Uniform\n",
      "       lomax             -- Lomax (Pareto of the second kind)\n",
      "       maxwell           -- Maxwell\n",
      "       mielke            -- Mielke's Beta-Kappa\n",
      "       moyal             -- Moyal\n",
      "       nakagami          -- Nakagami\n",
      "       ncx2              -- Non-central chi-squared\n",
      "       ncf               -- Non-central F\n",
      "       nct               -- Non-central Student's T\n",
      "       norm              -- Normal (Gaussian)\n",
      "       norminvgauss      -- Normal Inverse Gaussian\n",
      "       pareto            -- Pareto\n",
      "       pearson3          -- Pearson type III\n",
      "       powerlaw          -- Power-function\n",
      "       powerlognorm      -- Power log normal\n",
      "       powernorm         -- Power normal\n",
      "       rdist             -- R-distribution\n",
      "       rayleigh          -- Rayleigh\n",
      "       rice              -- Rice\n",
      "       recipinvgauss     -- Reciprocal Inverse Gaussian\n",
      "       semicircular      -- Semicircular\n",
      "       skewnorm          -- Skew normal\n",
      "       t                 -- Student's T\n",
      "       trapz             -- Trapezoidal\n",
      "       triang            -- Triangular\n",
      "       truncexpon        -- Truncated Exponential\n",
      "       truncnorm         -- Truncated Normal\n",
      "       tukeylambda       -- Tukey-Lambda\n",
      "       uniform           -- Uniform\n",
      "       vonmises          -- Von-Mises (Circular)\n",
      "       vonmises_line     -- Von-Mises (Line)\n",
      "       wald              -- Wald\n",
      "       weibull_min       -- Minimum Weibull (see Frechet)\n",
      "       weibull_max       -- Maximum Weibull (see Frechet)\n",
      "       wrapcauchy        -- Wrapped Cauchy\n",
      "    \n",
      "    Multivariate distributions\n",
      "    ==========================\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       multivariate_normal   -- Multivariate normal distribution\n",
      "       matrix_normal         -- Matrix normal distribution\n",
      "       dirichlet             -- Dirichlet\n",
      "       wishart               -- Wishart\n",
      "       invwishart            -- Inverse Wishart\n",
      "       multinomial           -- Multinomial distribution\n",
      "       special_ortho_group   -- SO(N) group\n",
      "       ortho_group           -- O(N) group\n",
      "       unitary_group         -- U(N) group\n",
      "       random_correlation    -- random correlation matrices\n",
      "    \n",
      "    Discrete distributions\n",
      "    ======================\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       bernoulli         -- Bernoulli\n",
      "       betabinom         -- Beta-Binomial\n",
      "       binom             -- Binomial\n",
      "       boltzmann         -- Boltzmann (Truncated Discrete Exponential)\n",
      "       dlaplace          -- Discrete Laplacian\n",
      "       geom              -- Geometric\n",
      "       hypergeom         -- Hypergeometric\n",
      "       logser            -- Logarithmic (Log-Series, Series)\n",
      "       nbinom            -- Negative Binomial\n",
      "       planck            -- Planck (Discrete Exponential)\n",
      "       poisson           -- Poisson\n",
      "       randint           -- Discrete Uniform\n",
      "       skellam           -- Skellam\n",
      "       zipf              -- Zipf\n",
      "       yulesimon         -- Yule-Simon\n",
      "    \n",
      "    An overview of statistical functions is given below.\n",
      "    Several of these functions have a similar version in\n",
      "    `scipy.stats.mstats` which work for masked arrays.\n",
      "    \n",
      "    Summary statistics\n",
      "    ==================\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       describe          -- Descriptive statistics\n",
      "       gmean             -- Geometric mean\n",
      "       hmean             -- Harmonic mean\n",
      "       kurtosis          -- Fisher or Pearson kurtosis\n",
      "       mode              -- Modal value\n",
      "       moment            -- Central moment\n",
      "       skew              -- Skewness\n",
      "       kstat             --\n",
      "       kstatvar          --\n",
      "       tmean             -- Truncated arithmetic mean\n",
      "       tvar              -- Truncated variance\n",
      "       tmin              --\n",
      "       tmax              --\n",
      "       tstd              --\n",
      "       tsem              --\n",
      "       variation         -- Coefficient of variation\n",
      "       find_repeats\n",
      "       trim_mean\n",
      "       gstd              -- Geometric Standard Deviation\n",
      "       iqr\n",
      "       sem\n",
      "       bayes_mvs\n",
      "       mvsdist\n",
      "       entropy\n",
      "       median_absolute_deviation\n",
      "    \n",
      "    Frequency statistics\n",
      "    ====================\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       cumfreq\n",
      "       itemfreq\n",
      "       percentileofscore\n",
      "       scoreatpercentile\n",
      "       relfreq\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       binned_statistic     -- Compute a binned statistic for a set of data.\n",
      "       binned_statistic_2d  -- Compute a 2-D binned statistic for a set of data.\n",
      "       binned_statistic_dd  -- Compute a d-D binned statistic for a set of data.\n",
      "    \n",
      "    Correlation functions\n",
      "    =====================\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       f_oneway\n",
      "       pearsonr\n",
      "       spearmanr\n",
      "       pointbiserialr\n",
      "       kendalltau\n",
      "       weightedtau\n",
      "       linregress\n",
      "       siegelslopes\n",
      "       theilslopes\n",
      "       multiscale_graphcorr\n",
      "    \n",
      "    Statistical tests\n",
      "    =================\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       ttest_1samp\n",
      "       ttest_ind\n",
      "       ttest_ind_from_stats\n",
      "       ttest_rel\n",
      "       kstest\n",
      "       chisquare\n",
      "       power_divergence\n",
      "       ks_2samp\n",
      "       epps_singleton_2samp\n",
      "       mannwhitneyu\n",
      "       tiecorrect\n",
      "       rankdata\n",
      "       ranksums\n",
      "       wilcoxon\n",
      "       kruskal\n",
      "       friedmanchisquare\n",
      "       brunnermunzel\n",
      "       combine_pvalues\n",
      "       jarque_bera\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       ansari\n",
      "       bartlett\n",
      "       levene\n",
      "       shapiro\n",
      "       anderson\n",
      "       anderson_ksamp\n",
      "       binom_test\n",
      "       fligner\n",
      "       median_test\n",
      "       mood\n",
      "       skewtest\n",
      "       kurtosistest\n",
      "       normaltest\n",
      "    \n",
      "    Transformations\n",
      "    ===============\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       boxcox\n",
      "       boxcox_normmax\n",
      "       boxcox_llf\n",
      "       yeojohnson\n",
      "       yeojohnson_normmax\n",
      "       yeojohnson_llf\n",
      "       obrientransform\n",
      "       sigmaclip\n",
      "       trimboth\n",
      "       trim1\n",
      "       zmap\n",
      "       zscore\n",
      "    \n",
      "    Statistical distances\n",
      "    =====================\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       wasserstein_distance\n",
      "       energy_distance\n",
      "    \n",
      "    Random variate generation\n",
      "    =========================\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       rvs_ratio_uniforms\n",
      "    \n",
      "    Circular statistical functions\n",
      "    ==============================\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       circmean\n",
      "       circvar\n",
      "       circstd\n",
      "    \n",
      "    Contingency table functions\n",
      "    ===========================\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       chi2_contingency\n",
      "       contingency.expected_freq\n",
      "       contingency.margins\n",
      "       fisher_exact\n",
      "    \n",
      "    Plot-tests\n",
      "    ==========\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       ppcc_max\n",
      "       ppcc_plot\n",
      "       probplot\n",
      "       boxcox_normplot\n",
      "       yeojohnson_normplot\n",
      "    \n",
      "    \n",
      "    Masked statistics functions\n",
      "    ===========================\n",
      "    \n",
      "    .. toctree::\n",
      "    \n",
      "       stats.mstats\n",
      "    \n",
      "    \n",
      "    Univariate and multivariate kernel density estimation\n",
      "    =====================================================\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       gaussian_kde\n",
      "    \n",
      "    Warnings used in :mod:`scipy.stats`\n",
      "    ===================================\n",
      "    \n",
      "    .. autosummary::\n",
      "       :toctree: generated/\n",
      "    \n",
      "       PearsonRConstantInputWarning\n",
      "       PearsonRNearConstantInputWarning\n",
      "    \n",
      "    For many more stat related functions install the software R and the\n",
      "    interface package rpy.\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _binned_statistic\n",
      "    _constants\n",
      "    _continuous_distns\n",
      "    _discrete_distns\n",
      "    _distn_infrastructure\n",
      "    _distr_params\n",
      "    _hypotests\n",
      "    _multivariate\n",
      "    _rvs_sampling\n",
      "    _stats\n",
      "    _stats_mstats_common\n",
      "    _tukeylambda_stats\n",
      "    contingency\n",
      "    distributions\n",
      "    kde\n",
      "    morestats\n",
      "    mstats\n",
      "    mstats_basic\n",
      "    mstats_extras\n",
      "    mvn\n",
      "    setup\n",
      "    statlib\n",
      "    stats\n",
      "    tests (package)\n",
      "    vonmises\n",
      "\n",
      "CLASSES\n",
      "    builtins.RuntimeWarning(builtins.Warning)\n",
      "        scipy.stats.stats.PearsonRConstantInputWarning\n",
      "        scipy.stats.stats.PearsonRNearConstantInputWarning\n",
      "    builtins.object\n",
      "        scipy.stats.kde.gaussian_kde\n",
      "    scipy.stats._distn_infrastructure.rv_generic(builtins.object)\n",
      "        scipy.stats._distn_infrastructure.rv_continuous\n",
      "            scipy.stats._continuous_distns.rv_histogram\n",
      "        scipy.stats._distn_infrastructure.rv_discrete\n",
      "    \n",
      "    class PearsonRConstantInputWarning(builtins.RuntimeWarning)\n",
      "     |  PearsonRConstantInputWarning(msg=None)\n",
      "     |  \n",
      "     |  Warning generated by `pearsonr` when an input is constant.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PearsonRConstantInputWarning\n",
      "     |      builtins.RuntimeWarning\n",
      "     |      builtins.Warning\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, msg=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.RuntimeWarning:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class PearsonRNearConstantInputWarning(builtins.RuntimeWarning)\n",
      "     |  PearsonRNearConstantInputWarning(msg=None)\n",
      "     |  \n",
      "     |  Warning generated by `pearsonr` when an input is nearly constant.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PearsonRNearConstantInputWarning\n",
      "     |      builtins.RuntimeWarning\n",
      "     |      builtins.Warning\n",
      "     |      builtins.Exception\n",
      "     |      builtins.BaseException\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, msg=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods inherited from builtins.RuntimeWarning:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __delattr__(self, name, /)\n",
      "     |      Implement delattr(self, name).\n",
      "     |  \n",
      "     |  __getattribute__(self, name, /)\n",
      "     |      Return getattr(self, name).\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setattr__(self, name, value, /)\n",
      "     |      Implement setattr(self, name, value).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  with_traceback(...)\n",
      "     |      Exception.with_traceback(tb) --\n",
      "     |      set self.__traceback__ to tb and return self.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from builtins.BaseException:\n",
      "     |  \n",
      "     |  __cause__\n",
      "     |      exception cause\n",
      "     |  \n",
      "     |  __context__\n",
      "     |      exception context\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |  \n",
      "     |  __suppress_context__\n",
      "     |  \n",
      "     |  __traceback__\n",
      "     |  \n",
      "     |  args\n",
      "    \n",
      "    class gaussian_kde(builtins.object)\n",
      "     |  gaussian_kde(dataset, bw_method=None, weights=None)\n",
      "     |  \n",
      "     |  Representation of a kernel-density estimate using Gaussian kernels.\n",
      "     |  \n",
      "     |  Kernel density estimation is a way to estimate the probability density\n",
      "     |  function (PDF) of a random variable in a non-parametric way.\n",
      "     |  `gaussian_kde` works for both uni-variate and multi-variate data.   It\n",
      "     |  includes automatic bandwidth determination.  The estimation works best for\n",
      "     |  a unimodal distribution; bimodal or multi-modal distributions tend to be\n",
      "     |  oversmoothed.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  dataset : array_like\n",
      "     |      Datapoints to estimate from. In case of univariate data this is a 1-D\n",
      "     |      array, otherwise a 2-D array with shape (# of dims, # of data).\n",
      "     |  bw_method : str, scalar or callable, optional\n",
      "     |      The method used to calculate the estimator bandwidth.  This can be\n",
      "     |      'scott', 'silverman', a scalar constant or a callable.  If a scalar,\n",
      "     |      this will be used directly as `kde.factor`.  If a callable, it should\n",
      "     |      take a `gaussian_kde` instance as only parameter and return a scalar.\n",
      "     |      If None (default), 'scott' is used.  See Notes for more details.\n",
      "     |  weights : array_like, optional\n",
      "     |      weights of datapoints. This must be the same shape as dataset.\n",
      "     |      If None (default), the samples are assumed to be equally weighted\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  dataset : ndarray\n",
      "     |      The dataset with which `gaussian_kde` was initialized.\n",
      "     |  d : int\n",
      "     |      Number of dimensions.\n",
      "     |  n : int\n",
      "     |      Number of datapoints.\n",
      "     |  neff : int\n",
      "     |      Effective number of datapoints.\n",
      "     |  \n",
      "     |      .. versionadded:: 1.2.0\n",
      "     |  factor : float\n",
      "     |      The bandwidth factor, obtained from `kde.covariance_factor`, with which\n",
      "     |      the covariance matrix is multiplied.\n",
      "     |  covariance : ndarray\n",
      "     |      The covariance matrix of `dataset`, scaled by the calculated bandwidth\n",
      "     |      (`kde.factor`).\n",
      "     |  inv_cov : ndarray\n",
      "     |      The inverse of `covariance`.\n",
      "     |  \n",
      "     |  Methods\n",
      "     |  -------\n",
      "     |  evaluate\n",
      "     |  __call__\n",
      "     |  integrate_gaussian\n",
      "     |  integrate_box_1d\n",
      "     |  integrate_box\n",
      "     |  integrate_kde\n",
      "     |  pdf\n",
      "     |  logpdf\n",
      "     |  resample\n",
      "     |  set_bandwidth\n",
      "     |  covariance_factor\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Bandwidth selection strongly influences the estimate obtained from the KDE\n",
      "     |  (much more so than the actual shape of the kernel).  Bandwidth selection\n",
      "     |  can be done by a \"rule of thumb\", by cross-validation, by \"plug-in\n",
      "     |  methods\" or by other means; see [3]_, [4]_ for reviews.  `gaussian_kde`\n",
      "     |  uses a rule of thumb, the default is Scott's Rule.\n",
      "     |  \n",
      "     |  Scott's Rule [1]_, implemented as `scotts_factor`, is::\n",
      "     |  \n",
      "     |      n**(-1./(d+4)),\n",
      "     |  \n",
      "     |  with ``n`` the number of data points and ``d`` the number of dimensions.\n",
      "     |  In the case of unequally weighted points, `scotts_factor` becomes::\n",
      "     |  \n",
      "     |      neff**(-1./(d+4)),\n",
      "     |  \n",
      "     |  with ``neff`` the effective number of datapoints.\n",
      "     |  Silverman's Rule [2]_, implemented as `silverman_factor`, is::\n",
      "     |  \n",
      "     |      (n * (d + 2) / 4.)**(-1. / (d + 4)).\n",
      "     |  \n",
      "     |  or in the case of unequally weighted points::\n",
      "     |  \n",
      "     |      (neff * (d + 2) / 4.)**(-1. / (d + 4)).\n",
      "     |  \n",
      "     |  Good general descriptions of kernel density estimation can be found in [1]_\n",
      "     |  and [2]_, the mathematics for this multi-dimensional implementation can be\n",
      "     |  found in [1]_.\n",
      "     |  \n",
      "     |  With a set of weighted samples, the effective number of datapoints ``neff``\n",
      "     |  is defined by::\n",
      "     |  \n",
      "     |      neff = sum(weights)^2 / sum(weights^2)\n",
      "     |  \n",
      "     |  as detailed in [5]_.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [1] D.W. Scott, \"Multivariate Density Estimation: Theory, Practice, and\n",
      "     |         Visualization\", John Wiley & Sons, New York, Chicester, 1992.\n",
      "     |  .. [2] B.W. Silverman, \"Density Estimation for Statistics and Data\n",
      "     |         Analysis\", Vol. 26, Monographs on Statistics and Applied Probability,\n",
      "     |         Chapman and Hall, London, 1986.\n",
      "     |  .. [3] B.A. Turlach, \"Bandwidth Selection in Kernel Density Estimation: A\n",
      "     |         Review\", CORE and Institut de Statistique, Vol. 19, pp. 1-33, 1993.\n",
      "     |  .. [4] D.M. Bashtannyk and R.J. Hyndman, \"Bandwidth selection for kernel\n",
      "     |         conditional density estimation\", Computational Statistics & Data\n",
      "     |         Analysis, Vol. 36, pp. 279-298, 2001.\n",
      "     |  .. [5] Gray P. G., 1969, Journal of the Royal Statistical Society.\n",
      "     |         Series A (General), 132, 272\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  Generate some random two-dimensional data:\n",
      "     |  \n",
      "     |  >>> from scipy import stats\n",
      "     |  >>> def measure(n):\n",
      "     |  ...     \"Measurement model, return two coupled measurements.\"\n",
      "     |  ...     m1 = np.random.normal(size=n)\n",
      "     |  ...     m2 = np.random.normal(scale=0.5, size=n)\n",
      "     |  ...     return m1+m2, m1-m2\n",
      "     |  \n",
      "     |  >>> m1, m2 = measure(2000)\n",
      "     |  >>> xmin = m1.min()\n",
      "     |  >>> xmax = m1.max()\n",
      "     |  >>> ymin = m2.min()\n",
      "     |  >>> ymax = m2.max()\n",
      "     |  \n",
      "     |  Perform a kernel density estimate on the data:\n",
      "     |  \n",
      "     |  >>> X, Y = np.mgrid[xmin:xmax:100j, ymin:ymax:100j]\n",
      "     |  >>> positions = np.vstack([X.ravel(), Y.ravel()])\n",
      "     |  >>> values = np.vstack([m1, m2])\n",
      "     |  >>> kernel = stats.gaussian_kde(values)\n",
      "     |  >>> Z = np.reshape(kernel(positions).T, X.shape)\n",
      "     |  \n",
      "     |  Plot the results:\n",
      "     |  \n",
      "     |  >>> import matplotlib.pyplot as plt\n",
      "     |  >>> fig, ax = plt.subplots()\n",
      "     |  >>> ax.imshow(np.rot90(Z), cmap=plt.cm.gist_earth_r,\n",
      "     |  ...           extent=[xmin, xmax, ymin, ymax])\n",
      "     |  >>> ax.plot(m1, m2, 'k.', markersize=2)\n",
      "     |  >>> ax.set_xlim([xmin, xmax])\n",
      "     |  >>> ax.set_ylim([ymin, ymax])\n",
      "     |  >>> plt.show()\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__ = evaluate(self, points)\n",
      "     |  \n",
      "     |  __init__(self, dataset, bw_method=None, weights=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  covariance_factor = scotts_factor(self)\n",
      "     |  \n",
      "     |  evaluate(self, points)\n",
      "     |      Evaluate the estimated pdf on a set of points.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      points : (# of dimensions, # of points)-array\n",
      "     |          Alternatively, a (# of dimensions,) vector can be passed in and\n",
      "     |          treated as a single point.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      values : (# of points,)-array\n",
      "     |          The values at each point.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError : if the dimensionality of the input points is different than\n",
      "     |                   the dimensionality of the KDE.\n",
      "     |  \n",
      "     |  integrate_box(self, low_bounds, high_bounds, maxpts=None)\n",
      "     |      Computes the integral of a pdf over a rectangular interval.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      low_bounds : array_like\n",
      "     |          A 1-D array containing the lower bounds of integration.\n",
      "     |      high_bounds : array_like\n",
      "     |          A 1-D array containing the upper bounds of integration.\n",
      "     |      maxpts : int, optional\n",
      "     |          The maximum number of points to use for integration.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value : scalar\n",
      "     |          The result of the integral.\n",
      "     |  \n",
      "     |  integrate_box_1d(self, low, high)\n",
      "     |      Computes the integral of a 1D pdf between two bounds.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      low : scalar\n",
      "     |          Lower bound of integration.\n",
      "     |      high : scalar\n",
      "     |          Upper bound of integration.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value : scalar\n",
      "     |          The result of the integral.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If the KDE is over more than one dimension.\n",
      "     |  \n",
      "     |  integrate_gaussian(self, mean, cov)\n",
      "     |      Multiply estimated density by a multivariate Gaussian and integrate\n",
      "     |      over the whole space.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mean : aray_like\n",
      "     |          A 1-D array, specifying the mean of the Gaussian.\n",
      "     |      cov : array_like\n",
      "     |          A 2-D array, specifying the covariance matrix of the Gaussian.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      result : scalar\n",
      "     |          The value of the integral.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If the mean or covariance of the input Gaussian differs from\n",
      "     |          the KDE's dimensionality.\n",
      "     |  \n",
      "     |  integrate_kde(self, other)\n",
      "     |      Computes the integral of the product of this  kernel density estimate\n",
      "     |      with another.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      other : gaussian_kde instance\n",
      "     |          The other kde.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      value : scalar\n",
      "     |          The result of the integral.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If the KDEs have different dimensionality.\n",
      "     |  \n",
      "     |  logpdf(self, x)\n",
      "     |      Evaluate the log of the estimated pdf on a provided set of points.\n",
      "     |  \n",
      "     |  pdf(self, x)\n",
      "     |      Evaluate the estimated pdf on a provided set of points.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is an alias for `gaussian_kde.evaluate`.  See the ``evaluate``\n",
      "     |      docstring for more details.\n",
      "     |  \n",
      "     |  resample(self, size=None, seed=None)\n",
      "     |      Randomly sample a dataset from the estimated pdf.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      size : int, optional\n",
      "     |          The number of samples to draw.  If not provided, then the size is\n",
      "     |          the same as the effective number of samples in the underlying\n",
      "     |          dataset.\n",
      "     |      seed : None or int or `np.random.RandomState`, optional\n",
      "     |          If `seed` is None, random variates are drawn by the RandomState\n",
      "     |          singleton used by np.random.\n",
      "     |          If `seed` is an int, a new `np.random.RandomState` instance is used,\n",
      "     |          seeded with seed.\n",
      "     |          If `seed` is already a `np.random.RandomState instance`, then that\n",
      "     |          `np.random.RandomState` instance is used.\n",
      "     |          Specify `seed` for reproducible drawing of random variates.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      resample : (self.d, `size`) ndarray\n",
      "     |          The sampled dataset.\n",
      "     |  \n",
      "     |  scotts_factor(self)\n",
      "     |      Computes the coefficient (`kde.factor`) that\n",
      "     |      multiplies the data covariance matrix to obtain the kernel covariance\n",
      "     |      matrix. The default is `scotts_factor`.  A subclass can overwrite this\n",
      "     |      method to provide a different method, or set it through a call to\n",
      "     |      `kde.set_bandwidth`.\n",
      "     |  \n",
      "     |  set_bandwidth(self, bw_method=None)\n",
      "     |      Compute the estimator bandwidth with given method.\n",
      "     |      \n",
      "     |      The new bandwidth calculated after a call to `set_bandwidth` is used\n",
      "     |      for subsequent evaluations of the estimated density.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      bw_method : str, scalar or callable, optional\n",
      "     |          The method used to calculate the estimator bandwidth.  This can be\n",
      "     |          'scott', 'silverman', a scalar constant or a callable.  If a\n",
      "     |          scalar, this will be used directly as `kde.factor`.  If a callable,\n",
      "     |          it should take a `gaussian_kde` instance as only parameter and\n",
      "     |          return a scalar.  If None (default), nothing happens; the current\n",
      "     |          `kde.covariance_factor` method is kept.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      .. versionadded:: 0.11\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> import scipy.stats as stats\n",
      "     |      >>> x1 = np.array([-7, -5, 1, 4, 5.])\n",
      "     |      >>> kde = stats.gaussian_kde(x1)\n",
      "     |      >>> xs = np.linspace(-10, 10, num=50)\n",
      "     |      >>> y1 = kde(xs)\n",
      "     |      >>> kde.set_bandwidth(bw_method='silverman')\n",
      "     |      >>> y2 = kde(xs)\n",
      "     |      >>> kde.set_bandwidth(bw_method=kde.factor / 3.)\n",
      "     |      >>> y3 = kde(xs)\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> fig, ax = plt.subplots()\n",
      "     |      >>> ax.plot(x1, np.full(x1.shape, 1 / (4. * x1.size)), 'bo',\n",
      "     |      ...         label='Data points (rescaled)')\n",
      "     |      >>> ax.plot(xs, y1, label='Scott (default)')\n",
      "     |      >>> ax.plot(xs, y2, label='Silverman')\n",
      "     |      >>> ax.plot(xs, y3, label='Const (1/3 * Silverman)')\n",
      "     |      >>> ax.legend()\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  silverman_factor(self)\n",
      "     |      Compute the Silverman factor.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      s : float\n",
      "     |          The silverman factor.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  neff\n",
      "     |  \n",
      "     |  weights\n",
      "    \n",
      "    class rv_continuous(rv_generic)\n",
      "     |  rv_continuous(momtype=1, a=None, b=None, xtol=1e-14, badvalue=None, name=None, longname=None, shapes=None, extradoc=None, seed=None)\n",
      "     |  \n",
      "     |  A generic continuous random variable class meant for subclassing.\n",
      "     |  \n",
      "     |  `rv_continuous` is a base class to construct specific distribution classes\n",
      "     |  and instances for continuous random variables. It cannot be used\n",
      "     |  directly as a distribution.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  momtype : int, optional\n",
      "     |      The type of generic moment calculation to use: 0 for pdf, 1 (default)\n",
      "     |      for ppf.\n",
      "     |  a : float, optional\n",
      "     |      Lower bound of the support of the distribution, default is minus\n",
      "     |      infinity.\n",
      "     |  b : float, optional\n",
      "     |      Upper bound of the support of the distribution, default is plus\n",
      "     |      infinity.\n",
      "     |  xtol : float, optional\n",
      "     |      The tolerance for fixed point calculation for generic ppf.\n",
      "     |  badvalue : float, optional\n",
      "     |      The value in a result arrays that indicates a value that for which\n",
      "     |      some argument restriction is violated, default is np.nan.\n",
      "     |  name : str, optional\n",
      "     |      The name of the instance. This string is used to construct the default\n",
      "     |      example for distributions.\n",
      "     |  longname : str, optional\n",
      "     |      This string is used as part of the first line of the docstring returned\n",
      "     |      when a subclass has no docstring of its own. Note: `longname` exists\n",
      "     |      for backwards compatibility, do not use for new subclasses.\n",
      "     |  shapes : str, optional\n",
      "     |      The shape of the distribution. For example ``\"m, n\"`` for a\n",
      "     |      distribution that takes two integers as the two shape arguments for all\n",
      "     |      its methods. If not provided, shape parameters will be inferred from\n",
      "     |      the signature of the private methods, ``_pdf`` and ``_cdf`` of the\n",
      "     |      instance.\n",
      "     |  extradoc :  str, optional, deprecated\n",
      "     |      This string is used as the last part of the docstring returned when a\n",
      "     |      subclass has no docstring of its own. Note: `extradoc` exists for\n",
      "     |      backwards compatibility, do not use for new subclasses.\n",
      "     |  seed : None or int or ``numpy.random.RandomState`` instance, optional\n",
      "     |      This parameter defines the RandomState object to use for drawing\n",
      "     |      random variates.\n",
      "     |      If None (or np.random), the global np.random state is used.\n",
      "     |      If integer, it is used to seed the local RandomState instance.\n",
      "     |      Default is None.\n",
      "     |  \n",
      "     |  Methods\n",
      "     |  -------\n",
      "     |  rvs\n",
      "     |  pdf\n",
      "     |  logpdf\n",
      "     |  cdf\n",
      "     |  logcdf\n",
      "     |  sf\n",
      "     |  logsf\n",
      "     |  ppf\n",
      "     |  isf\n",
      "     |  moment\n",
      "     |  stats\n",
      "     |  entropy\n",
      "     |  expect\n",
      "     |  median\n",
      "     |  mean\n",
      "     |  std\n",
      "     |  var\n",
      "     |  interval\n",
      "     |  __call__\n",
      "     |  fit\n",
      "     |  fit_loc_scale\n",
      "     |  nnlf\n",
      "     |  support\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Public methods of an instance of a distribution class (e.g., ``pdf``,\n",
      "     |  ``cdf``) check their arguments and pass valid arguments to private,\n",
      "     |  computational methods (``_pdf``, ``_cdf``). For ``pdf(x)``, ``x`` is valid\n",
      "     |  if it is within the support of the distribution.\n",
      "     |  Whether a shape parameter is valid is decided by an ``_argcheck`` method\n",
      "     |  (which defaults to checking that its arguments are strictly positive.)\n",
      "     |  \n",
      "     |  **Subclassing**\n",
      "     |  \n",
      "     |  New random variables can be defined by subclassing the `rv_continuous` class\n",
      "     |  and re-defining at least the ``_pdf`` or the ``_cdf`` method (normalized\n",
      "     |  to location 0 and scale 1).\n",
      "     |  \n",
      "     |  If positive argument checking is not correct for your RV\n",
      "     |  then you will also need to re-define the ``_argcheck`` method.\n",
      "     |  \n",
      "     |  For most of the scipy.stats distributions, the support interval doesn't\n",
      "     |  depend on the shape parameters. ``x`` being in the support interval is\n",
      "     |  equivalent to ``self.a <= x <= self.b``.  If either of the endpoints of\n",
      "     |  the support do depend on the shape parameters, then\n",
      "     |  i) the distribution must implement the ``_get_support`` method; and\n",
      "     |  ii) those dependent endpoints must be omitted from the distribution's\n",
      "     |  call to the ``rv_continuous`` initializer.\n",
      "     |  \n",
      "     |  Correct, but potentially slow defaults exist for the remaining\n",
      "     |  methods but for speed and/or accuracy you can over-ride::\n",
      "     |  \n",
      "     |    _logpdf, _cdf, _logcdf, _ppf, _rvs, _isf, _sf, _logsf\n",
      "     |  \n",
      "     |  The default method ``_rvs`` relies on the inverse of the cdf, ``_ppf``,\n",
      "     |  applied to a uniform random variate. In order to generate random variates\n",
      "     |  efficiently, either the default ``_ppf`` needs to be overwritten (e.g.\n",
      "     |  if the inverse cdf can expressed in an explicit form) or a sampling\n",
      "     |  method needs to be implemented in a custom ``_rvs`` method.\n",
      "     |  \n",
      "     |  If possible, you should override ``_isf``, ``_sf`` or ``_logsf``.\n",
      "     |  The main reason would be to improve numerical accuracy: for example,\n",
      "     |  the survival function ``_sf`` is computed as ``1 - _cdf`` which can\n",
      "     |  result in loss of precision if ``_cdf(x)`` is close to one.\n",
      "     |  \n",
      "     |  **Methods that can be overwritten by subclasses**\n",
      "     |  ::\n",
      "     |  \n",
      "     |    _rvs\n",
      "     |    _pdf\n",
      "     |    _cdf\n",
      "     |    _sf\n",
      "     |    _ppf\n",
      "     |    _isf\n",
      "     |    _stats\n",
      "     |    _munp\n",
      "     |    _entropy\n",
      "     |    _argcheck\n",
      "     |    _get_support\n",
      "     |  \n",
      "     |  There are additional (internal and private) generic methods that can\n",
      "     |  be useful for cross-checking and for debugging, but might work in all\n",
      "     |  cases when directly called.\n",
      "     |  \n",
      "     |  A note on ``shapes``: subclasses need not specify them explicitly. In this\n",
      "     |  case, `shapes` will be automatically deduced from the signatures of the\n",
      "     |  overridden methods (`pdf`, `cdf` etc).\n",
      "     |  If, for some reason, you prefer to avoid relying on introspection, you can\n",
      "     |  specify ``shapes`` explicitly as an argument to the instance constructor.\n",
      "     |  \n",
      "     |  \n",
      "     |  **Frozen Distributions**\n",
      "     |  \n",
      "     |  Normally, you must provide shape parameters (and, optionally, location and\n",
      "     |  scale parameters to each call of a method of a distribution.\n",
      "     |  \n",
      "     |  Alternatively, the object may be called (as a function) to fix the shape,\n",
      "     |  location, and scale parameters returning a \"frozen\" continuous RV object:\n",
      "     |  \n",
      "     |  rv = generic(<shape(s)>, loc=0, scale=1)\n",
      "     |      `rv_frozen` object with the same methods but holding the given shape,\n",
      "     |      location, and scale fixed\n",
      "     |  \n",
      "     |  **Statistics**\n",
      "     |  \n",
      "     |  Statistics are computed using numerical integration by default.\n",
      "     |  For speed you can redefine this using ``_stats``:\n",
      "     |  \n",
      "     |   - take shape parameters and return mu, mu2, g1, g2\n",
      "     |   - If you can't compute one of these, return it as None\n",
      "     |   - Can also be defined with a keyword argument ``moments``, which is a\n",
      "     |     string composed of \"m\", \"v\", \"s\", and/or \"k\".\n",
      "     |     Only the components appearing in string should be computed and\n",
      "     |     returned in the order \"m\", \"v\", \"s\", or \"k\"  with missing values\n",
      "     |     returned as None.\n",
      "     |  \n",
      "     |  Alternatively, you can override ``_munp``, which takes ``n`` and shape\n",
      "     |  parameters and returns the n-th non-central moment of the distribution.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  To create a new Gaussian distribution, we would do the following:\n",
      "     |  \n",
      "     |  >>> from scipy.stats import rv_continuous\n",
      "     |  >>> class gaussian_gen(rv_continuous):\n",
      "     |  ...     \"Gaussian distribution\"\n",
      "     |  ...     def _pdf(self, x):\n",
      "     |  ...         return np.exp(-x**2 / 2.) / np.sqrt(2.0 * np.pi)\n",
      "     |  >>> gaussian = gaussian_gen(name='gaussian')\n",
      "     |  \n",
      "     |  ``scipy.stats`` distributions are *instances*, so here we subclass\n",
      "     |  `rv_continuous` and create an instance. With this, we now have\n",
      "     |  a fully functional distribution with all relevant methods automagically\n",
      "     |  generated by the framework.\n",
      "     |  \n",
      "     |  Note that above we defined a standard normal distribution, with zero mean\n",
      "     |  and unit variance. Shifting and scaling of the distribution can be done\n",
      "     |  by using ``loc`` and ``scale`` parameters: ``gaussian.pdf(x, loc, scale)``\n",
      "     |  essentially computes ``y = (x - loc) / scale`` and\n",
      "     |  ``gaussian._pdf(y) / scale``.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      rv_continuous\n",
      "     |      rv_generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, momtype=1, a=None, b=None, xtol=1e-14, badvalue=None, name=None, longname=None, shapes=None, extradoc=None, seed=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  cdf(self, x, *args, **kwds)\n",
      "     |      Cumulative distribution function of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          quantiles\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cdf : ndarray\n",
      "     |          Cumulative distribution function evaluated at `x`\n",
      "     |  \n",
      "     |  expect(self, func=None, args=(), loc=0, scale=1, lb=None, ub=None, conditional=False, **kwds)\n",
      "     |      Calculate expected value of a function with respect to the\n",
      "     |      distribution by numerical integration.\n",
      "     |      \n",
      "     |      The expected value of a function ``f(x)`` with respect to a\n",
      "     |      distribution ``dist`` is defined as::\n",
      "     |      \n",
      "     |                  ub\n",
      "     |          E[f(x)] = Integral(f(x) * dist.pdf(x)),\n",
      "     |                  lb\n",
      "     |      \n",
      "     |      where ``ub`` and ``lb`` are arguments and ``x`` has the ``dist.pdf(x)``\n",
      "     |      distribution. If the bounds ``lb`` and ``ub`` correspond to the\n",
      "     |      support of the distribution, e.g. ``[-inf, inf]`` in the default\n",
      "     |      case, then the integral is the unrestricted expectation of ``f(x)``.\n",
      "     |      Also, the function ``f(x)`` may be defined such that ``f(x)`` is ``0``\n",
      "     |      outside a finite interval in which case the expectation is\n",
      "     |      calculated within the finite range ``[lb, ub]``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable, optional\n",
      "     |          Function for which integral is calculated. Takes only one argument.\n",
      "     |          The default is the identity mapping f(x) = x.\n",
      "     |      args : tuple, optional\n",
      "     |          Shape parameters of the distribution.\n",
      "     |      loc : float, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      scale : float, optional\n",
      "     |          Scale parameter (default=1).\n",
      "     |      lb, ub : scalar, optional\n",
      "     |          Lower and upper bound for integration. Default is set to the\n",
      "     |          support of the distribution.\n",
      "     |      conditional : bool, optional\n",
      "     |          If True, the integral is corrected by the conditional probability\n",
      "     |          of the integration interval.  The return value is the expectation\n",
      "     |          of the function, conditional on being in the given interval.\n",
      "     |          Default is False.\n",
      "     |      \n",
      "     |      Additional keyword arguments are passed to the integration routine.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      expect : float\n",
      "     |          The calculated expected value.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The integration behavior of this function is inherited from\n",
      "     |      `scipy.integrate.quad`. Neither this function nor\n",
      "     |      `scipy.integrate.quad` can verify whether the integral exists or is\n",
      "     |      finite. For example ``cauchy(0).mean()`` returns ``np.nan`` and\n",
      "     |      ``cauchy(0).expect()`` returns ``0.0``.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      To understand the effect of the bounds of integration consider\n",
      "     |      \n",
      "     |      >>> from scipy.stats import expon\n",
      "     |      >>> expon(1).expect(lambda x: 1, lb=0.0, ub=2.0)\n",
      "     |      0.6321205588285578\n",
      "     |      \n",
      "     |      This is close to\n",
      "     |      \n",
      "     |      >>> expon(1).cdf(2.0) - expon(1).cdf(0.0)\n",
      "     |      0.6321205588285577\n",
      "     |      \n",
      "     |      If ``conditional=True``\n",
      "     |      \n",
      "     |      >>> expon(1).expect(lambda x: 1, lb=0.0, ub=2.0, conditional=True)\n",
      "     |      1.0000000000000002\n",
      "     |      \n",
      "     |      The slight deviation from 1 is due to numerical integration.\n",
      "     |  \n",
      "     |  fit(self, data, *args, **kwds)\n",
      "     |      Return MLEs for shape (if applicable), location, and scale\n",
      "     |      parameters from data.\n",
      "     |      \n",
      "     |      MLE stands for Maximum Likelihood Estimate.  Starting estimates for\n",
      "     |      the fit are given by input arguments; for any arguments not provided\n",
      "     |      with starting estimates, ``self._fitstart(data)`` is called to generate\n",
      "     |      such.\n",
      "     |      \n",
      "     |      One can hold some parameters fixed to specific values by passing in\n",
      "     |      keyword arguments ``f0``, ``f1``, ..., ``fn`` (for shape parameters)\n",
      "     |      and ``floc`` and ``fscale`` (for location and scale parameters,\n",
      "     |      respectively).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : array_like\n",
      "     |          Data to use in calculating the MLEs.\n",
      "     |      args : floats, optional\n",
      "     |          Starting value(s) for any shape-characterizing arguments (those not\n",
      "     |          provided will be determined by a call to ``_fitstart(data)``).\n",
      "     |          No default value.\n",
      "     |      kwds : floats, optional\n",
      "     |          Starting values for the location and scale parameters; no default.\n",
      "     |          Special keyword arguments are recognized as holding certain\n",
      "     |          parameters fixed:\n",
      "     |      \n",
      "     |          - f0...fn : hold respective shape parameters fixed.\n",
      "     |            Alternatively, shape parameters to fix can be specified by name.\n",
      "     |            For example, if ``self.shapes == \"a, b\"``, ``fa``and ``fix_a``\n",
      "     |            are equivalent to ``f0``, and ``fb`` and ``fix_b`` are\n",
      "     |            equivalent to ``f1``.\n",
      "     |      \n",
      "     |          - floc : hold location parameter fixed to specified value.\n",
      "     |      \n",
      "     |          - fscale : hold scale parameter fixed to specified value.\n",
      "     |      \n",
      "     |          - optimizer : The optimizer to use.  The optimizer must take ``func``,\n",
      "     |            and starting position as the first two arguments,\n",
      "     |            plus ``args`` (for extra arguments to pass to the\n",
      "     |            function to be optimized) and ``disp=0`` to suppress\n",
      "     |            output as keyword arguments.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      mle_tuple : tuple of floats\n",
      "     |          MLEs for any shape parameters (if applicable), followed by those\n",
      "     |          for location and scale. For most random variables, shape statistics\n",
      "     |          will be returned, but there are exceptions (e.g. ``norm``).\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This fit is computed by maximizing a log-likelihood function, with\n",
      "     |      penalty applied for samples outside of range of the distribution. The\n",
      "     |      returned answer is not guaranteed to be the globally optimal MLE, it\n",
      "     |      may only be locally optimal, or the optimization may fail altogether.\n",
      "     |      If the data contain any of np.nan, np.inf, or -np.inf, the fit routine\n",
      "     |      will throw a RuntimeError.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Generate some data to fit: draw random variates from the `beta`\n",
      "     |      distribution\n",
      "     |      \n",
      "     |      >>> from scipy.stats import beta\n",
      "     |      >>> a, b = 1., 2.\n",
      "     |      >>> x = beta.rvs(a, b, size=1000)\n",
      "     |      \n",
      "     |      Now we can fit all four parameters (``a``, ``b``, ``loc`` and ``scale``):\n",
      "     |      \n",
      "     |      >>> a1, b1, loc1, scale1 = beta.fit(x)\n",
      "     |      \n",
      "     |      We can also use some prior knowledge about the dataset: let's keep\n",
      "     |      ``loc`` and ``scale`` fixed:\n",
      "     |      \n",
      "     |      >>> a1, b1, loc1, scale1 = beta.fit(x, floc=0, fscale=1)\n",
      "     |      >>> loc1, scale1\n",
      "     |      (0, 1)\n",
      "     |      \n",
      "     |      We can also keep shape parameters fixed by using ``f``-keywords. To\n",
      "     |      keep the zero-th shape parameter ``a`` equal 1, use ``f0=1`` or,\n",
      "     |      equivalently, ``fa=1``:\n",
      "     |      \n",
      "     |      >>> a1, b1, loc1, scale1 = beta.fit(x, fa=1, floc=0, fscale=1)\n",
      "     |      >>> a1\n",
      "     |      1\n",
      "     |      \n",
      "     |      Not all distributions return estimates for the shape parameters.\n",
      "     |      ``norm`` for example just returns estimates for location and scale:\n",
      "     |      \n",
      "     |      >>> from scipy.stats import norm\n",
      "     |      >>> x = norm.rvs(a, b, size=1000, random_state=123)\n",
      "     |      >>> loc1, scale1 = norm.fit(x)\n",
      "     |      >>> loc1, scale1\n",
      "     |      (0.92087172783841631, 2.0015750750324668)\n",
      "     |  \n",
      "     |  fit_loc_scale(self, data, *args)\n",
      "     |      Estimate loc and scale parameters from data using 1st and 2nd moments.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : array_like\n",
      "     |          Data to fit.\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Lhat : float\n",
      "     |          Estimated location parameter for the data.\n",
      "     |      Shat : float\n",
      "     |          Estimated scale parameter for the data.\n",
      "     |  \n",
      "     |  isf(self, q, *args, **kwds)\n",
      "     |      Inverse survival function (inverse of `sf`) at q of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      q : array_like\n",
      "     |          upper tail probability\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      x : ndarray or scalar\n",
      "     |          Quantile corresponding to the upper tail probability q.\n",
      "     |  \n",
      "     |  logcdf(self, x, *args, **kwds)\n",
      "     |      Log of the cumulative distribution function at x of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          quantiles\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      logcdf : array_like\n",
      "     |          Log of the cumulative distribution function evaluated at x\n",
      "     |  \n",
      "     |  logpdf(self, x, *args, **kwds)\n",
      "     |      Log of the probability density function at x of the given RV.\n",
      "     |      \n",
      "     |      This uses a more numerically accurate calculation if available.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          quantiles\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      logpdf : array_like\n",
      "     |          Log of the probability density function evaluated at x\n",
      "     |  \n",
      "     |  logsf(self, x, *args, **kwds)\n",
      "     |      Log of the survival function of the given RV.\n",
      "     |      \n",
      "     |      Returns the log of the \"survival function,\" defined as (1 - `cdf`),\n",
      "     |      evaluated at `x`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          quantiles\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      logsf : ndarray\n",
      "     |          Log of the survival function evaluated at `x`.\n",
      "     |  \n",
      "     |  nnlf(self, theta, x)\n",
      "     |      Return negative loglikelihood function.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is ``-sum(log pdf(x, theta), axis=0)`` where `theta` are the\n",
      "     |      parameters (including loc and scale).\n",
      "     |  \n",
      "     |  pdf(self, x, *args, **kwds)\n",
      "     |      Probability density function at x of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          quantiles\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      pdf : ndarray\n",
      "     |          Probability density function evaluated at x\n",
      "     |  \n",
      "     |  ppf(self, q, *args, **kwds)\n",
      "     |      Percent point function (inverse of `cdf`) at q of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      q : array_like\n",
      "     |          lower tail probability\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      x : array_like\n",
      "     |          quantile corresponding to the lower tail probability q.\n",
      "     |  \n",
      "     |  sf(self, x, *args, **kwds)\n",
      "     |      Survival function (1 - `cdf`) at x of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          quantiles\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sf : array_like\n",
      "     |          Survival function evaluated at x\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from rv_generic:\n",
      "     |  \n",
      "     |  __call__(self, *args, **kwds)\n",
      "     |      Freeze the distribution for the given arguments.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution.  Should include all\n",
      "     |          the non-optional arguments, may include ``loc`` and ``scale``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      rv_frozen : rv_frozen instance\n",
      "     |          The frozen distribution.\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  entropy(self, *args, **kwds)\n",
      "     |      Differential entropy of the RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      scale : array_like, optional  (continuous distributions only).\n",
      "     |          Scale parameter (default=1).\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Entropy is defined base `e`:\n",
      "     |      \n",
      "     |      >>> drv = rv_discrete(values=((0, 1), (0.5, 0.5)))\n",
      "     |      >>> np.allclose(drv.entropy(), np.log(2.0))\n",
      "     |      True\n",
      "     |  \n",
      "     |  freeze(self, *args, **kwds)\n",
      "     |      Freeze the distribution for the given arguments.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution.  Should include all\n",
      "     |          the non-optional arguments, may include ``loc`` and ``scale``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      rv_frozen : rv_frozen instance\n",
      "     |          The frozen distribution.\n",
      "     |  \n",
      "     |  interval(self, alpha, *args, **kwds)\n",
      "     |      Confidence interval with equal areas around the median.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      alpha : array_like of float\n",
      "     |          Probability that an rv will be drawn from the returned range.\n",
      "     |          Each value should be in the range [0, 1].\n",
      "     |      arg1, arg2, ... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter, Default is 0.\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter, Default is 1.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a, b : ndarray of float\n",
      "     |          end-points of range that contain ``100 * alpha %`` of the rv's\n",
      "     |          possible values.\n",
      "     |  \n",
      "     |  mean(self, *args, **kwds)\n",
      "     |      Mean of the distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      mean : float\n",
      "     |          the mean of the distribution\n",
      "     |  \n",
      "     |  median(self, *args, **kwds)\n",
      "     |      Median of the distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter, Default is 0.\n",
      "     |      scale : array_like, optional\n",
      "     |          Scale parameter, Default is 1.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      median : float\n",
      "     |          The median of the distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      rv_discrete.ppf\n",
      "     |          Inverse of the CDF\n",
      "     |  \n",
      "     |  moment(self, n, *args, **kwds)\n",
      "     |      n-th order non-central moment of distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int, n >= 1\n",
      "     |          Order of moment.\n",
      "     |      arg1, arg2, arg3,... : float\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |  \n",
      "     |  rvs(self, *args, **kwds)\n",
      "     |      Random variates of given type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      scale : array_like, optional\n",
      "     |          Scale parameter (default=1).\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Defining number of random variates (default is 1).\n",
      "     |      random_state : None or int or ``np.random.RandomState`` instance, optional\n",
      "     |          If int or RandomState, use it for drawing the random variates.\n",
      "     |          If None, rely on ``self.random_state``.\n",
      "     |          Default is None.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      rvs : ndarray or scalar\n",
      "     |          Random variates of given `size`.\n",
      "     |  \n",
      "     |  stats(self, *args, **kwds)\n",
      "     |      Some statistics of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional (continuous RVs only)\n",
      "     |          scale parameter (default=1)\n",
      "     |      moments : str, optional\n",
      "     |          composed of letters ['mvsk'] defining which moments to compute:\n",
      "     |          'm' = mean,\n",
      "     |          'v' = variance,\n",
      "     |          's' = (Fisher's) skew,\n",
      "     |          'k' = (Fisher's) kurtosis.\n",
      "     |          (default is 'mv')\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      stats : sequence\n",
      "     |          of requested moments.\n",
      "     |  \n",
      "     |  std(self, *args, **kwds)\n",
      "     |      Standard deviation of the distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      std : float\n",
      "     |          standard deviation of the distribution\n",
      "     |  \n",
      "     |  support(self, *args, **kwargs)\n",
      "     |      Return the support of the distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, ... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter, Default is 0.\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter, Default is 1.\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a, b : float\n",
      "     |          end-points of the distribution's support.\n",
      "     |  \n",
      "     |  var(self, *args, **kwds)\n",
      "     |      Variance of the distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      var : float\n",
      "     |          the variance of the distribution\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from rv_generic:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  random_state\n",
      "     |      Get or set the RandomState object for generating random variates.\n",
      "     |      \n",
      "     |      This can be either None or an existing RandomState object.\n",
      "     |      \n",
      "     |      If None (or np.random), use the RandomState singleton used by np.random.\n",
      "     |      If already a RandomState instance, use it.\n",
      "     |      If an int, use a new RandomState instance seeded with seed.\n",
      "    \n",
      "    class rv_discrete(rv_generic)\n",
      "     |  rv_discrete(a=0, b=inf, name=None, badvalue=None, moment_tol=1e-08, values=None, inc=1, longname=None, shapes=None, extradoc=None, seed=None)\n",
      "     |  \n",
      "     |  A generic discrete random variable class meant for subclassing.\n",
      "     |  \n",
      "     |  `rv_discrete` is a base class to construct specific distribution classes\n",
      "     |  and instances for discrete random variables. It can also be used\n",
      "     |  to construct an arbitrary distribution defined by a list of support\n",
      "     |  points and corresponding probabilities.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  a : float, optional\n",
      "     |      Lower bound of the support of the distribution, default: 0\n",
      "     |  b : float, optional\n",
      "     |      Upper bound of the support of the distribution, default: plus infinity\n",
      "     |  moment_tol : float, optional\n",
      "     |      The tolerance for the generic calculation of moments.\n",
      "     |  values : tuple of two array_like, optional\n",
      "     |      ``(xk, pk)`` where ``xk`` are integers and ``pk`` are the non-zero\n",
      "     |      probabilities between 0 and 1 with ``sum(pk) = 1``. ``xk``\n",
      "     |      and ``pk`` must have the same shape.\n",
      "     |  inc : integer, optional\n",
      "     |      Increment for the support of the distribution.\n",
      "     |      Default is 1. (other values have not been tested)\n",
      "     |  badvalue : float, optional\n",
      "     |      The value in a result arrays that indicates a value that for which\n",
      "     |      some argument restriction is violated, default is np.nan.\n",
      "     |  name : str, optional\n",
      "     |      The name of the instance. This string is used to construct the default\n",
      "     |      example for distributions.\n",
      "     |  longname : str, optional\n",
      "     |      This string is used as part of the first line of the docstring returned\n",
      "     |      when a subclass has no docstring of its own. Note: `longname` exists\n",
      "     |      for backwards compatibility, do not use for new subclasses.\n",
      "     |  shapes : str, optional\n",
      "     |      The shape of the distribution. For example \"m, n\" for a distribution\n",
      "     |      that takes two integers as the two shape arguments for all its methods\n",
      "     |      If not provided, shape parameters will be inferred from\n",
      "     |      the signatures of the private methods, ``_pmf`` and ``_cdf`` of\n",
      "     |      the instance.\n",
      "     |  extradoc :  str, optional\n",
      "     |      This string is used as the last part of the docstring returned when a\n",
      "     |      subclass has no docstring of its own. Note: `extradoc` exists for\n",
      "     |      backwards compatibility, do not use for new subclasses.\n",
      "     |  seed : None or int or ``numpy.random.RandomState`` instance, optional\n",
      "     |      This parameter defines the RandomState object to use for drawing\n",
      "     |      random variates.\n",
      "     |      If None, the global np.random state is used.\n",
      "     |      If integer, it is used to seed the local RandomState instance.\n",
      "     |      Default is None.\n",
      "     |  \n",
      "     |  Methods\n",
      "     |  -------\n",
      "     |  rvs\n",
      "     |  pmf\n",
      "     |  logpmf\n",
      "     |  cdf\n",
      "     |  logcdf\n",
      "     |  sf\n",
      "     |  logsf\n",
      "     |  ppf\n",
      "     |  isf\n",
      "     |  moment\n",
      "     |  stats\n",
      "     |  entropy\n",
      "     |  expect\n",
      "     |  median\n",
      "     |  mean\n",
      "     |  std\n",
      "     |  var\n",
      "     |  interval\n",
      "     |  __call__\n",
      "     |  support\n",
      "     |  \n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  \n",
      "     |  This class is similar to `rv_continuous`. Whether a shape parameter is\n",
      "     |  valid is decided by an ``_argcheck`` method (which defaults to checking\n",
      "     |  that its arguments are strictly positive.)\n",
      "     |  The main differences are:\n",
      "     |  \n",
      "     |  - the support of the distribution is a set of integers\n",
      "     |  - instead of the probability density function, ``pdf`` (and the\n",
      "     |    corresponding private ``_pdf``), this class defines the\n",
      "     |    *probability mass function*, `pmf` (and the corresponding\n",
      "     |    private ``_pmf``.)\n",
      "     |  - scale parameter is not defined.\n",
      "     |  \n",
      "     |  To create a new discrete distribution, we would do the following:\n",
      "     |  \n",
      "     |  >>> from scipy.stats import rv_discrete\n",
      "     |  >>> class poisson_gen(rv_discrete):\n",
      "     |  ...     \"Poisson distribution\"\n",
      "     |  ...     def _pmf(self, k, mu):\n",
      "     |  ...         return exp(-mu) * mu**k / factorial(k)\n",
      "     |  \n",
      "     |  and create an instance::\n",
      "     |  \n",
      "     |  >>> poisson = poisson_gen(name=\"poisson\")\n",
      "     |  \n",
      "     |  Note that above we defined the Poisson distribution in the standard form.\n",
      "     |  Shifting the distribution can be done by providing the ``loc`` parameter\n",
      "     |  to the methods of the instance. For example, ``poisson.pmf(x, mu, loc)``\n",
      "     |  delegates the work to ``poisson._pmf(x-loc, mu)``.\n",
      "     |  \n",
      "     |  **Discrete distributions from a list of probabilities**\n",
      "     |  \n",
      "     |  Alternatively, you can construct an arbitrary discrete rv defined\n",
      "     |  on a finite set of values ``xk`` with ``Prob{X=xk} = pk`` by using the\n",
      "     |  ``values`` keyword argument to the `rv_discrete` constructor.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  \n",
      "     |  Custom made discrete distribution:\n",
      "     |  \n",
      "     |  >>> from scipy import stats\n",
      "     |  >>> xk = np.arange(7)\n",
      "     |  >>> pk = (0.1, 0.2, 0.3, 0.1, 0.1, 0.0, 0.2)\n",
      "     |  >>> custm = stats.rv_discrete(name='custm', values=(xk, pk))\n",
      "     |  >>>\n",
      "     |  >>> import matplotlib.pyplot as plt\n",
      "     |  >>> fig, ax = plt.subplots(1, 1)\n",
      "     |  >>> ax.plot(xk, custm.pmf(xk), 'ro', ms=12, mec='r')\n",
      "     |  >>> ax.vlines(xk, 0, custm.pmf(xk), colors='r', lw=4)\n",
      "     |  >>> plt.show()\n",
      "     |  \n",
      "     |  Random number generation:\n",
      "     |  \n",
      "     |  >>> R = custm.rvs(size=100)\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      rv_discrete\n",
      "     |      rv_generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, a=0, b=inf, name=None, badvalue=None, moment_tol=1e-08, values=None, inc=1, longname=None, shapes=None, extradoc=None, seed=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  cdf(self, k, *args, **kwds)\n",
      "     |      Cumulative distribution function of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      k : array_like, int\n",
      "     |          Quantiles.\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cdf : ndarray\n",
      "     |          Cumulative distribution function evaluated at `k`.\n",
      "     |  \n",
      "     |  expect(self, func=None, args=(), loc=0, lb=None, ub=None, conditional=False, maxcount=1000, tolerance=1e-10, chunksize=32)\n",
      "     |      Calculate expected value of a function with respect to the distribution\n",
      "     |      for discrete distribution by numerical summation.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable, optional\n",
      "     |          Function for which the expectation value is calculated.\n",
      "     |          Takes only one argument.\n",
      "     |          The default is the identity mapping f(k) = k.\n",
      "     |      args : tuple, optional\n",
      "     |          Shape parameters of the distribution.\n",
      "     |      loc : float, optional\n",
      "     |          Location parameter.\n",
      "     |          Default is 0.\n",
      "     |      lb, ub : int, optional\n",
      "     |          Lower and upper bound for the summation, default is set to the\n",
      "     |          support of the distribution, inclusive (``ul <= k <= ub``).\n",
      "     |      conditional : bool, optional\n",
      "     |          If true then the expectation is corrected by the conditional\n",
      "     |          probability of the summation interval. The return value is the\n",
      "     |          expectation of the function, `func`, conditional on being in\n",
      "     |          the given interval (k such that ``ul <= k <= ub``).\n",
      "     |          Default is False.\n",
      "     |      maxcount : int, optional\n",
      "     |          Maximal number of terms to evaluate (to avoid an endless loop for\n",
      "     |          an infinite sum). Default is 1000.\n",
      "     |      tolerance : float, optional\n",
      "     |          Absolute tolerance for the summation. Default is 1e-10.\n",
      "     |      chunksize : int, optional\n",
      "     |          Iterate over the support of a distributions in chunks of this size.\n",
      "     |          Default is 32.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      expect : float\n",
      "     |          Expected value.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For heavy-tailed distributions, the expected value may or may not exist,\n",
      "     |      depending on the function, `func`. If it does exist, but the sum converges\n",
      "     |      slowly, the accuracy of the result may be rather low. For instance, for\n",
      "     |      ``zipf(4)``, accuracy for mean, variance in example is only 1e-5.\n",
      "     |      increasing `maxcount` and/or `chunksize` may improve the result, but may\n",
      "     |      also make zipf very slow.\n",
      "     |      \n",
      "     |      The function is not vectorized.\n",
      "     |  \n",
      "     |  isf(self, q, *args, **kwds)\n",
      "     |      Inverse survival function (inverse of `sf`) at q of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      q : array_like\n",
      "     |          Upper tail probability.\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      k : ndarray or scalar\n",
      "     |          Quantile corresponding to the upper tail probability, q.\n",
      "     |  \n",
      "     |  logcdf(self, k, *args, **kwds)\n",
      "     |      Log of the cumulative distribution function at k of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      k : array_like, int\n",
      "     |          Quantiles.\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      logcdf : array_like\n",
      "     |          Log of the cumulative distribution function evaluated at k.\n",
      "     |  \n",
      "     |  logpmf(self, k, *args, **kwds)\n",
      "     |      Log of the probability mass function at k of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      k : array_like\n",
      "     |          Quantiles.\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter. Default is 0.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      logpmf : array_like\n",
      "     |          Log of the probability mass function evaluated at k.\n",
      "     |  \n",
      "     |  logsf(self, k, *args, **kwds)\n",
      "     |      Log of the survival function of the given RV.\n",
      "     |      \n",
      "     |      Returns the log of the \"survival function,\" defined as 1 - `cdf`,\n",
      "     |      evaluated at `k`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      k : array_like\n",
      "     |          Quantiles.\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      logsf : ndarray\n",
      "     |          Log of the survival function evaluated at `k`.\n",
      "     |  \n",
      "     |  pmf(self, k, *args, **kwds)\n",
      "     |      Probability mass function at k of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      k : array_like\n",
      "     |          Quantiles.\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      pmf : array_like\n",
      "     |          Probability mass function evaluated at k\n",
      "     |  \n",
      "     |  ppf(self, q, *args, **kwds)\n",
      "     |      Percent point function (inverse of `cdf`) at q of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      q : array_like\n",
      "     |          Lower tail probability.\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      k : array_like\n",
      "     |          Quantile corresponding to the lower tail probability, q.\n",
      "     |  \n",
      "     |  rvs(self, *args, **kwargs)\n",
      "     |      Random variates of given type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Defining number of random variates (Default is 1).  Note that `size`\n",
      "     |          has to be given as keyword, not as positional argument.\n",
      "     |      random_state : None or int or ``np.random.RandomState`` instance, optional\n",
      "     |          If int or RandomState, use it for drawing the random variates.\n",
      "     |          If None, rely on ``self.random_state``.\n",
      "     |          Default is None.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      rvs : ndarray or scalar\n",
      "     |          Random variates of given `size`.\n",
      "     |  \n",
      "     |  sf(self, k, *args, **kwds)\n",
      "     |      Survival function (1 - `cdf`) at k of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      k : array_like\n",
      "     |          Quantiles.\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sf : array_like\n",
      "     |          Survival function evaluated at k.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(cls, a=0, b=inf, name=None, badvalue=None, moment_tol=1e-08, values=None, inc=1, longname=None, shapes=None, extradoc=None, seed=None)\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from rv_generic:\n",
      "     |  \n",
      "     |  __call__(self, *args, **kwds)\n",
      "     |      Freeze the distribution for the given arguments.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution.  Should include all\n",
      "     |          the non-optional arguments, may include ``loc`` and ``scale``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      rv_frozen : rv_frozen instance\n",
      "     |          The frozen distribution.\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  entropy(self, *args, **kwds)\n",
      "     |      Differential entropy of the RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      scale : array_like, optional  (continuous distributions only).\n",
      "     |          Scale parameter (default=1).\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Entropy is defined base `e`:\n",
      "     |      \n",
      "     |      >>> drv = rv_discrete(values=((0, 1), (0.5, 0.5)))\n",
      "     |      >>> np.allclose(drv.entropy(), np.log(2.0))\n",
      "     |      True\n",
      "     |  \n",
      "     |  freeze(self, *args, **kwds)\n",
      "     |      Freeze the distribution for the given arguments.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution.  Should include all\n",
      "     |          the non-optional arguments, may include ``loc`` and ``scale``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      rv_frozen : rv_frozen instance\n",
      "     |          The frozen distribution.\n",
      "     |  \n",
      "     |  interval(self, alpha, *args, **kwds)\n",
      "     |      Confidence interval with equal areas around the median.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      alpha : array_like of float\n",
      "     |          Probability that an rv will be drawn from the returned range.\n",
      "     |          Each value should be in the range [0, 1].\n",
      "     |      arg1, arg2, ... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter, Default is 0.\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter, Default is 1.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a, b : ndarray of float\n",
      "     |          end-points of range that contain ``100 * alpha %`` of the rv's\n",
      "     |          possible values.\n",
      "     |  \n",
      "     |  mean(self, *args, **kwds)\n",
      "     |      Mean of the distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      mean : float\n",
      "     |          the mean of the distribution\n",
      "     |  \n",
      "     |  median(self, *args, **kwds)\n",
      "     |      Median of the distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter, Default is 0.\n",
      "     |      scale : array_like, optional\n",
      "     |          Scale parameter, Default is 1.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      median : float\n",
      "     |          The median of the distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      rv_discrete.ppf\n",
      "     |          Inverse of the CDF\n",
      "     |  \n",
      "     |  moment(self, n, *args, **kwds)\n",
      "     |      n-th order non-central moment of distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int, n >= 1\n",
      "     |          Order of moment.\n",
      "     |      arg1, arg2, arg3,... : float\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |  \n",
      "     |  stats(self, *args, **kwds)\n",
      "     |      Some statistics of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional (continuous RVs only)\n",
      "     |          scale parameter (default=1)\n",
      "     |      moments : str, optional\n",
      "     |          composed of letters ['mvsk'] defining which moments to compute:\n",
      "     |          'm' = mean,\n",
      "     |          'v' = variance,\n",
      "     |          's' = (Fisher's) skew,\n",
      "     |          'k' = (Fisher's) kurtosis.\n",
      "     |          (default is 'mv')\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      stats : sequence\n",
      "     |          of requested moments.\n",
      "     |  \n",
      "     |  std(self, *args, **kwds)\n",
      "     |      Standard deviation of the distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      std : float\n",
      "     |          standard deviation of the distribution\n",
      "     |  \n",
      "     |  support(self, *args, **kwargs)\n",
      "     |      Return the support of the distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, ... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter, Default is 0.\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter, Default is 1.\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a, b : float\n",
      "     |          end-points of the distribution's support.\n",
      "     |  \n",
      "     |  var(self, *args, **kwds)\n",
      "     |      Variance of the distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      var : float\n",
      "     |          the variance of the distribution\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from rv_generic:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  random_state\n",
      "     |      Get or set the RandomState object for generating random variates.\n",
      "     |      \n",
      "     |      This can be either None or an existing RandomState object.\n",
      "     |      \n",
      "     |      If None (or np.random), use the RandomState singleton used by np.random.\n",
      "     |      If already a RandomState instance, use it.\n",
      "     |      If an int, use a new RandomState instance seeded with seed.\n",
      "    \n",
      "    class rv_histogram(scipy.stats._distn_infrastructure.rv_continuous)\n",
      "     |  rv_histogram(histogram, *args, **kwargs)\n",
      "     |  \n",
      "     |  Generates a distribution given by a histogram.\n",
      "     |  This is useful to generate a template distribution from a binned\n",
      "     |  datasample.\n",
      "     |  \n",
      "     |  As a subclass of the `rv_continuous` class, `rv_histogram` inherits from it\n",
      "     |  a collection of generic methods (see `rv_continuous` for the full list),\n",
      "     |  and implements them based on the properties of the provided binned\n",
      "     |  datasample.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  histogram : tuple of array_like\n",
      "     |    Tuple containing two array_like objects\n",
      "     |    The first containing the content of n bins\n",
      "     |    The second containing the (n+1) bin boundaries\n",
      "     |    In particular the return value np.histogram is accepted\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  There are no additional shape parameters except for the loc and scale.\n",
      "     |  The pdf is defined as a stepwise function from the provided histogram\n",
      "     |  The cdf is a linear interpolation of the pdf.\n",
      "     |  \n",
      "     |  .. versionadded:: 0.19.0\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  \n",
      "     |  Create a scipy.stats distribution from a numpy histogram\n",
      "     |  \n",
      "     |  >>> import scipy.stats\n",
      "     |  >>> import numpy as np\n",
      "     |  >>> data = scipy.stats.norm.rvs(size=100000, loc=0, scale=1.5, random_state=123)\n",
      "     |  >>> hist = np.histogram(data, bins=100)\n",
      "     |  >>> hist_dist = scipy.stats.rv_histogram(hist)\n",
      "     |  \n",
      "     |  Behaves like an ordinary scipy rv_continuous distribution\n",
      "     |  \n",
      "     |  >>> hist_dist.pdf(1.0)\n",
      "     |  0.20538577847618705\n",
      "     |  >>> hist_dist.cdf(2.0)\n",
      "     |  0.90818568543056499\n",
      "     |  \n",
      "     |  PDF is zero above (below) the highest (lowest) bin of the histogram,\n",
      "     |  defined by the max (min) of the original dataset\n",
      "     |  \n",
      "     |  >>> hist_dist.pdf(np.max(data))\n",
      "     |  0.0\n",
      "     |  >>> hist_dist.cdf(np.max(data))\n",
      "     |  1.0\n",
      "     |  >>> hist_dist.pdf(np.min(data))\n",
      "     |  7.7591907244498314e-05\n",
      "     |  >>> hist_dist.cdf(np.min(data))\n",
      "     |  0.0\n",
      "     |  \n",
      "     |  PDF and CDF follow the histogram\n",
      "     |  \n",
      "     |  >>> import matplotlib.pyplot as plt\n",
      "     |  >>> X = np.linspace(-5.0, 5.0, 100)\n",
      "     |  >>> plt.title(\"PDF from Template\")\n",
      "     |  >>> plt.hist(data, density=True, bins=100)\n",
      "     |  >>> plt.plot(X, hist_dist.pdf(X), label='PDF')\n",
      "     |  >>> plt.plot(X, hist_dist.cdf(X), label='CDF')\n",
      "     |  >>> plt.show()\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      rv_histogram\n",
      "     |      scipy.stats._distn_infrastructure.rv_continuous\n",
      "     |      scipy.stats._distn_infrastructure.rv_generic\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, histogram, *args, **kwargs)\n",
      "     |      Create a new distribution using the given histogram\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      histogram : tuple of array_like\n",
      "     |        Tuple containing two array_like objects\n",
      "     |        The first containing the content of n bins\n",
      "     |        The second containing the (n+1) bin boundaries\n",
      "     |        In particular the return value np.histogram is accepted\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from scipy.stats._distn_infrastructure.rv_continuous:\n",
      "     |  \n",
      "     |  cdf(self, x, *args, **kwds)\n",
      "     |      Cumulative distribution function of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          quantiles\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      cdf : ndarray\n",
      "     |          Cumulative distribution function evaluated at `x`\n",
      "     |  \n",
      "     |  expect(self, func=None, args=(), loc=0, scale=1, lb=None, ub=None, conditional=False, **kwds)\n",
      "     |      Calculate expected value of a function with respect to the\n",
      "     |      distribution by numerical integration.\n",
      "     |      \n",
      "     |      The expected value of a function ``f(x)`` with respect to a\n",
      "     |      distribution ``dist`` is defined as::\n",
      "     |      \n",
      "     |                  ub\n",
      "     |          E[f(x)] = Integral(f(x) * dist.pdf(x)),\n",
      "     |                  lb\n",
      "     |      \n",
      "     |      where ``ub`` and ``lb`` are arguments and ``x`` has the ``dist.pdf(x)``\n",
      "     |      distribution. If the bounds ``lb`` and ``ub`` correspond to the\n",
      "     |      support of the distribution, e.g. ``[-inf, inf]`` in the default\n",
      "     |      case, then the integral is the unrestricted expectation of ``f(x)``.\n",
      "     |      Also, the function ``f(x)`` may be defined such that ``f(x)`` is ``0``\n",
      "     |      outside a finite interval in which case the expectation is\n",
      "     |      calculated within the finite range ``[lb, ub]``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      func : callable, optional\n",
      "     |          Function for which integral is calculated. Takes only one argument.\n",
      "     |          The default is the identity mapping f(x) = x.\n",
      "     |      args : tuple, optional\n",
      "     |          Shape parameters of the distribution.\n",
      "     |      loc : float, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      scale : float, optional\n",
      "     |          Scale parameter (default=1).\n",
      "     |      lb, ub : scalar, optional\n",
      "     |          Lower and upper bound for integration. Default is set to the\n",
      "     |          support of the distribution.\n",
      "     |      conditional : bool, optional\n",
      "     |          If True, the integral is corrected by the conditional probability\n",
      "     |          of the integration interval.  The return value is the expectation\n",
      "     |          of the function, conditional on being in the given interval.\n",
      "     |          Default is False.\n",
      "     |      \n",
      "     |      Additional keyword arguments are passed to the integration routine.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      expect : float\n",
      "     |          The calculated expected value.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The integration behavior of this function is inherited from\n",
      "     |      `scipy.integrate.quad`. Neither this function nor\n",
      "     |      `scipy.integrate.quad` can verify whether the integral exists or is\n",
      "     |      finite. For example ``cauchy(0).mean()`` returns ``np.nan`` and\n",
      "     |      ``cauchy(0).expect()`` returns ``0.0``.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      To understand the effect of the bounds of integration consider\n",
      "     |      \n",
      "     |      >>> from scipy.stats import expon\n",
      "     |      >>> expon(1).expect(lambda x: 1, lb=0.0, ub=2.0)\n",
      "     |      0.6321205588285578\n",
      "     |      \n",
      "     |      This is close to\n",
      "     |      \n",
      "     |      >>> expon(1).cdf(2.0) - expon(1).cdf(0.0)\n",
      "     |      0.6321205588285577\n",
      "     |      \n",
      "     |      If ``conditional=True``\n",
      "     |      \n",
      "     |      >>> expon(1).expect(lambda x: 1, lb=0.0, ub=2.0, conditional=True)\n",
      "     |      1.0000000000000002\n",
      "     |      \n",
      "     |      The slight deviation from 1 is due to numerical integration.\n",
      "     |  \n",
      "     |  fit(self, data, *args, **kwds)\n",
      "     |      Return MLEs for shape (if applicable), location, and scale\n",
      "     |      parameters from data.\n",
      "     |      \n",
      "     |      MLE stands for Maximum Likelihood Estimate.  Starting estimates for\n",
      "     |      the fit are given by input arguments; for any arguments not provided\n",
      "     |      with starting estimates, ``self._fitstart(data)`` is called to generate\n",
      "     |      such.\n",
      "     |      \n",
      "     |      One can hold some parameters fixed to specific values by passing in\n",
      "     |      keyword arguments ``f0``, ``f1``, ..., ``fn`` (for shape parameters)\n",
      "     |      and ``floc`` and ``fscale`` (for location and scale parameters,\n",
      "     |      respectively).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : array_like\n",
      "     |          Data to use in calculating the MLEs.\n",
      "     |      args : floats, optional\n",
      "     |          Starting value(s) for any shape-characterizing arguments (those not\n",
      "     |          provided will be determined by a call to ``_fitstart(data)``).\n",
      "     |          No default value.\n",
      "     |      kwds : floats, optional\n",
      "     |          Starting values for the location and scale parameters; no default.\n",
      "     |          Special keyword arguments are recognized as holding certain\n",
      "     |          parameters fixed:\n",
      "     |      \n",
      "     |          - f0...fn : hold respective shape parameters fixed.\n",
      "     |            Alternatively, shape parameters to fix can be specified by name.\n",
      "     |            For example, if ``self.shapes == \"a, b\"``, ``fa``and ``fix_a``\n",
      "     |            are equivalent to ``f0``, and ``fb`` and ``fix_b`` are\n",
      "     |            equivalent to ``f1``.\n",
      "     |      \n",
      "     |          - floc : hold location parameter fixed to specified value.\n",
      "     |      \n",
      "     |          - fscale : hold scale parameter fixed to specified value.\n",
      "     |      \n",
      "     |          - optimizer : The optimizer to use.  The optimizer must take ``func``,\n",
      "     |            and starting position as the first two arguments,\n",
      "     |            plus ``args`` (for extra arguments to pass to the\n",
      "     |            function to be optimized) and ``disp=0`` to suppress\n",
      "     |            output as keyword arguments.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      mle_tuple : tuple of floats\n",
      "     |          MLEs for any shape parameters (if applicable), followed by those\n",
      "     |          for location and scale. For most random variables, shape statistics\n",
      "     |          will be returned, but there are exceptions (e.g. ``norm``).\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This fit is computed by maximizing a log-likelihood function, with\n",
      "     |      penalty applied for samples outside of range of the distribution. The\n",
      "     |      returned answer is not guaranteed to be the globally optimal MLE, it\n",
      "     |      may only be locally optimal, or the optimization may fail altogether.\n",
      "     |      If the data contain any of np.nan, np.inf, or -np.inf, the fit routine\n",
      "     |      will throw a RuntimeError.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      \n",
      "     |      Generate some data to fit: draw random variates from the `beta`\n",
      "     |      distribution\n",
      "     |      \n",
      "     |      >>> from scipy.stats import beta\n",
      "     |      >>> a, b = 1., 2.\n",
      "     |      >>> x = beta.rvs(a, b, size=1000)\n",
      "     |      \n",
      "     |      Now we can fit all four parameters (``a``, ``b``, ``loc`` and ``scale``):\n",
      "     |      \n",
      "     |      >>> a1, b1, loc1, scale1 = beta.fit(x)\n",
      "     |      \n",
      "     |      We can also use some prior knowledge about the dataset: let's keep\n",
      "     |      ``loc`` and ``scale`` fixed:\n",
      "     |      \n",
      "     |      >>> a1, b1, loc1, scale1 = beta.fit(x, floc=0, fscale=1)\n",
      "     |      >>> loc1, scale1\n",
      "     |      (0, 1)\n",
      "     |      \n",
      "     |      We can also keep shape parameters fixed by using ``f``-keywords. To\n",
      "     |      keep the zero-th shape parameter ``a`` equal 1, use ``f0=1`` or,\n",
      "     |      equivalently, ``fa=1``:\n",
      "     |      \n",
      "     |      >>> a1, b1, loc1, scale1 = beta.fit(x, fa=1, floc=0, fscale=1)\n",
      "     |      >>> a1\n",
      "     |      1\n",
      "     |      \n",
      "     |      Not all distributions return estimates for the shape parameters.\n",
      "     |      ``norm`` for example just returns estimates for location and scale:\n",
      "     |      \n",
      "     |      >>> from scipy.stats import norm\n",
      "     |      >>> x = norm.rvs(a, b, size=1000, random_state=123)\n",
      "     |      >>> loc1, scale1 = norm.fit(x)\n",
      "     |      >>> loc1, scale1\n",
      "     |      (0.92087172783841631, 2.0015750750324668)\n",
      "     |  \n",
      "     |  fit_loc_scale(self, data, *args)\n",
      "     |      Estimate loc and scale parameters from data using 1st and 2nd moments.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      data : array_like\n",
      "     |          Data to fit.\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Lhat : float\n",
      "     |          Estimated location parameter for the data.\n",
      "     |      Shat : float\n",
      "     |          Estimated scale parameter for the data.\n",
      "     |  \n",
      "     |  isf(self, q, *args, **kwds)\n",
      "     |      Inverse survival function (inverse of `sf`) at q of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      q : array_like\n",
      "     |          upper tail probability\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      x : ndarray or scalar\n",
      "     |          Quantile corresponding to the upper tail probability q.\n",
      "     |  \n",
      "     |  logcdf(self, x, *args, **kwds)\n",
      "     |      Log of the cumulative distribution function at x of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          quantiles\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      logcdf : array_like\n",
      "     |          Log of the cumulative distribution function evaluated at x\n",
      "     |  \n",
      "     |  logpdf(self, x, *args, **kwds)\n",
      "     |      Log of the probability density function at x of the given RV.\n",
      "     |      \n",
      "     |      This uses a more numerically accurate calculation if available.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          quantiles\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      logpdf : array_like\n",
      "     |          Log of the probability density function evaluated at x\n",
      "     |  \n",
      "     |  logsf(self, x, *args, **kwds)\n",
      "     |      Log of the survival function of the given RV.\n",
      "     |      \n",
      "     |      Returns the log of the \"survival function,\" defined as (1 - `cdf`),\n",
      "     |      evaluated at `x`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          quantiles\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      logsf : ndarray\n",
      "     |          Log of the survival function evaluated at `x`.\n",
      "     |  \n",
      "     |  nnlf(self, theta, x)\n",
      "     |      Return negative loglikelihood function.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is ``-sum(log pdf(x, theta), axis=0)`` where `theta` are the\n",
      "     |      parameters (including loc and scale).\n",
      "     |  \n",
      "     |  pdf(self, x, *args, **kwds)\n",
      "     |      Probability density function at x of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          quantiles\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      pdf : ndarray\n",
      "     |          Probability density function evaluated at x\n",
      "     |  \n",
      "     |  ppf(self, q, *args, **kwds)\n",
      "     |      Percent point function (inverse of `cdf`) at q of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      q : array_like\n",
      "     |          lower tail probability\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      x : array_like\n",
      "     |          quantile corresponding to the lower tail probability q.\n",
      "     |  \n",
      "     |  sf(self, x, *args, **kwds)\n",
      "     |      Survival function (1 - `cdf`) at x of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          quantiles\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      sf : array_like\n",
      "     |          Survival function evaluated at x\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from scipy.stats._distn_infrastructure.rv_generic:\n",
      "     |  \n",
      "     |  __call__(self, *args, **kwds)\n",
      "     |      Freeze the distribution for the given arguments.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution.  Should include all\n",
      "     |          the non-optional arguments, may include ``loc`` and ``scale``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      rv_frozen : rv_frozen instance\n",
      "     |          The frozen distribution.\n",
      "     |  \n",
      "     |  __getstate__(self)\n",
      "     |  \n",
      "     |  __setstate__(self, state)\n",
      "     |  \n",
      "     |  entropy(self, *args, **kwds)\n",
      "     |      Differential entropy of the RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      scale : array_like, optional  (continuous distributions only).\n",
      "     |          Scale parameter (default=1).\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Entropy is defined base `e`:\n",
      "     |      \n",
      "     |      >>> drv = rv_discrete(values=((0, 1), (0.5, 0.5)))\n",
      "     |      >>> np.allclose(drv.entropy(), np.log(2.0))\n",
      "     |      True\n",
      "     |  \n",
      "     |  freeze(self, *args, **kwds)\n",
      "     |      Freeze the distribution for the given arguments.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution.  Should include all\n",
      "     |          the non-optional arguments, may include ``loc`` and ``scale``.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      rv_frozen : rv_frozen instance\n",
      "     |          The frozen distribution.\n",
      "     |  \n",
      "     |  interval(self, alpha, *args, **kwds)\n",
      "     |      Confidence interval with equal areas around the median.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      alpha : array_like of float\n",
      "     |          Probability that an rv will be drawn from the returned range.\n",
      "     |          Each value should be in the range [0, 1].\n",
      "     |      arg1, arg2, ... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter, Default is 0.\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter, Default is 1.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a, b : ndarray of float\n",
      "     |          end-points of range that contain ``100 * alpha %`` of the rv's\n",
      "     |          possible values.\n",
      "     |  \n",
      "     |  mean(self, *args, **kwds)\n",
      "     |      Mean of the distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      mean : float\n",
      "     |          the mean of the distribution\n",
      "     |  \n",
      "     |  median(self, *args, **kwds)\n",
      "     |      Median of the distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter, Default is 0.\n",
      "     |      scale : array_like, optional\n",
      "     |          Scale parameter, Default is 1.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      median : float\n",
      "     |          The median of the distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      rv_discrete.ppf\n",
      "     |          Inverse of the CDF\n",
      "     |  \n",
      "     |  moment(self, n, *args, **kwds)\n",
      "     |      n-th order non-central moment of distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int, n >= 1\n",
      "     |          Order of moment.\n",
      "     |      arg1, arg2, arg3,... : float\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |  \n",
      "     |  rvs(self, *args, **kwds)\n",
      "     |      Random variates of given type.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          Location parameter (default=0).\n",
      "     |      scale : array_like, optional\n",
      "     |          Scale parameter (default=1).\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Defining number of random variates (default is 1).\n",
      "     |      random_state : None or int or ``np.random.RandomState`` instance, optional\n",
      "     |          If int or RandomState, use it for drawing the random variates.\n",
      "     |          If None, rely on ``self.random_state``.\n",
      "     |          Default is None.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      rvs : ndarray or scalar\n",
      "     |          Random variates of given `size`.\n",
      "     |  \n",
      "     |  stats(self, *args, **kwds)\n",
      "     |      Some statistics of the given RV.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional (continuous RVs only)\n",
      "     |          scale parameter (default=1)\n",
      "     |      moments : str, optional\n",
      "     |          composed of letters ['mvsk'] defining which moments to compute:\n",
      "     |          'm' = mean,\n",
      "     |          'v' = variance,\n",
      "     |          's' = (Fisher's) skew,\n",
      "     |          'k' = (Fisher's) kurtosis.\n",
      "     |          (default is 'mv')\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      stats : sequence\n",
      "     |          of requested moments.\n",
      "     |  \n",
      "     |  std(self, *args, **kwds)\n",
      "     |      Standard deviation of the distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      std : float\n",
      "     |          standard deviation of the distribution\n",
      "     |  \n",
      "     |  support(self, *args, **kwargs)\n",
      "     |      Return the support of the distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, ... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information).\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter, Default is 0.\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter, Default is 1.\n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      a, b : float\n",
      "     |          end-points of the distribution's support.\n",
      "     |  \n",
      "     |  var(self, *args, **kwds)\n",
      "     |      Variance of the distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      arg1, arg2, arg3,... : array_like\n",
      "     |          The shape parameter(s) for the distribution (see docstring of the\n",
      "     |          instance object for more information)\n",
      "     |      loc : array_like, optional\n",
      "     |          location parameter (default=0)\n",
      "     |      scale : array_like, optional\n",
      "     |          scale parameter (default=1)\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      var : float\n",
      "     |          the variance of the distribution\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from scipy.stats._distn_infrastructure.rv_generic:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  random_state\n",
      "     |      Get or set the RandomState object for generating random variates.\n",
      "     |      \n",
      "     |      This can be either None or an existing RandomState object.\n",
      "     |      \n",
      "     |      If None (or np.random), use the RandomState singleton used by np.random.\n",
      "     |      If already a RandomState instance, use it.\n",
      "     |      If an int, use a new RandomState instance seeded with seed.\n",
      "\n",
      "FUNCTIONS\n",
      "    anderson(x, dist='norm')\n",
      "        Anderson-Darling test for data coming from a particular distribution.\n",
      "        \n",
      "        The Anderson-Darling tests the null hypothesis that a sample is\n",
      "        drawn from a population that follows a particular distribution.\n",
      "        For the Anderson-Darling test, the critical values depend on\n",
      "        which distribution is being tested against.  This function works\n",
      "        for normal, exponential, logistic, or Gumbel (Extreme Value\n",
      "        Type I) distributions.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Array of sample data.\n",
      "        dist : {'norm','expon','logistic','gumbel','gumbel_l', gumbel_r',\n",
      "            'extreme1'}, optional\n",
      "            the type of distribution to test against.  The default is 'norm'\n",
      "            and 'extreme1', 'gumbel_l' and 'gumbel' are synonyms.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float\n",
      "            The Anderson-Darling test statistic.\n",
      "        critical_values : list\n",
      "            The critical values for this distribution.\n",
      "        significance_level : list\n",
      "            The significance levels for the corresponding critical values\n",
      "            in percents.  The function returns critical values for a\n",
      "            differing set of significance levels depending on the\n",
      "            distribution that is being tested against.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        kstest : The Kolmogorov-Smirnov test for goodness-of-fit.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Critical values provided are for the following significance levels:\n",
      "        \n",
      "        normal/exponenential\n",
      "            15%, 10%, 5%, 2.5%, 1%\n",
      "        logistic\n",
      "            25%, 10%, 5%, 2.5%, 1%, 0.5%\n",
      "        Gumbel\n",
      "            25%, 10%, 5%, 2.5%, 1%\n",
      "        \n",
      "        If the returned statistic is larger than these critical values then\n",
      "        for the corresponding significance level, the null hypothesis that\n",
      "        the data come from the chosen distribution can be rejected.\n",
      "        The returned statistic is referred to as 'A2' in the references.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm\n",
      "        .. [2] Stephens, M. A. (1974). EDF Statistics for Goodness of Fit and\n",
      "               Some Comparisons, Journal of the American Statistical Association,\n",
      "               Vol. 69, pp. 730-737.\n",
      "        .. [3] Stephens, M. A. (1976). Asymptotic Results for Goodness-of-Fit\n",
      "               Statistics with Unknown Parameters, Annals of Statistics, Vol. 4,\n",
      "               pp. 357-369.\n",
      "        .. [4] Stephens, M. A. (1977). Goodness of Fit for the Extreme Value\n",
      "               Distribution, Biometrika, Vol. 64, pp. 583-588.\n",
      "        .. [5] Stephens, M. A. (1977). Goodness of Fit with Special Reference\n",
      "               to Tests for Exponentiality , Technical Report No. 262,\n",
      "               Department of Statistics, Stanford University, Stanford, CA.\n",
      "        .. [6] Stephens, M. A. (1979). Tests of Fit for the Logistic Distribution\n",
      "               Based on the Empirical Distribution Function, Biometrika, Vol. 66,\n",
      "               pp. 591-595.\n",
      "    \n",
      "    anderson_ksamp(samples, midrank=True)\n",
      "        The Anderson-Darling test for k-samples.\n",
      "        \n",
      "        The k-sample Anderson-Darling test is a modification of the\n",
      "        one-sample Anderson-Darling test. It tests the null hypothesis\n",
      "        that k-samples are drawn from the same population without having\n",
      "        to specify the distribution function of that population. The\n",
      "        critical values depend on the number of samples.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        samples : sequence of 1-D array_like\n",
      "            Array of sample data in arrays.\n",
      "        midrank : bool, optional\n",
      "            Type of Anderson-Darling test which is computed. Default\n",
      "            (True) is the midrank test applicable to continuous and\n",
      "            discrete populations. If False, the right side empirical\n",
      "            distribution is used.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float\n",
      "            Normalized k-sample Anderson-Darling test statistic.\n",
      "        critical_values : array\n",
      "            The critical values for significance levels 25%, 10%, 5%, 2.5%, 1%,\n",
      "            0.5%, 0.1%.\n",
      "        significance_level : float\n",
      "            An approximate significance level at which the null hypothesis for the\n",
      "            provided samples can be rejected. The value is floored / capped at\n",
      "            0.1% / 25%.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        ValueError\n",
      "            If less than 2 samples are provided, a sample is empty, or no\n",
      "            distinct observations are in the samples.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        ks_2samp : 2 sample Kolmogorov-Smirnov test\n",
      "        anderson : 1 sample Anderson-Darling test\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        [1]_ defines three versions of the k-sample Anderson-Darling test:\n",
      "        one for continuous distributions and two for discrete\n",
      "        distributions, in which ties between samples may occur. The\n",
      "        default of this routine is to compute the version based on the\n",
      "        midrank empirical distribution function. This test is applicable\n",
      "        to continuous and discrete data. If midrank is set to False, the\n",
      "        right side empirical distribution is used for a test for discrete\n",
      "        data. According to [1]_, the two discrete test statistics differ\n",
      "        only slightly if a few collisions due to round-off errors occur in\n",
      "        the test not adjusted for ties between samples.\n",
      "        \n",
      "        The critical values corresponding to the significance levels from 0.01\n",
      "        to 0.25 are taken from [1]_. p-values are floored / capped\n",
      "        at 0.1% / 25%. Since the range of critical values might be extended in\n",
      "        future releases, it is recommended not to test ``p == 0.25``, but rather\n",
      "        ``p >= 0.25`` (analogously for the lower bound).\n",
      "        \n",
      "        .. versionadded:: 0.14.0\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Scholz, F. W and Stephens, M. A. (1987), K-Sample\n",
      "               Anderson-Darling Tests, Journal of the American Statistical\n",
      "               Association, Vol. 82, pp. 918-924.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> np.random.seed(314159)\n",
      "        \n",
      "        The null hypothesis that the two random samples come from the same\n",
      "        distribution can be rejected at the 5% level because the returned\n",
      "        test value is greater than the critical value for 5% (1.961) but\n",
      "        not at the 2.5% level. The interpolation gives an approximate\n",
      "        significance level of 3.2%:\n",
      "        \n",
      "        >>> stats.anderson_ksamp([np.random.normal(size=50),\n",
      "        ... np.random.normal(loc=0.5, size=30)])\n",
      "        (2.4615796189876105,\n",
      "          array([ 0.325,  1.226,  1.961,  2.718,  3.752, 4.592, 6.546]),\n",
      "          0.03176687568842282)\n",
      "        \n",
      "        \n",
      "        The null hypothesis cannot be rejected for three samples from an\n",
      "        identical distribution. The reported p-value (25%) has been capped and\n",
      "        may not be very accurate (since it corresponds to the value 0.449\n",
      "        whereas the statistic is -0.731):\n",
      "        \n",
      "        >>> stats.anderson_ksamp([np.random.normal(size=50),\n",
      "        ... np.random.normal(size=30), np.random.normal(size=20)])\n",
      "        (-0.73091722665244196,\n",
      "          array([ 0.44925884,  1.3052767 ,  1.9434184 ,  2.57696569,  3.41634856,\n",
      "          4.07210043, 5.56419101]),\n",
      "          0.25)\n",
      "    \n",
      "    ansari(x, y)\n",
      "        Perform the Ansari-Bradley test for equal scale parameters.\n",
      "        \n",
      "        The Ansari-Bradley test is a non-parametric test for the equality\n",
      "        of the scale parameter of the distributions from which two\n",
      "        samples were drawn.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x, y : array_like\n",
      "            Arrays of sample data.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float\n",
      "            The Ansari-Bradley test statistic.\n",
      "        pvalue : float\n",
      "            The p-value of the hypothesis test.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        fligner : A non-parametric test for the equality of k variances\n",
      "        mood : A non-parametric test for the equality of two scale parameters\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The p-value given is exact when the sample sizes are both less than\n",
      "        55 and there are no ties, otherwise a normal approximation for the\n",
      "        p-value is used.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Sprent, Peter and N.C. Smeeton.  Applied nonparametric statistical\n",
      "               methods.  3rd ed. Chapman and Hall/CRC. 2001.  Section 5.8.2.\n",
      "    \n",
      "    bartlett(*args)\n",
      "        Perform Bartlett's test for equal variances.\n",
      "        \n",
      "        Bartlett's test tests the null hypothesis that all input samples\n",
      "        are from populations with equal variances.  For samples\n",
      "        from significantly non-normal populations, Levene's test\n",
      "        `levene` is more robust.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        sample1, sample2,... : array_like\n",
      "            arrays of sample data.  Only 1d arrays are accepted, they may have\n",
      "            different lengths.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float\n",
      "            The test statistic.\n",
      "        pvalue : float\n",
      "            The p-value of the test.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        fligner : A non-parametric test for the equality of k variances\n",
      "        levene : A robust parametric test for equality of k variances\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Conover et al. (1981) examine many of the existing parametric and\n",
      "        nonparametric tests by extensive simulations and they conclude that the\n",
      "        tests proposed by Fligner and Killeen (1976) and Levene (1960) appear to be\n",
      "        superior in terms of robustness of departures from normality and power\n",
      "        ([3]_).\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1]  https://www.itl.nist.gov/div898/handbook/eda/section3/eda357.htm\n",
      "        \n",
      "        .. [2]  Snedecor, George W. and Cochran, William G. (1989), Statistical\n",
      "                  Methods, Eighth Edition, Iowa State University Press.\n",
      "        \n",
      "        .. [3] Park, C. and Lindsay, B. G. (1999). Robust Scale Estimation and\n",
      "               Hypothesis Testing based on Quadratic Inference Function. Technical\n",
      "               Report #99-03, Center for Likelihood Studies, Pennsylvania State\n",
      "               University.\n",
      "        \n",
      "        .. [4] Bartlett, M. S. (1937). Properties of Sufficiency and Statistical\n",
      "               Tests. Proceedings of the Royal Society of London. Series A,\n",
      "               Mathematical and Physical Sciences, Vol. 160, No.901, pp. 268-282.\n",
      "    \n",
      "    bayes_mvs(data, alpha=0.9)\n",
      "        Bayesian confidence intervals for the mean, var, and std.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data : array_like\n",
      "            Input data, if multi-dimensional it is flattened to 1-D by `bayes_mvs`.\n",
      "            Requires 2 or more data points.\n",
      "        alpha : float, optional\n",
      "            Probability that the returned confidence interval contains\n",
      "            the true parameter.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        mean_cntr, var_cntr, std_cntr : tuple\n",
      "            The three results are for the mean, variance and standard deviation,\n",
      "            respectively.  Each result is a tuple of the form::\n",
      "        \n",
      "                (center, (lower, upper))\n",
      "        \n",
      "            with `center` the mean of the conditional pdf of the value given the\n",
      "            data, and `(lower, upper)` a confidence interval, centered on the\n",
      "            median, containing the estimate to a probability ``alpha``.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        mvsdist\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Each tuple of mean, variance, and standard deviation estimates represent\n",
      "        the (center, (lower, upper)) with center the mean of the conditional pdf\n",
      "        of the value given the data and (lower, upper) is a confidence interval\n",
      "        centered on the median, containing the estimate to a probability\n",
      "        ``alpha``.\n",
      "        \n",
      "        Converts data to 1-D and assumes all data has the same mean and variance.\n",
      "        Uses Jeffrey's prior for variance and std.\n",
      "        \n",
      "        Equivalent to ``tuple((x.mean(), x.interval(alpha)) for x in mvsdist(dat))``\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        T.E. Oliphant, \"A Bayesian perspective on estimating mean, variance, and\n",
      "        standard-deviation from data\", https://scholarsarchive.byu.edu/facpub/278,\n",
      "        2006.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        First a basic example to demonstrate the outputs:\n",
      "        \n",
      "        >>> from scipy import stats\n",
      "        >>> data = [6, 9, 12, 7, 8, 8, 13]\n",
      "        >>> mean, var, std = stats.bayes_mvs(data)\n",
      "        >>> mean\n",
      "        Mean(statistic=9.0, minmax=(7.103650222612533, 10.896349777387467))\n",
      "        >>> var\n",
      "        Variance(statistic=10.0, minmax=(3.176724206..., 24.45910382...))\n",
      "        >>> std\n",
      "        Std_dev(statistic=2.9724954732045084, minmax=(1.7823367265645143, 4.945614605014631))\n",
      "        \n",
      "        Now we generate some normally distributed random data, and get estimates of\n",
      "        mean and standard deviation with 95% confidence intervals for those\n",
      "        estimates:\n",
      "        \n",
      "        >>> n_samples = 100000\n",
      "        >>> data = stats.norm.rvs(size=n_samples)\n",
      "        >>> res_mean, res_var, res_std = stats.bayes_mvs(data, alpha=0.95)\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> fig = plt.figure()\n",
      "        >>> ax = fig.add_subplot(111)\n",
      "        >>> ax.hist(data, bins=100, density=True, label='Histogram of data')\n",
      "        >>> ax.vlines(res_mean.statistic, 0, 0.5, colors='r', label='Estimated mean')\n",
      "        >>> ax.axvspan(res_mean.minmax[0],res_mean.minmax[1], facecolor='r',\n",
      "        ...            alpha=0.2, label=r'Estimated mean (95% limits)')\n",
      "        >>> ax.vlines(res_std.statistic, 0, 0.5, colors='g', label='Estimated scale')\n",
      "        >>> ax.axvspan(res_std.minmax[0],res_std.minmax[1], facecolor='g', alpha=0.2,\n",
      "        ...            label=r'Estimated scale (95% limits)')\n",
      "        \n",
      "        >>> ax.legend(fontsize=10)\n",
      "        >>> ax.set_xlim([-4, 4])\n",
      "        >>> ax.set_ylim([0, 0.5])\n",
      "        >>> plt.show()\n",
      "    \n",
      "    binned_statistic(x, values, statistic='mean', bins=10, range=None)\n",
      "        Compute a binned statistic for one or more sets of data.\n",
      "        \n",
      "        This is a generalization of a histogram function.  A histogram divides\n",
      "        the space into bins, and returns the count of the number of points in\n",
      "        each bin.  This function allows the computation of the sum, mean, median,\n",
      "        or other statistic of the values (or set of values) within each bin.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : (N,) array_like\n",
      "            A sequence of values to be binned.\n",
      "        values : (N,) array_like or list of (N,) array_like\n",
      "            The data on which the statistic will be computed.  This must be\n",
      "            the same shape as `x`, or a set of sequences - each the same shape as\n",
      "            `x`.  If `values` is a set of sequences, the statistic will be computed\n",
      "            on each independently.\n",
      "        statistic : string or callable, optional\n",
      "            The statistic to compute (default is 'mean').\n",
      "            The following statistics are available:\n",
      "        \n",
      "              * 'mean' : compute the mean of values for points within each bin.\n",
      "                Empty bins will be represented by NaN.\n",
      "              * 'std' : compute the standard deviation within each bin. This\n",
      "                is implicitly calculated with ddof=0.\n",
      "              * 'median' : compute the median of values for points within each\n",
      "                bin. Empty bins will be represented by NaN.\n",
      "              * 'count' : compute the count of points within each bin.  This is\n",
      "                identical to an unweighted histogram.  `values` array is not\n",
      "                referenced.\n",
      "              * 'sum' : compute the sum of values for points within each bin.\n",
      "                This is identical to a weighted histogram.\n",
      "              * 'min' : compute the minimum of values for points within each bin.\n",
      "                Empty bins will be represented by NaN.\n",
      "              * 'max' : compute the maximum of values for point within each bin.\n",
      "                Empty bins will be represented by NaN.\n",
      "              * function : a user-defined function which takes a 1D array of\n",
      "                values, and outputs a single numerical statistic. This function\n",
      "                will be called on the values in each bin.  Empty bins will be\n",
      "                represented by function([]), or NaN if this returns an error.\n",
      "        \n",
      "        bins : int or sequence of scalars, optional\n",
      "            If `bins` is an int, it defines the number of equal-width bins in the\n",
      "            given range (10 by default).  If `bins` is a sequence, it defines the\n",
      "            bin edges, including the rightmost edge, allowing for non-uniform bin\n",
      "            widths.  Values in `x` that are smaller than lowest bin edge are\n",
      "            assigned to bin number 0, values beyond the highest bin are assigned to\n",
      "            ``bins[-1]``.  If the bin edges are specified, the number of bins will\n",
      "            be, (nx = len(bins)-1).\n",
      "        range : (float, float) or [(float, float)], optional\n",
      "            The lower and upper range of the bins.  If not provided, range\n",
      "            is simply ``(x.min(), x.max())``.  Values outside the range are\n",
      "            ignored.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : array\n",
      "            The values of the selected statistic in each bin.\n",
      "        bin_edges : array of dtype float\n",
      "            Return the bin edges ``(length(statistic)+1)``.\n",
      "        binnumber: 1-D ndarray of ints\n",
      "            Indices of the bins (corresponding to `bin_edges`) in which each value\n",
      "            of `x` belongs.  Same length as `values`.  A binnumber of `i` means the\n",
      "            corresponding value is between (bin_edges[i-1], bin_edges[i]).\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        numpy.digitize, numpy.histogram, binned_statistic_2d, binned_statistic_dd\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        All but the last (righthand-most) bin is half-open.  In other words, if\n",
      "        `bins` is ``[1, 2, 3, 4]``, then the first bin is ``[1, 2)`` (including 1,\n",
      "        but excluding 2) and the second ``[2, 3)``.  The last bin, however, is\n",
      "        ``[3, 4]``, which *includes* 4.\n",
      "        \n",
      "        .. versionadded:: 0.11.0\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        \n",
      "        First some basic examples:\n",
      "        \n",
      "        Create two evenly spaced bins in the range of the given sample, and sum the\n",
      "        corresponding values in each of those bins:\n",
      "        \n",
      "        >>> values = [1.0, 1.0, 2.0, 1.5, 3.0]\n",
      "        >>> stats.binned_statistic([1, 1, 2, 5, 7], values, 'sum', bins=2)\n",
      "        BinnedStatisticResult(statistic=array([4. , 4.5]), bin_edges=array([1., 4., 7.]), binnumber=array([1, 1, 1, 2, 2]))\n",
      "        \n",
      "        Multiple arrays of values can also be passed.  The statistic is calculated\n",
      "        on each set independently:\n",
      "        \n",
      "        >>> values = [[1.0, 1.0, 2.0, 1.5, 3.0], [2.0, 2.0, 4.0, 3.0, 6.0]]\n",
      "        >>> stats.binned_statistic([1, 1, 2, 5, 7], values, 'sum', bins=2)\n",
      "        BinnedStatisticResult(statistic=array([[4. , 4.5],\n",
      "               [8. , 9. ]]), bin_edges=array([1., 4., 7.]), binnumber=array([1, 1, 1, 2, 2]))\n",
      "        \n",
      "        >>> stats.binned_statistic([1, 2, 1, 2, 4], np.arange(5), statistic='mean',\n",
      "        ...                        bins=3)\n",
      "        BinnedStatisticResult(statistic=array([1., 2., 4.]), bin_edges=array([1., 2., 3., 4.]), binnumber=array([1, 2, 1, 2, 3]))\n",
      "        \n",
      "        As a second example, we now generate some random data of sailing boat speed\n",
      "        as a function of wind speed, and then determine how fast our boat is for\n",
      "        certain wind speeds:\n",
      "        \n",
      "        >>> windspeed = 8 * np.random.rand(500)\n",
      "        >>> boatspeed = .3 * windspeed**.5 + .2 * np.random.rand(500)\n",
      "        >>> bin_means, bin_edges, binnumber = stats.binned_statistic(windspeed,\n",
      "        ...                 boatspeed, statistic='median', bins=[1,2,3,4,5,6,7])\n",
      "        >>> plt.figure()\n",
      "        >>> plt.plot(windspeed, boatspeed, 'b.', label='raw data')\n",
      "        >>> plt.hlines(bin_means, bin_edges[:-1], bin_edges[1:], colors='g', lw=5,\n",
      "        ...            label='binned statistic of data')\n",
      "        >>> plt.legend()\n",
      "        \n",
      "        Now we can use ``binnumber`` to select all datapoints with a windspeed\n",
      "        below 1:\n",
      "        \n",
      "        >>> low_boatspeed = boatspeed[binnumber == 0]\n",
      "        \n",
      "        As a final example, we will use ``bin_edges`` and ``binnumber`` to make a\n",
      "        plot of a distribution that shows the mean and distribution around that\n",
      "        mean per bin, on top of a regular histogram and the probability\n",
      "        distribution function:\n",
      "        \n",
      "        >>> x = np.linspace(0, 5, num=500)\n",
      "        >>> x_pdf = stats.maxwell.pdf(x)\n",
      "        >>> samples = stats.maxwell.rvs(size=10000)\n",
      "        \n",
      "        >>> bin_means, bin_edges, binnumber = stats.binned_statistic(x, x_pdf,\n",
      "        ...         statistic='mean', bins=25)\n",
      "        >>> bin_width = (bin_edges[1] - bin_edges[0])\n",
      "        >>> bin_centers = bin_edges[1:] - bin_width/2\n",
      "        \n",
      "        >>> plt.figure()\n",
      "        >>> plt.hist(samples, bins=50, density=True, histtype='stepfilled',\n",
      "        ...          alpha=0.2, label='histogram of data')\n",
      "        >>> plt.plot(x, x_pdf, 'r-', label='analytical pdf')\n",
      "        >>> plt.hlines(bin_means, bin_edges[:-1], bin_edges[1:], colors='g', lw=2,\n",
      "        ...            label='binned statistic of data')\n",
      "        >>> plt.plot((binnumber - 0.5) * bin_width, x_pdf, 'g.', alpha=0.5)\n",
      "        >>> plt.legend(fontsize=10)\n",
      "        >>> plt.show()\n",
      "    \n",
      "    binned_statistic_2d(x, y, values, statistic='mean', bins=10, range=None, expand_binnumbers=False)\n",
      "        Compute a bidimensional binned statistic for one or more sets of data.\n",
      "        \n",
      "        This is a generalization of a histogram2d function.  A histogram divides\n",
      "        the space into bins, and returns the count of the number of points in\n",
      "        each bin.  This function allows the computation of the sum, mean, median,\n",
      "        or other statistic of the values (or set of values) within each bin.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : (N,) array_like\n",
      "            A sequence of values to be binned along the first dimension.\n",
      "        y : (N,) array_like\n",
      "            A sequence of values to be binned along the second dimension.\n",
      "        values : (N,) array_like or list of (N,) array_like\n",
      "            The data on which the statistic will be computed.  This must be\n",
      "            the same shape as `x`, or a list of sequences - each with the same\n",
      "            shape as `x`.  If `values` is such a list, the statistic will be\n",
      "            computed on each independently.\n",
      "        statistic : string or callable, optional\n",
      "            The statistic to compute (default is 'mean').\n",
      "            The following statistics are available:\n",
      "        \n",
      "              * 'mean' : compute the mean of values for points within each bin.\n",
      "                Empty bins will be represented by NaN.\n",
      "              * 'std' : compute the standard deviation within each bin. This\n",
      "                is implicitly calculated with ddof=0.\n",
      "              * 'median' : compute the median of values for points within each\n",
      "                bin. Empty bins will be represented by NaN.\n",
      "              * 'count' : compute the count of points within each bin.  This is\n",
      "                identical to an unweighted histogram.  `values` array is not\n",
      "                referenced.\n",
      "              * 'sum' : compute the sum of values for points within each bin.\n",
      "                This is identical to a weighted histogram.\n",
      "              * 'min' : compute the minimum of values for points within each bin.\n",
      "                Empty bins will be represented by NaN.\n",
      "              * 'max' : compute the maximum of values for point within each bin.\n",
      "                Empty bins will be represented by NaN.\n",
      "              * function : a user-defined function which takes a 1D array of\n",
      "                values, and outputs a single numerical statistic. This function\n",
      "                will be called on the values in each bin.  Empty bins will be\n",
      "                represented by function([]), or NaN if this returns an error.\n",
      "        \n",
      "        bins : int or [int, int] or array_like or [array, array], optional\n",
      "            The bin specification:\n",
      "        \n",
      "              * the number of bins for the two dimensions (nx = ny = bins),\n",
      "              * the number of bins in each dimension (nx, ny = bins),\n",
      "              * the bin edges for the two dimensions (x_edge = y_edge = bins),\n",
      "              * the bin edges in each dimension (x_edge, y_edge = bins).\n",
      "        \n",
      "            If the bin edges are specified, the number of bins will be,\n",
      "            (nx = len(x_edge)-1, ny = len(y_edge)-1).\n",
      "        \n",
      "        range : (2,2) array_like, optional\n",
      "            The leftmost and rightmost edges of the bins along each dimension\n",
      "            (if not specified explicitly in the `bins` parameters):\n",
      "            [[xmin, xmax], [ymin, ymax]]. All values outside of this range will be\n",
      "            considered outliers and not tallied in the histogram.\n",
      "        expand_binnumbers : bool, optional\n",
      "            'False' (default): the returned `binnumber` is a shape (N,) array of\n",
      "            linearized bin indices.\n",
      "            'True': the returned `binnumber` is 'unraveled' into a shape (2,N)\n",
      "            ndarray, where each row gives the bin numbers in the corresponding\n",
      "            dimension.\n",
      "            See the `binnumber` returned value, and the `Examples` section.\n",
      "        \n",
      "            .. versionadded:: 0.17.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : (nx, ny) ndarray\n",
      "            The values of the selected statistic in each two-dimensional bin.\n",
      "        x_edge : (nx + 1) ndarray\n",
      "            The bin edges along the first dimension.\n",
      "        y_edge : (ny + 1) ndarray\n",
      "            The bin edges along the second dimension.\n",
      "        binnumber : (N,) array of ints or (2,N) ndarray of ints\n",
      "            This assigns to each element of `sample` an integer that represents the\n",
      "            bin in which this observation falls.  The representation depends on the\n",
      "            `expand_binnumbers` argument.  See `Notes` for details.\n",
      "        \n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        numpy.digitize, numpy.histogram2d, binned_statistic, binned_statistic_dd\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Binedges:\n",
      "        All but the last (righthand-most) bin is half-open.  In other words, if\n",
      "        `bins` is ``[1, 2, 3, 4]``, then the first bin is ``[1, 2)`` (including 1,\n",
      "        but excluding 2) and the second ``[2, 3)``.  The last bin, however, is\n",
      "        ``[3, 4]``, which *includes* 4.\n",
      "        \n",
      "        `binnumber`:\n",
      "        This returned argument assigns to each element of `sample` an integer that\n",
      "        represents the bin in which it belongs.  The representation depends on the\n",
      "        `expand_binnumbers` argument. If 'False' (default): The returned\n",
      "        `binnumber` is a shape (N,) array of linearized indices mapping each\n",
      "        element of `sample` to its corresponding bin (using row-major ordering).\n",
      "        If 'True': The returned `binnumber` is a shape (2,N) ndarray where\n",
      "        each row indicates bin placements for each dimension respectively.  In each\n",
      "        dimension, a binnumber of `i` means the corresponding value is between\n",
      "        (D_edge[i-1], D_edge[i]), where 'D' is either 'x' or 'y'.\n",
      "        \n",
      "        .. versionadded:: 0.11.0\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        \n",
      "        Calculate the counts with explicit bin-edges:\n",
      "        \n",
      "        >>> x = [0.1, 0.1, 0.1, 0.6]\n",
      "        >>> y = [2.1, 2.6, 2.1, 2.1]\n",
      "        >>> binx = [0.0, 0.5, 1.0]\n",
      "        >>> biny = [2.0, 2.5, 3.0]\n",
      "        >>> ret = stats.binned_statistic_2d(x, y, x, 'count', bins=[binx,biny])\n",
      "        >>> ret.statistic\n",
      "        array([[2., 1.],\n",
      "               [1., 0.]])\n",
      "        \n",
      "        The bin in which each sample is placed is given by the `binnumber`\n",
      "        returned parameter.  By default, these are the linearized bin indices:\n",
      "        \n",
      "        >>> ret.binnumber\n",
      "        array([5, 6, 5, 9])\n",
      "        \n",
      "        The bin indices can also be expanded into separate entries for each\n",
      "        dimension using the `expand_binnumbers` parameter:\n",
      "        \n",
      "        >>> ret = stats.binned_statistic_2d(x, y, x, 'count', bins=[binx,biny],\n",
      "        ...                                 expand_binnumbers=True)\n",
      "        >>> ret.binnumber\n",
      "        array([[1, 1, 1, 2],\n",
      "               [1, 2, 1, 1]])\n",
      "        \n",
      "        Which shows that the first three elements belong in the xbin 1, and the\n",
      "        fourth into xbin 2; and so on for y.\n",
      "    \n",
      "    binned_statistic_dd(sample, values, statistic='mean', bins=10, range=None, expand_binnumbers=False, binned_statistic_result=None)\n",
      "        Compute a multidimensional binned statistic for a set of data.\n",
      "        \n",
      "        This is a generalization of a histogramdd function.  A histogram divides\n",
      "        the space into bins, and returns the count of the number of points in\n",
      "        each bin.  This function allows the computation of the sum, mean, median,\n",
      "        or other statistic of the values within each bin.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        sample : array_like\n",
      "            Data to histogram passed as a sequence of N arrays of length D, or\n",
      "            as an (N,D) array.\n",
      "        values : (N,) array_like or list of (N,) array_like\n",
      "            The data on which the statistic will be computed.  This must be\n",
      "            the same shape as `sample`, or a list of sequences - each with the\n",
      "            same shape as `sample`.  If `values` is such a list, the statistic\n",
      "            will be computed on each independently.\n",
      "        statistic : string or callable, optional\n",
      "            The statistic to compute (default is 'mean').\n",
      "            The following statistics are available:\n",
      "        \n",
      "              * 'mean' : compute the mean of values for points within each bin.\n",
      "                Empty bins will be represented by NaN.\n",
      "              * 'median' : compute the median of values for points within each\n",
      "                bin. Empty bins will be represented by NaN.\n",
      "              * 'count' : compute the count of points within each bin.  This is\n",
      "                identical to an unweighted histogram.  `values` array is not\n",
      "                referenced.\n",
      "              * 'sum' : compute the sum of values for points within each bin.\n",
      "                This is identical to a weighted histogram.\n",
      "              * 'std' : compute the standard deviation within each bin. This\n",
      "                is implicitly calculated with ddof=0.\n",
      "              * 'min' : compute the minimum of values for points within each bin.\n",
      "                Empty bins will be represented by NaN.\n",
      "              * 'max' : compute the maximum of values for point within each bin.\n",
      "                Empty bins will be represented by NaN.\n",
      "              * function : a user-defined function which takes a 1D array of\n",
      "                values, and outputs a single numerical statistic. This function\n",
      "                will be called on the values in each bin.  Empty bins will be\n",
      "                represented by function([]), or NaN if this returns an error.\n",
      "        \n",
      "        bins : sequence or positive int, optional\n",
      "            The bin specification must be in one of the following forms:\n",
      "        \n",
      "              * A sequence of arrays describing the bin edges along each dimension.\n",
      "              * The number of bins for each dimension (nx, ny, ... = bins).\n",
      "              * The number of bins for all dimensions (nx = ny = ... = bins).\n",
      "        range : sequence, optional\n",
      "            A sequence of lower and upper bin edges to be used if the edges are\n",
      "            not given explicitly in `bins`. Defaults to the minimum and maximum\n",
      "            values along each dimension.\n",
      "        expand_binnumbers : bool, optional\n",
      "            'False' (default): the returned `binnumber` is a shape (N,) array of\n",
      "            linearized bin indices.\n",
      "            'True': the returned `binnumber` is 'unraveled' into a shape (D,N)\n",
      "            ndarray, where each row gives the bin numbers in the corresponding\n",
      "            dimension.\n",
      "            See the `binnumber` returned value, and the `Examples` section of\n",
      "            `binned_statistic_2d`.\n",
      "        binned_statistic_result : binnedStatisticddResult\n",
      "            Result of a previous call to the function in order to reuse bin edges\n",
      "            and bin numbers with new values and/or a different statistic.\n",
      "            To reuse bin numbers, `expand_binnumbers` must have been set to False\n",
      "            (the default)\n",
      "        \n",
      "            .. versionadded:: 0.17.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : ndarray, shape(nx1, nx2, nx3,...)\n",
      "            The values of the selected statistic in each two-dimensional bin.\n",
      "        bin_edges : list of ndarrays\n",
      "            A list of D arrays describing the (nxi + 1) bin edges for each\n",
      "            dimension.\n",
      "        binnumber : (N,) array of ints or (D,N) ndarray of ints\n",
      "            This assigns to each element of `sample` an integer that represents the\n",
      "            bin in which this observation falls.  The representation depends on the\n",
      "            `expand_binnumbers` argument.  See `Notes` for details.\n",
      "        \n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        numpy.digitize, numpy.histogramdd, binned_statistic, binned_statistic_2d\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Binedges:\n",
      "        All but the last (righthand-most) bin is half-open in each dimension.  In\n",
      "        other words, if `bins` is ``[1, 2, 3, 4]``, then the first bin is\n",
      "        ``[1, 2)`` (including 1, but excluding 2) and the second ``[2, 3)``.  The\n",
      "        last bin, however, is ``[3, 4]``, which *includes* 4.\n",
      "        \n",
      "        `binnumber`:\n",
      "        This returned argument assigns to each element of `sample` an integer that\n",
      "        represents the bin in which it belongs.  The representation depends on the\n",
      "        `expand_binnumbers` argument. If 'False' (default): The returned\n",
      "        `binnumber` is a shape (N,) array of linearized indices mapping each\n",
      "        element of `sample` to its corresponding bin (using row-major ordering).\n",
      "        If 'True': The returned `binnumber` is a shape (D,N) ndarray where\n",
      "        each row indicates bin placements for each dimension respectively.  In each\n",
      "        dimension, a binnumber of `i` means the corresponding value is between\n",
      "        (bin_edges[D][i-1], bin_edges[D][i]), for each dimension 'D'.\n",
      "        \n",
      "        .. versionadded:: 0.11.0\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> from mpl_toolkits.mplot3d import Axes3D\n",
      "        \n",
      "        Take an array of 600 (x, y) coordinates as an example.\n",
      "        `binned_statistic_dd` can handle arrays of higher dimension `D`. But a plot\n",
      "        of dimension `D+1` is required.\n",
      "        \n",
      "        >>> mu = np.array([0., 1.])\n",
      "        >>> sigma = np.array([[1., -0.5],[-0.5, 1.5]])\n",
      "        >>> multinormal = stats.multivariate_normal(mu, sigma)\n",
      "        >>> data = multinormal.rvs(size=600, random_state=235412)\n",
      "        >>> data.shape\n",
      "        (600, 2)\n",
      "        \n",
      "        Create bins and count how many arrays fall in each bin:\n",
      "        \n",
      "        >>> N = 60\n",
      "        >>> x = np.linspace(-3, 3, N)\n",
      "        >>> y = np.linspace(-3, 4, N)\n",
      "        >>> ret = stats.binned_statistic_dd(data, np.arange(600), bins=[x, y],\n",
      "        ...                                 statistic='count')\n",
      "        >>> bincounts = ret.statistic\n",
      "        \n",
      "        Set the volume and the location of bars:\n",
      "        \n",
      "        >>> dx = x[1] - x[0]\n",
      "        >>> dy = y[1] - y[0]\n",
      "        >>> x, y = np.meshgrid(x[:-1]+dx/2, y[:-1]+dy/2)\n",
      "        >>> z = 0\n",
      "        \n",
      "        >>> bincounts = bincounts.ravel()\n",
      "        >>> x = x.ravel()\n",
      "        >>> y = y.ravel()\n",
      "        \n",
      "        >>> fig = plt.figure()\n",
      "        >>> ax = fig.add_subplot(111, projection='3d')\n",
      "        >>> with np.errstate(divide='ignore'):   # silence random axes3d warning\n",
      "        ...     ax.bar3d(x, y, z, dx, dy, bincounts)\n",
      "        \n",
      "        Reuse bin numbers and bin edges with new values:\n",
      "        \n",
      "        >>> ret2 = stats.binned_statistic_dd(data, -np.arange(600),\n",
      "        ...                                  binned_statistic_result=ret,\n",
      "        ...                                  statistic='mean')\n",
      "    \n",
      "    binom_test(x, n=None, p=0.5, alternative='two-sided')\n",
      "        Perform a test that the probability of success is p.\n",
      "        \n",
      "        This is an exact, two-sided test of the null hypothesis\n",
      "        that the probability of success in a Bernoulli experiment\n",
      "        is `p`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : int or array_like\n",
      "            The number of successes, or if x has length 2, it is the\n",
      "            number of successes and the number of failures.\n",
      "        n : int\n",
      "            The number of trials.  This is ignored if x gives both the\n",
      "            number of successes and failures.\n",
      "        p : float, optional\n",
      "            The hypothesized probability of success.  ``0 <= p <= 1``. The\n",
      "            default value is ``p = 0.5``.\n",
      "        alternative : {'two-sided', 'greater', 'less'}, optional\n",
      "            Indicates the alternative hypothesis. The default value is\n",
      "            'two-sided'.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        p-value : float\n",
      "            The p-value of the hypothesis test.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] https://en.wikipedia.org/wiki/Binomial_test\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        \n",
      "        A car manufacturer claims that no more than 10% of their cars are unsafe.\n",
      "        15 cars are inspected for safety, 3 were found to be unsafe. Test the\n",
      "        manufacturer's claim:\n",
      "        \n",
      "        >>> stats.binom_test(3, n=15, p=0.1, alternative='greater')\n",
      "        0.18406106910639114\n",
      "        \n",
      "        The null hypothesis cannot be rejected at the 5% level of significance\n",
      "        because the returned p-value is greater than the critical value of 5%.\n",
      "    \n",
      "    boxcox(x, lmbda=None, alpha=None)\n",
      "        Return a dataset transformed by a Box-Cox power transformation.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : ndarray\n",
      "            Input array.  Must be positive 1-dimensional.  Must not be constant.\n",
      "        lmbda : {None, scalar}, optional\n",
      "            If `lmbda` is not None, do the transformation for that value.\n",
      "        \n",
      "            If `lmbda` is None, find the lambda that maximizes the log-likelihood\n",
      "            function and return it as the second output argument.\n",
      "        alpha : {None, float}, optional\n",
      "            If ``alpha`` is not None, return the ``100 * (1-alpha)%`` confidence\n",
      "            interval for `lmbda` as the third output argument.\n",
      "            Must be between 0.0 and 1.0.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        boxcox : ndarray\n",
      "            Box-Cox power transformed array.\n",
      "        maxlog : float, optional\n",
      "            If the `lmbda` parameter is None, the second returned argument is\n",
      "            the lambda that maximizes the log-likelihood function.\n",
      "        (min_ci, max_ci) : tuple of float, optional\n",
      "            If `lmbda` parameter is None and ``alpha`` is not None, this returned\n",
      "            tuple of floats represents the minimum and maximum confidence limits\n",
      "            given ``alpha``.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        probplot, boxcox_normplot, boxcox_normmax, boxcox_llf\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The Box-Cox transform is given by::\n",
      "        \n",
      "            y = (x**lmbda - 1) / lmbda,  for lmbda > 0\n",
      "                log(x),                  for lmbda = 0\n",
      "        \n",
      "        `boxcox` requires the input data to be positive.  Sometimes a Box-Cox\n",
      "        transformation provides a shift parameter to achieve this; `boxcox` does\n",
      "        not.  Such a shift parameter is equivalent to adding a positive constant to\n",
      "        `x` before calling `boxcox`.\n",
      "        \n",
      "        The confidence limits returned when ``alpha`` is provided give the interval\n",
      "        where:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            llf(\\hat{\\lambda}) - llf(\\lambda) < \\frac{1}{2}\\chi^2(1 - \\alpha, 1),\n",
      "        \n",
      "        with ``llf`` the log-likelihood function and :math:`\\chi^2` the chi-squared\n",
      "        function.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        G.E.P. Box and D.R. Cox, \"An Analysis of Transformations\", Journal of the\n",
      "        Royal Statistical Society B, 26, 211-252 (1964).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        \n",
      "        We generate some random variates from a non-normal distribution and make a\n",
      "        probability plot for it, to show it is non-normal in the tails:\n",
      "        \n",
      "        >>> fig = plt.figure()\n",
      "        >>> ax1 = fig.add_subplot(211)\n",
      "        >>> x = stats.loggamma.rvs(5, size=500) + 5\n",
      "        >>> prob = stats.probplot(x, dist=stats.norm, plot=ax1)\n",
      "        >>> ax1.set_xlabel('')\n",
      "        >>> ax1.set_title('Probplot against normal distribution')\n",
      "        \n",
      "        We now use `boxcox` to transform the data so it's closest to normal:\n",
      "        \n",
      "        >>> ax2 = fig.add_subplot(212)\n",
      "        >>> xt, _ = stats.boxcox(x)\n",
      "        >>> prob = stats.probplot(xt, dist=stats.norm, plot=ax2)\n",
      "        >>> ax2.set_title('Probplot after Box-Cox transformation')\n",
      "        \n",
      "        >>> plt.show()\n",
      "    \n",
      "    boxcox_llf(lmb, data)\n",
      "        The boxcox log-likelihood function.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        lmb : scalar\n",
      "            Parameter for Box-Cox transformation.  See `boxcox` for details.\n",
      "        data : array_like\n",
      "            Data to calculate Box-Cox log-likelihood for.  If `data` is\n",
      "            multi-dimensional, the log-likelihood is calculated along the first\n",
      "            axis.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        llf : float or ndarray\n",
      "            Box-Cox log-likelihood of `data` given `lmb`.  A float for 1-D `data`,\n",
      "            an array otherwise.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        boxcox, probplot, boxcox_normplot, boxcox_normmax\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The Box-Cox log-likelihood function is defined here as\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            llf = (\\lambda - 1) \\sum_i(\\log(x_i)) -\n",
      "                  N/2 \\log(\\sum_i (y_i - \\bar{y})^2 / N),\n",
      "        \n",
      "        where ``y`` is the Box-Cox transformed input data ``x``.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
      "        >>> np.random.seed(1245)\n",
      "        \n",
      "        Generate some random variates and calculate Box-Cox log-likelihood values\n",
      "        for them for a range of ``lmbda`` values:\n",
      "        \n",
      "        >>> x = stats.loggamma.rvs(5, loc=10, size=1000)\n",
      "        >>> lmbdas = np.linspace(-2, 10)\n",
      "        >>> llf = np.zeros(lmbdas.shape, dtype=float)\n",
      "        >>> for ii, lmbda in enumerate(lmbdas):\n",
      "        ...     llf[ii] = stats.boxcox_llf(lmbda, x)\n",
      "        \n",
      "        Also find the optimal lmbda value with `boxcox`:\n",
      "        \n",
      "        >>> x_most_normal, lmbda_optimal = stats.boxcox(x)\n",
      "        \n",
      "        Plot the log-likelihood as function of lmbda.  Add the optimal lmbda as a\n",
      "        horizontal line to check that that's really the optimum:\n",
      "        \n",
      "        >>> fig = plt.figure()\n",
      "        >>> ax = fig.add_subplot(111)\n",
      "        >>> ax.plot(lmbdas, llf, 'b.-')\n",
      "        >>> ax.axhline(stats.boxcox_llf(lmbda_optimal, x), color='r')\n",
      "        >>> ax.set_xlabel('lmbda parameter')\n",
      "        >>> ax.set_ylabel('Box-Cox log-likelihood')\n",
      "        \n",
      "        Now add some probability plots to show that where the log-likelihood is\n",
      "        maximized the data transformed with `boxcox` looks closest to normal:\n",
      "        \n",
      "        >>> locs = [3, 10, 4]  # 'lower left', 'center', 'lower right'\n",
      "        >>> for lmbda, loc in zip([-1, lmbda_optimal, 9], locs):\n",
      "        ...     xt = stats.boxcox(x, lmbda=lmbda)\n",
      "        ...     (osm, osr), (slope, intercept, r_sq) = stats.probplot(xt)\n",
      "        ...     ax_inset = inset_axes(ax, width=\"20%\", height=\"20%\", loc=loc)\n",
      "        ...     ax_inset.plot(osm, osr, 'c.', osm, slope*osm + intercept, 'k-')\n",
      "        ...     ax_inset.set_xticklabels([])\n",
      "        ...     ax_inset.set_yticklabels([])\n",
      "        ...     ax_inset.set_title(r'$\\lambda=%1.2f$' % lmbda)\n",
      "        \n",
      "        >>> plt.show()\n",
      "    \n",
      "    boxcox_normmax(x, brack=(-2.0, 2.0), method='pearsonr')\n",
      "        Compute optimal Box-Cox transform parameter for input data.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Input array.\n",
      "        brack : 2-tuple, optional\n",
      "            The starting interval for a downhill bracket search with\n",
      "            `optimize.brent`.  Note that this is in most cases not critical; the\n",
      "            final result is allowed to be outside this bracket.\n",
      "        method : str, optional\n",
      "            The method to determine the optimal transform parameter (`boxcox`\n",
      "            ``lmbda`` parameter). Options are:\n",
      "        \n",
      "            'pearsonr'  (default)\n",
      "                Maximizes the Pearson correlation coefficient between\n",
      "                ``y = boxcox(x)`` and the expected values for ``y`` if `x` would be\n",
      "                normally-distributed.\n",
      "        \n",
      "            'mle'\n",
      "                Minimizes the log-likelihood `boxcox_llf`.  This is the method used\n",
      "                in `boxcox`.\n",
      "        \n",
      "            'all'\n",
      "                Use all optimization methods available, and return all results.\n",
      "                Useful to compare different methods.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        maxlog : float or ndarray\n",
      "            The optimal transform parameter found.  An array instead of a scalar\n",
      "            for ``method='all'``.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        boxcox, boxcox_llf, boxcox_normplot\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> np.random.seed(1234)  # make this example reproducible\n",
      "        \n",
      "        Generate some data and determine optimal ``lmbda`` in various ways:\n",
      "        \n",
      "        >>> x = stats.loggamma.rvs(5, size=30) + 5\n",
      "        >>> y, lmax_mle = stats.boxcox(x)\n",
      "        >>> lmax_pearsonr = stats.boxcox_normmax(x)\n",
      "        \n",
      "        >>> lmax_mle\n",
      "        7.177...\n",
      "        >>> lmax_pearsonr\n",
      "        7.916...\n",
      "        >>> stats.boxcox_normmax(x, method='all')\n",
      "        array([ 7.91667384,  7.17718692])\n",
      "        \n",
      "        >>> fig = plt.figure()\n",
      "        >>> ax = fig.add_subplot(111)\n",
      "        >>> prob = stats.boxcox_normplot(x, -10, 10, plot=ax)\n",
      "        >>> ax.axvline(lmax_mle, color='r')\n",
      "        >>> ax.axvline(lmax_pearsonr, color='g', ls='--')\n",
      "        \n",
      "        >>> plt.show()\n",
      "    \n",
      "    boxcox_normplot(x, la, lb, plot=None, N=80)\n",
      "        Compute parameters for a Box-Cox normality plot, optionally show it.\n",
      "        \n",
      "        A Box-Cox normality plot shows graphically what the best transformation\n",
      "        parameter is to use in `boxcox` to obtain a distribution that is close\n",
      "        to normal.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Input array.\n",
      "        la, lb : scalar\n",
      "            The lower and upper bounds for the ``lmbda`` values to pass to `boxcox`\n",
      "            for Box-Cox transformations.  These are also the limits of the\n",
      "            horizontal axis of the plot if that is generated.\n",
      "        plot : object, optional\n",
      "            If given, plots the quantiles and least squares fit.\n",
      "            `plot` is an object that has to have methods \"plot\" and \"text\".\n",
      "            The `matplotlib.pyplot` module or a Matplotlib Axes object can be used,\n",
      "            or a custom object with the same methods.\n",
      "            Default is None, which means that no plot is created.\n",
      "        N : int, optional\n",
      "            Number of points on the horizontal axis (equally distributed from\n",
      "            `la` to `lb`).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        lmbdas : ndarray\n",
      "            The ``lmbda`` values for which a Box-Cox transform was done.\n",
      "        ppcc : ndarray\n",
      "            Probability Plot Correlelation Coefficient, as obtained from `probplot`\n",
      "            when fitting the Box-Cox transformed input `x` against a normal\n",
      "            distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        probplot, boxcox, boxcox_normmax, boxcox_llf, ppcc_max\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Even if `plot` is given, the figure is not shown or saved by\n",
      "        `boxcox_normplot`; ``plt.show()`` or ``plt.savefig('figname.png')``\n",
      "        should be used after calling `probplot`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        \n",
      "        Generate some non-normally distributed data, and create a Box-Cox plot:\n",
      "        \n",
      "        >>> x = stats.loggamma.rvs(5, size=500) + 5\n",
      "        >>> fig = plt.figure()\n",
      "        >>> ax = fig.add_subplot(111)\n",
      "        >>> prob = stats.boxcox_normplot(x, -20, 20, plot=ax)\n",
      "        \n",
      "        Determine and plot the optimal ``lmbda`` to transform ``x`` and plot it in\n",
      "        the same plot:\n",
      "        \n",
      "        >>> _, maxlog = stats.boxcox(x)\n",
      "        >>> ax.axvline(maxlog, color='r')\n",
      "        \n",
      "        >>> plt.show()\n",
      "    \n",
      "    brunnermunzel(x, y, alternative='two-sided', distribution='t', nan_policy='propagate')\n",
      "        Compute the Brunner-Munzel test on samples x and y.\n",
      "        \n",
      "        The Brunner-Munzel test is a nonparametric test of the null hypothesis that\n",
      "        when values are taken one by one from each group, the probabilities of\n",
      "        getting large values in both groups are equal.\n",
      "        Unlike the Wilcoxon-Mann-Whitney's U test, this does not require the\n",
      "        assumption of equivariance of two groups. Note that this does not assume\n",
      "        the distributions are same. This test works on two independent samples,\n",
      "        which may have different sizes.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x, y : array_like\n",
      "            Array of samples, should be one-dimensional.\n",
      "        alternative : {'two-sided', 'less', 'greater'}, optional\n",
      "            Defines the alternative hypothesis.\n",
      "            The following options are available (default is 'two-sided'):\n",
      "        \n",
      "              * 'two-sided'\n",
      "              * 'less': one-sided\n",
      "              * 'greater': one-sided\n",
      "        distribution : {'t', 'normal'}, optional\n",
      "            Defines how to get the p-value.\n",
      "            The following options are available (default is 't'):\n",
      "        \n",
      "              * 't': get the p-value by t-distribution\n",
      "              * 'normal': get the p-value by standard normal distribution.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan.\n",
      "            The following options are available (default is 'propagate'):\n",
      "        \n",
      "              * 'propagate': returns nan\n",
      "              * 'raise': throws an error\n",
      "              * 'omit': performs the calculations ignoring nan values\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float\n",
      "            The Brunner-Munzer W statistic.\n",
      "        pvalue : float\n",
      "            p-value assuming an t distribution. One-sided or\n",
      "            two-sided, depending on the choice of `alternative` and `distribution`.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        mannwhitneyu : Mann-Whitney rank test on two samples.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Brunner and Munzel recommended to estimate the p-value by t-distribution\n",
      "        when the size of data is 50 or less. If the size is lower than 10, it would\n",
      "        be better to use permuted Brunner Munzel test (see [2]_).\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Brunner, E. and Munzel, U. \"The nonparametric Benhrens-Fisher\n",
      "               problem: Asymptotic theory and a small-sample approximation\".\n",
      "               Biometrical Journal. Vol. 42(2000): 17-25.\n",
      "        .. [2] Neubert, K. and Brunner, E. \"A studentized permutation test for the\n",
      "               non-parametric Behrens-Fisher problem\". Computational Statistics and\n",
      "               Data Analysis. Vol. 51(2007): 5192-5204.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> x1 = [1,2,1,1,1,1,1,1,1,1,2,4,1,1]\n",
      "        >>> x2 = [3,3,4,3,1,2,3,1,1,5,4]\n",
      "        >>> w, p_value = stats.brunnermunzel(x1, x2)\n",
      "        >>> w\n",
      "        3.1374674823029505\n",
      "        >>> p_value\n",
      "        0.0057862086661515377\n",
      "    \n",
      "    chi2_contingency(observed, correction=True, lambda_=None)\n",
      "        Chi-square test of independence of variables in a contingency table.\n",
      "        \n",
      "        This function computes the chi-square statistic and p-value for the\n",
      "        hypothesis test of independence of the observed frequencies in the\n",
      "        contingency table [1]_ `observed`.  The expected frequencies are computed\n",
      "        based on the marginal sums under the assumption of independence; see\n",
      "        `scipy.stats.contingency.expected_freq`.  The number of degrees of\n",
      "        freedom is (expressed using numpy functions and attributes)::\n",
      "        \n",
      "            dof = observed.size - sum(observed.shape) + observed.ndim - 1\n",
      "        \n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        observed : array_like\n",
      "            The contingency table. The table contains the observed frequencies\n",
      "            (i.e. number of occurrences) in each category.  In the two-dimensional\n",
      "            case, the table is often described as an \"R x C table\".\n",
      "        correction : bool, optional\n",
      "            If True, *and* the degrees of freedom is 1, apply Yates' correction\n",
      "            for continuity.  The effect of the correction is to adjust each\n",
      "            observed value by 0.5 towards the corresponding expected value.\n",
      "        lambda_ : float or str, optional.\n",
      "            By default, the statistic computed in this test is Pearson's\n",
      "            chi-squared statistic [2]_.  `lambda_` allows a statistic from the\n",
      "            Cressie-Read power divergence family [3]_ to be used instead.  See\n",
      "            `power_divergence` for details.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        chi2 : float\n",
      "            The test statistic.\n",
      "        p : float\n",
      "            The p-value of the test\n",
      "        dof : int\n",
      "            Degrees of freedom\n",
      "        expected : ndarray, same shape as `observed`\n",
      "            The expected frequencies, based on the marginal sums of the table.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        contingency.expected_freq\n",
      "        fisher_exact\n",
      "        chisquare\n",
      "        power_divergence\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        An often quoted guideline for the validity of this calculation is that\n",
      "        the test should be used only if the observed and expected frequencies\n",
      "        in each cell are at least 5.\n",
      "        \n",
      "        This is a test for the independence of different categories of a\n",
      "        population. The test is only meaningful when the dimension of\n",
      "        `observed` is two or more.  Applying the test to a one-dimensional\n",
      "        table will always result in `expected` equal to `observed` and a\n",
      "        chi-square statistic equal to 0.\n",
      "        \n",
      "        This function does not handle masked arrays, because the calculation\n",
      "        does not make sense with missing values.\n",
      "        \n",
      "        Like stats.chisquare, this function computes a chi-square statistic;\n",
      "        the convenience this function provides is to figure out the expected\n",
      "        frequencies and degrees of freedom from the given contingency table.\n",
      "        If these were already known, and if the Yates' correction was not\n",
      "        required, one could use stats.chisquare.  That is, if one calls::\n",
      "        \n",
      "            chi2, p, dof, ex = chi2_contingency(obs, correction=False)\n",
      "        \n",
      "        then the following is true::\n",
      "        \n",
      "            (chi2, p) == stats.chisquare(obs.ravel(), f_exp=ex.ravel(),\n",
      "                                         ddof=obs.size - 1 - dof)\n",
      "        \n",
      "        The `lambda_` argument was added in version 0.13.0 of scipy.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] \"Contingency table\",\n",
      "               https://en.wikipedia.org/wiki/Contingency_table\n",
      "        .. [2] \"Pearson's chi-squared test\",\n",
      "               https://en.wikipedia.org/wiki/Pearson%27s_chi-squared_test\n",
      "        .. [3] Cressie, N. and Read, T. R. C., \"Multinomial Goodness-of-Fit\n",
      "               Tests\", J. Royal Stat. Soc. Series B, Vol. 46, No. 3 (1984),\n",
      "               pp. 440-464.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        A two-way example (2 x 3):\n",
      "        \n",
      "        >>> from scipy.stats import chi2_contingency\n",
      "        >>> obs = np.array([[10, 10, 20], [20, 20, 20]])\n",
      "        >>> chi2_contingency(obs)\n",
      "        (2.7777777777777777,\n",
      "         0.24935220877729619,\n",
      "         2,\n",
      "         array([[ 12.,  12.,  16.],\n",
      "                [ 18.,  18.,  24.]]))\n",
      "        \n",
      "        Perform the test using the log-likelihood ratio (i.e. the \"G-test\")\n",
      "        instead of Pearson's chi-squared statistic.\n",
      "        \n",
      "        >>> g, p, dof, expctd = chi2_contingency(obs, lambda_=\"log-likelihood\")\n",
      "        >>> g, p\n",
      "        (2.7688587616781319, 0.25046668010954165)\n",
      "        \n",
      "        A four-way example (2 x 2 x 2 x 2):\n",
      "        \n",
      "        >>> obs = np.array(\n",
      "        ...     [[[[12, 17],\n",
      "        ...        [11, 16]],\n",
      "        ...       [[11, 12],\n",
      "        ...        [15, 16]]],\n",
      "        ...      [[[23, 15],\n",
      "        ...        [30, 22]],\n",
      "        ...       [[14, 17],\n",
      "        ...        [15, 16]]]])\n",
      "        >>> chi2_contingency(obs)\n",
      "        (8.7584514426741897,\n",
      "         0.64417725029295503,\n",
      "         11,\n",
      "         array([[[[ 14.15462386,  14.15462386],\n",
      "                  [ 16.49423111,  16.49423111]],\n",
      "                 [[ 11.2461395 ,  11.2461395 ],\n",
      "                  [ 13.10500554,  13.10500554]]],\n",
      "                [[[ 19.5591166 ,  19.5591166 ],\n",
      "                  [ 22.79202844,  22.79202844]],\n",
      "                 [[ 15.54012004,  15.54012004],\n",
      "                  [ 18.10873492,  18.10873492]]]]))\n",
      "    \n",
      "    chisquare(f_obs, f_exp=None, ddof=0, axis=0)\n",
      "        Calculate a one-way chi-square test.\n",
      "        \n",
      "        The chi-square test tests the null hypothesis that the categorical data\n",
      "        has the given frequencies.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        f_obs : array_like\n",
      "            Observed frequencies in each category.\n",
      "        f_exp : array_like, optional\n",
      "            Expected frequencies in each category.  By default the categories are\n",
      "            assumed to be equally likely.\n",
      "        ddof : int, optional\n",
      "            \"Delta degrees of freedom\": adjustment to the degrees of freedom\n",
      "            for the p-value.  The p-value is computed using a chi-squared\n",
      "            distribution with ``k - 1 - ddof`` degrees of freedom, where `k`\n",
      "            is the number of observed frequencies.  The default value of `ddof`\n",
      "            is 0.\n",
      "        axis : int or None, optional\n",
      "            The axis of the broadcast result of `f_obs` and `f_exp` along which to\n",
      "            apply the test.  If axis is None, all values in `f_obs` are treated\n",
      "            as a single data set.  Default is 0.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        chisq : float or ndarray\n",
      "            The chi-squared test statistic.  The value is a float if `axis` is\n",
      "            None or `f_obs` and `f_exp` are 1-D.\n",
      "        p : float or ndarray\n",
      "            The p-value of the test.  The value is a float if `ddof` and the\n",
      "            return value `chisq` are scalars.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.stats.power_divergence\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This test is invalid when the observed or expected frequencies in each\n",
      "        category are too small.  A typical rule is that all of the observed\n",
      "        and expected frequencies should be at least 5.\n",
      "        \n",
      "        The default degrees of freedom, k-1, are for the case when no parameters\n",
      "        of the distribution are estimated. If p parameters are estimated by\n",
      "        efficient maximum likelihood then the correct degrees of freedom are\n",
      "        k-1-p. If the parameters are estimated in a different way, then the\n",
      "        dof can be between k-1-p and k-1. However, it is also possible that\n",
      "        the asymptotic distribution is not chi-square, in which case this test\n",
      "        is not appropriate.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Lowry, Richard.  \"Concepts and Applications of Inferential\n",
      "               Statistics\". Chapter 8.\n",
      "               https://web.archive.org/web/20171022032306/http://vassarstats.net:80/textbook/ch8pt1.html\n",
      "        .. [2] \"Chi-squared test\", https://en.wikipedia.org/wiki/Chi-squared_test\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        When just `f_obs` is given, it is assumed that the expected frequencies\n",
      "        are uniform and given by the mean of the observed frequencies.\n",
      "        \n",
      "        >>> from scipy.stats import chisquare\n",
      "        >>> chisquare([16, 18, 16, 14, 12, 12])\n",
      "        (2.0, 0.84914503608460956)\n",
      "        \n",
      "        With `f_exp` the expected frequencies can be given.\n",
      "        \n",
      "        >>> chisquare([16, 18, 16, 14, 12, 12], f_exp=[16, 16, 16, 16, 16, 8])\n",
      "        (3.5, 0.62338762774958223)\n",
      "        \n",
      "        When `f_obs` is 2-D, by default the test is applied to each column.\n",
      "        \n",
      "        >>> obs = np.array([[16, 18, 16, 14, 12, 12], [32, 24, 16, 28, 20, 24]]).T\n",
      "        >>> obs.shape\n",
      "        (6, 2)\n",
      "        >>> chisquare(obs)\n",
      "        (array([ 2.        ,  6.66666667]), array([ 0.84914504,  0.24663415]))\n",
      "        \n",
      "        By setting ``axis=None``, the test is applied to all data in the array,\n",
      "        which is equivalent to applying the test to the flattened array.\n",
      "        \n",
      "        >>> chisquare(obs, axis=None)\n",
      "        (23.31034482758621, 0.015975692534127565)\n",
      "        >>> chisquare(obs.ravel())\n",
      "        (23.31034482758621, 0.015975692534127565)\n",
      "        \n",
      "        `ddof` is the change to make to the default degrees of freedom.\n",
      "        \n",
      "        >>> chisquare([16, 18, 16, 14, 12, 12], ddof=1)\n",
      "        (2.0, 0.73575888234288467)\n",
      "        \n",
      "        The calculation of the p-values is done by broadcasting the\n",
      "        chi-squared statistic with `ddof`.\n",
      "        \n",
      "        >>> chisquare([16, 18, 16, 14, 12, 12], ddof=[0,1,2])\n",
      "        (2.0, array([ 0.84914504,  0.73575888,  0.5724067 ]))\n",
      "        \n",
      "        `f_obs` and `f_exp` are also broadcast.  In the following, `f_obs` has\n",
      "        shape (6,) and `f_exp` has shape (2, 6), so the result of broadcasting\n",
      "        `f_obs` and `f_exp` has shape (2, 6).  To compute the desired chi-squared\n",
      "        statistics, we use ``axis=1``:\n",
      "        \n",
      "        >>> chisquare([16, 18, 16, 14, 12, 12],\n",
      "        ...           f_exp=[[16, 16, 16, 16, 16, 8], [8, 20, 20, 16, 12, 12]],\n",
      "        ...           axis=1)\n",
      "        (array([ 3.5 ,  9.25]), array([ 0.62338763,  0.09949846]))\n",
      "    \n",
      "    circmean(samples, high=6.283185307179586, low=0, axis=None, nan_policy='propagate')\n",
      "        Compute the circular mean for samples in a range.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        samples : array_like\n",
      "            Input array.\n",
      "        high : float or int, optional\n",
      "            High boundary for circular mean range.  Default is ``2*pi``.\n",
      "        low : float or int, optional\n",
      "            Low boundary for circular mean range.  Default is 0.\n",
      "        axis : int, optional\n",
      "            Axis along which means are computed.  The default is to compute\n",
      "            the mean of the flattened array.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan. 'propagate' returns nan,\n",
      "            'raise' throws an error, 'omit' performs the calculations ignoring nan\n",
      "            values. Default is 'propagate'.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        circmean : float\n",
      "            Circular mean.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.stats import circmean\n",
      "        >>> circmean([0.1, 2*np.pi+0.2, 6*np.pi+0.3])\n",
      "        0.2\n",
      "        \n",
      "        >>> from scipy.stats import circmean\n",
      "        >>> circmean([0.2, 1.4, 2.6], high = 1, low = 0)\n",
      "        0.4\n",
      "    \n",
      "    circstd(samples, high=6.283185307179586, low=0, axis=None, nan_policy='propagate')\n",
      "        Compute the circular standard deviation for samples assumed to be in the\n",
      "        range [low to high].\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        samples : array_like\n",
      "            Input array.\n",
      "        high : float or int, optional\n",
      "            High boundary for circular standard deviation range.\n",
      "            Default is ``2*pi``.\n",
      "        low : float or int, optional\n",
      "            Low boundary for circular standard deviation range.  Default is 0.\n",
      "        axis : int, optional\n",
      "            Axis along which standard deviations are computed.  The default is\n",
      "            to compute the standard deviation of the flattened array.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan. 'propagate' returns nan,\n",
      "            'raise' throws an error, 'omit' performs the calculations ignoring nan\n",
      "            values. Default is 'propagate'.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        circstd : float\n",
      "            Circular standard deviation.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This uses a definition of circular standard deviation that in the limit of\n",
      "        small angles returns a number close to the 'linear' standard deviation.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.stats import circstd\n",
      "        >>> circstd([0, 0.1*np.pi/2, 0.001*np.pi, 0.03*np.pi/2])\n",
      "        0.063564063306\n",
      "    \n",
      "    circvar(samples, high=6.283185307179586, low=0, axis=None, nan_policy='propagate')\n",
      "        Compute the circular variance for samples assumed to be in a range.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        samples : array_like\n",
      "            Input array.\n",
      "        high : float or int, optional\n",
      "            High boundary for circular variance range.  Default is ``2*pi``.\n",
      "        low : float or int, optional\n",
      "            Low boundary for circular variance range.  Default is 0.\n",
      "        axis : int, optional\n",
      "            Axis along which variances are computed.  The default is to compute\n",
      "            the variance of the flattened array.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan. 'propagate' returns nan,\n",
      "            'raise' throws an error, 'omit' performs the calculations ignoring nan\n",
      "            values. Default is 'propagate'.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        circvar : float\n",
      "            Circular variance.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This uses a definition of circular variance that in the limit of small\n",
      "        angles returns a number close to the 'linear' variance.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.stats import circvar\n",
      "        >>> circvar([0, 2*np.pi/3, 5*np.pi/3])\n",
      "        2.19722457734\n",
      "    \n",
      "    combine_pvalues(pvalues, method='fisher', weights=None)\n",
      "        Combine p-values from independent tests bearing upon the same hypothesis.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        pvalues : array_like, 1-D\n",
      "            Array of p-values assumed to come from independent tests.\n",
      "        method : {'fisher', 'pearson', 'tippett', 'stouffer', 'mudholkar_george'}, optional\n",
      "            Name of method to use to combine p-values.\n",
      "            The following methods are available (default is 'fisher'):\n",
      "        \n",
      "              * 'fisher': Fisher's method (Fisher's combined probability test), the\n",
      "                sum of the logarithm of the p-values\n",
      "              * 'pearson': Pearson's method (similar to Fisher's but uses sum of the\n",
      "                complement of the p-values inside the logarithms)\n",
      "              * 'tippett': Tippett's method (minimum of p-values)\n",
      "              * 'stouffer': Stouffer's Z-score method\n",
      "              * 'mudholkar_george': the difference of Fisher's and Pearson's methods\n",
      "                divided by 2\n",
      "        weights : array_like, 1-D, optional\n",
      "            Optional array of weights used only for Stouffer's Z-score method.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic: float\n",
      "            The statistic calculated by the specified method.\n",
      "        pval: float\n",
      "            The combined p-value.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Fisher's method (also known as Fisher's combined probability test) [1]_ uses\n",
      "        a chi-squared statistic to compute a combined p-value. The closely related\n",
      "        Stouffer's Z-score method [2]_ uses Z-scores rather than p-values. The\n",
      "        advantage of Stouffer's method is that it is straightforward to introduce\n",
      "        weights, which can make Stouffer's method more powerful than Fisher's\n",
      "        method when the p-values are from studies of different size [6]_ [7]_.\n",
      "        The Pearson's method uses :math:`log(1-p_i)` inside the sum whereas Fisher's\n",
      "        method uses :math:`log(p_i)` [4]_. For Fisher's and Pearson's method, the\n",
      "        sum of the logarithms is multiplied by -2 in the implementation. This\n",
      "        quantity has a chi-square distribution that determines the p-value. The\n",
      "        `mudholkar_george` method is the difference of the Fisher's and Pearson's\n",
      "        test statistics, each of which include the -2 factor [4]_. However, the\n",
      "        `mudholkar_george` method does not include these -2 factors. The test\n",
      "        statistic of `mudholkar_george` is the sum of logisitic random variables and\n",
      "        equation 3.6 in [3]_ is used to approximate the p-value based on Student's\n",
      "        t-distribution.\n",
      "        \n",
      "        Fisher's method may be extended to combine p-values from dependent tests\n",
      "        [5]_. Extensions such as Brown's method and Kost's method are not currently\n",
      "        implemented.\n",
      "        \n",
      "        .. versionadded:: 0.15.0\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] https://en.wikipedia.org/wiki/Fisher%27s_method\n",
      "        .. [2] https://en.wikipedia.org/wiki/Fisher%27s_method#Relation_to_Stouffer.27s_Z-score_method\n",
      "        .. [3] George, E. O., and G. S. Mudholkar. \"On the convolution of logistic\n",
      "               random variables.\" Metrika 30.1 (1983): 1-13.\n",
      "        .. [4] Heard, N. and Rubin-Delanchey, P. \"Choosing between methods of\n",
      "               combining p-values.\"  Biometrika 105.1 (2018): 239-246.\n",
      "        .. [5] Whitlock, M. C. \"Combining probability from independent tests: the\n",
      "               weighted Z-method is superior to Fisher's approach.\" Journal of\n",
      "               Evolutionary Biology 18, no. 5 (2005): 1368-1373.\n",
      "        .. [6] Zaykin, Dmitri V. \"Optimally weighted Z-test is a powerful method\n",
      "               for combining probabilities in meta-analysis.\" Journal of\n",
      "               Evolutionary Biology 24, no. 8 (2011): 1836-1841.\n",
      "        .. [7] https://en.wikipedia.org/wiki/Extensions_of_Fisher%27s_method\n",
      "    \n",
      "    cumfreq(a, numbins=10, defaultreallimits=None, weights=None)\n",
      "        Return a cumulative frequency histogram, using the histogram function.\n",
      "        \n",
      "        A cumulative histogram is a mapping that counts the cumulative number of\n",
      "        observations in all of the bins up to the specified bin.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Input array.\n",
      "        numbins : int, optional\n",
      "            The number of bins to use for the histogram. Default is 10.\n",
      "        defaultreallimits : tuple (lower, upper), optional\n",
      "            The lower and upper values for the range of the histogram.\n",
      "            If no value is given, a range slightly larger than the range of the\n",
      "            values in `a` is used. Specifically ``(a.min() - s, a.max() + s)``,\n",
      "            where ``s = (1/2)(a.max() - a.min()) / (numbins - 1)``.\n",
      "        weights : array_like, optional\n",
      "            The weights for each value in `a`. Default is None, which gives each\n",
      "            value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        cumcount : ndarray\n",
      "            Binned values of cumulative frequency.\n",
      "        lowerlimit : float\n",
      "            Lower real limit\n",
      "        binsize : float\n",
      "            Width of each bin.\n",
      "        extrapoints : int\n",
      "            Extra points.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> from scipy import stats\n",
      "        >>> x = [1, 4, 2, 1, 3, 1]\n",
      "        >>> res = stats.cumfreq(x, numbins=4, defaultreallimits=(1.5, 5))\n",
      "        >>> res.cumcount\n",
      "        array([ 1.,  2.,  3.,  3.])\n",
      "        >>> res.extrapoints\n",
      "        3\n",
      "        \n",
      "        Create a normal distribution with 1000 random values\n",
      "        \n",
      "        >>> rng = np.random.RandomState(seed=12345)\n",
      "        >>> samples = stats.norm.rvs(size=1000, random_state=rng)\n",
      "        \n",
      "        Calculate cumulative frequencies\n",
      "        \n",
      "        >>> res = stats.cumfreq(samples, numbins=25)\n",
      "        \n",
      "        Calculate space of values for x\n",
      "        \n",
      "        >>> x = res.lowerlimit + np.linspace(0, res.binsize*res.cumcount.size,\n",
      "        ...                                  res.cumcount.size)\n",
      "        \n",
      "        Plot histogram and cumulative histogram\n",
      "        \n",
      "        >>> fig = plt.figure(figsize=(10, 4))\n",
      "        >>> ax1 = fig.add_subplot(1, 2, 1)\n",
      "        >>> ax2 = fig.add_subplot(1, 2, 2)\n",
      "        >>> ax1.hist(samples, bins=25)\n",
      "        >>> ax1.set_title('Histogram')\n",
      "        >>> ax2.bar(x, res.cumcount, width=res.binsize)\n",
      "        >>> ax2.set_title('Cumulative histogram')\n",
      "        >>> ax2.set_xlim([x.min(), x.max()])\n",
      "        \n",
      "        >>> plt.show()\n",
      "    \n",
      "    describe(a, axis=0, ddof=1, bias=True, nan_policy='propagate')\n",
      "        Compute several descriptive statistics of the passed array.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "           Input data.\n",
      "        axis : int or None, optional\n",
      "           Axis along which statistics are calculated. Default is 0.\n",
      "           If None, compute over the whole array `a`.\n",
      "        ddof : int, optional\n",
      "            Delta degrees of freedom (only for variance).  Default is 1.\n",
      "        bias : bool, optional\n",
      "            If False, then the skewness and kurtosis calculations are corrected for\n",
      "            statistical bias.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan.\n",
      "            The following options are available (default is 'propagate'):\n",
      "        \n",
      "              * 'propagate': returns nan\n",
      "              * 'raise': throws an error\n",
      "              * 'omit': performs the calculations ignoring nan values\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        nobs : int or ndarray of ints\n",
      "           Number of observations (length of data along `axis`).\n",
      "           When 'omit' is chosen as nan_policy, each column is counted separately.\n",
      "        minmax: tuple of ndarrays or floats\n",
      "           Minimum and maximum value of data array.\n",
      "        mean : ndarray or float\n",
      "           Arithmetic mean of data along axis.\n",
      "        variance : ndarray or float\n",
      "           Unbiased variance of the data along axis, denominator is number of\n",
      "           observations minus one.\n",
      "        skewness : ndarray or float\n",
      "           Skewness, based on moment calculations with denominator equal to\n",
      "           the number of observations, i.e. no degrees of freedom correction.\n",
      "        kurtosis : ndarray or float\n",
      "           Kurtosis (Fisher).  The kurtosis is normalized so that it is\n",
      "           zero for the normal distribution.  No degrees of freedom are used.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        skew, kurtosis\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> a = np.arange(10)\n",
      "        >>> stats.describe(a)\n",
      "        DescribeResult(nobs=10, minmax=(0, 9), mean=4.5, variance=9.166666666666666,\n",
      "                       skewness=0.0, kurtosis=-1.2242424242424244)\n",
      "        >>> b = [[1, 2], [3, 4]]\n",
      "        >>> stats.describe(b)\n",
      "        DescribeResult(nobs=2, minmax=(array([1, 2]), array([3, 4])),\n",
      "                       mean=array([2., 3.]), variance=array([2., 2.]),\n",
      "                       skewness=array([0., 0.]), kurtosis=array([-2., -2.]))\n",
      "    \n",
      "    energy_distance(u_values, v_values, u_weights=None, v_weights=None)\n",
      "        Compute the energy distance between two 1D distributions.\n",
      "        \n",
      "        .. versionadded:: 1.0.0\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u_values, v_values : array_like\n",
      "            Values observed in the (empirical) distribution.\n",
      "        u_weights, v_weights : array_like, optional\n",
      "            Weight for each value. If unspecified, each value is assigned the same\n",
      "            weight.\n",
      "            `u_weights` (resp. `v_weights`) must have the same length as\n",
      "            `u_values` (resp. `v_values`). If the weight sum differs from 1, it\n",
      "            must still be positive and finite so that the weights can be normalized\n",
      "            to sum to 1.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        distance : float\n",
      "            The computed distance between the distributions.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The energy distance between two distributions :math:`u` and :math:`v`, whose\n",
      "        respective CDFs are :math:`U` and :math:`V`, equals to:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            D(u, v) = \\left( 2\\mathbb E|X - Y| - \\mathbb E|X - X'| -\n",
      "            \\mathbb E|Y - Y'| \\right)^{1/2}\n",
      "        \n",
      "        where :math:`X` and :math:`X'` (resp. :math:`Y` and :math:`Y'`) are\n",
      "        independent random variables whose probability distribution is :math:`u`\n",
      "        (resp. :math:`v`).\n",
      "        \n",
      "        As shown in [2]_, for one-dimensional real-valued variables, the energy\n",
      "        distance is linked to the non-distribution-free version of the Cramer-von\n",
      "        Mises distance:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            D(u, v) = \\sqrt{2} l_2(u, v) = \\left( 2 \\int_{-\\infty}^{+\\infty} (U-V)^2\n",
      "            \\right)^{1/2}\n",
      "        \n",
      "        Note that the common Cramer-von Mises criterion uses the distribution-free\n",
      "        version of the distance. See [2]_ (section 2), for more details about both\n",
      "        versions of the distance.\n",
      "        \n",
      "        The input distributions can be empirical, therefore coming from samples\n",
      "        whose values are effectively inputs of the function, or they can be seen as\n",
      "        generalized functions, in which case they are weighted sums of Dirac delta\n",
      "        functions located at the specified values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] \"Energy distance\", https://en.wikipedia.org/wiki/Energy_distance\n",
      "        .. [2] Szekely \"E-statistics: The energy of statistical samples.\" Bowling\n",
      "               Green State University, Department of Mathematics and Statistics,\n",
      "               Technical Report 02-16 (2002).\n",
      "        .. [3] Rizzo, Szekely \"Energy distance.\" Wiley Interdisciplinary Reviews:\n",
      "               Computational Statistics, 8(1):27-38 (2015).\n",
      "        .. [4] Bellemare, Danihelka, Dabney, Mohamed, Lakshminarayanan, Hoyer,\n",
      "               Munos \"The Cramer Distance as a Solution to Biased Wasserstein\n",
      "               Gradients\" (2017). :arXiv:`1705.10743`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.stats import energy_distance\n",
      "        >>> energy_distance([0], [2])\n",
      "        2.0000000000000004\n",
      "        >>> energy_distance([0, 8], [0, 8], [3, 1], [2, 2])\n",
      "        1.0000000000000002\n",
      "        >>> energy_distance([0.7, 7.4, 2.4, 6.8], [1.4, 8. ],\n",
      "        ...                 [2.1, 4.2, 7.4, 8. ], [7.6, 8.8])\n",
      "        0.88003340976158217\n",
      "    \n",
      "    entropy(pk, qk=None, base=None, axis=0)\n",
      "        Calculate the entropy of a distribution for given probability values.\n",
      "        \n",
      "        If only probabilities `pk` are given, the entropy is calculated as\n",
      "        ``S = -sum(pk * log(pk), axis=axis)``.\n",
      "        \n",
      "        If `qk` is not None, then compute the Kullback-Leibler divergence\n",
      "        ``S = sum(pk * log(pk / qk), axis=axis)``.\n",
      "        \n",
      "        This routine will normalize `pk` and `qk` if they don't sum to 1.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        pk : sequence\n",
      "            Defines the (discrete) distribution. ``pk[i]`` is the (possibly\n",
      "            unnormalized) probability of event ``i``.\n",
      "        qk : sequence, optional\n",
      "            Sequence against which the relative entropy is computed. Should be in\n",
      "            the same format as `pk`.\n",
      "        base : float, optional\n",
      "            The logarithmic base to use, defaults to ``e`` (natural logarithm).\n",
      "        axis: int, optional\n",
      "            The axis along which the entropy is calculated. Default is 0.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        S : float\n",
      "            The calculated entropy.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        \n",
      "        >>> from scipy.stats import entropy\n",
      "        \n",
      "        Bernoulli trial with different p.\n",
      "        The outcome of a fair coin is the most uncertain:\n",
      "        \n",
      "        >>> entropy([1/2, 1/2], base=2)\n",
      "        1.0\n",
      "        \n",
      "        The outcome of a biased coin is less uncertain:\n",
      "        \n",
      "        >>> entropy([9/10, 1/10], base=2)\n",
      "        0.46899559358928117\n",
      "        \n",
      "        Relative entropy:\n",
      "        \n",
      "        >>> entropy([1/2, 1/2], qk=[9/10, 1/10])\n",
      "        0.5108256237659907\n",
      "    \n",
      "    epps_singleton_2samp(x, y, t=(0.4, 0.8))\n",
      "        Compute the Epps-Singleton (ES) test statistic.\n",
      "        \n",
      "        Test the null hypothesis that two samples have the same underlying\n",
      "        probability distribution.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x, y : array-like\n",
      "            The two samples of observations to be tested. Input must not have more\n",
      "            than one dimension. Samples can have different lengths.\n",
      "        t : array-like, optional\n",
      "            The points (t1, ..., tn) where the empirical characteristic function is\n",
      "            to be evaluated. It should be positive distinct numbers. The default\n",
      "            value (0.4, 0.8) is proposed in [1]_. Input must not have more than\n",
      "            one dimension.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float\n",
      "            The test statistic.\n",
      "        pvalue : float\n",
      "            The associated p-value based on the asymptotic chi2-distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        ks_2samp, anderson_ksamp\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Testing whether two samples are generated by the same underlying\n",
      "        distribution is a classical question in statistics. A widely used test is\n",
      "        the Kolmogorov-Smirnov (KS) test which relies on the empirical\n",
      "        distribution function. Epps and Singleton introduce a test based on the\n",
      "        empirical characteristic function in [1]_.\n",
      "        \n",
      "        One advantage of the ES test compared to the KS test is that is does\n",
      "        not assume a continuous distribution. In [1]_, the authors conclude\n",
      "        that the test also has a higher power than the KS test in many\n",
      "        examples. They recommend the use of the ES test for discrete samples as\n",
      "        well as continuous samples with at least 25 observations each, whereas\n",
      "        `anderson_ksamp` is recommended for smaller sample sizes in the\n",
      "        continuous case.\n",
      "        \n",
      "        The p-value is computed from the asymptotic distribution of the test\n",
      "        statistic which follows a `chi2` distribution. If the sample size of both\n",
      "        `x` and `y` is below 25, the small sample correction proposed in [1]_ is\n",
      "        applied to the test statistic.\n",
      "        \n",
      "        The default values of `t` are determined in [1]_ by considering\n",
      "        various distributions and finding good values that lead to a high power\n",
      "        of the test in general. Table III in [1]_ gives the optimal values for\n",
      "        the distributions tested in that study. The values of `t` are scaled by\n",
      "        the semi-interquartile range in the implementation, see [1]_.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] T. W. Epps and K. J. Singleton, \"An omnibus test for the two-sample\n",
      "           problem using the empirical characteristic function\", Journal of\n",
      "           Statistical Computation and Simulation 26, p. 177--203, 1986.\n",
      "        \n",
      "        .. [2] S. J. Goerg and J. Kaiser, \"Nonparametric testing of distributions\n",
      "           - the Epps-Singleton two-sample test using the empirical characteristic\n",
      "           function\", The Stata Journal 9(3), p. 454--465, 2009.\n",
      "    \n",
      "    f_oneway(*args)\n",
      "        Perform one-way ANOVA.\n",
      "        \n",
      "        The one-way ANOVA tests the null hypothesis that two or more groups have\n",
      "        the same population mean.  The test is applied to samples from two or\n",
      "        more groups, possibly with differing sizes.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        sample1, sample2, ... : array_like\n",
      "            The sample measurements for each group.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float\n",
      "            The computed F-value of the test.\n",
      "        pvalue : float\n",
      "            The associated p-value from the F-distribution.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The ANOVA test has important assumptions that must be satisfied in order\n",
      "        for the associated p-value to be valid.\n",
      "        \n",
      "        1. The samples are independent.\n",
      "        2. Each sample is from a normally distributed population.\n",
      "        3. The population standard deviations of the groups are all equal.  This\n",
      "           property is known as homoscedasticity.\n",
      "        \n",
      "        If these assumptions are not true for a given set of data, it may still be\n",
      "        possible to use the Kruskal-Wallis H-test (`scipy.stats.kruskal`) although\n",
      "        with some loss of power.\n",
      "        \n",
      "        The algorithm is from Heiman[2], pp.394-7.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] R. Lowry, \"Concepts and Applications of Inferential Statistics\",\n",
      "               Chapter 14, 2014, http://vassarstats.net/textbook/\n",
      "        \n",
      "        .. [2] G.W. Heiman, \"Understanding research methods and statistics: An\n",
      "               integrated introduction for psychology\", Houghton, Mifflin and\n",
      "               Company, 2001.\n",
      "        \n",
      "        .. [3] G.H. McDonald, \"Handbook of Biological Statistics\", One-way ANOVA.\n",
      "               http://www.biostathandbook.com/onewayanova.html\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import scipy.stats as stats\n",
      "        \n",
      "        [3]_ Here are some data on a shell measurement (the length of the anterior\n",
      "        adductor muscle scar, standardized by dividing by length) in the mussel\n",
      "        Mytilus trossulus from five locations: Tillamook, Oregon; Newport, Oregon;\n",
      "        Petersburg, Alaska; Magadan, Russia; and Tvarminne, Finland, taken from a\n",
      "        much larger data set used in McDonald et al. (1991).\n",
      "        \n",
      "        >>> tillamook = [0.0571, 0.0813, 0.0831, 0.0976, 0.0817, 0.0859, 0.0735,\n",
      "        ...              0.0659, 0.0923, 0.0836]\n",
      "        >>> newport = [0.0873, 0.0662, 0.0672, 0.0819, 0.0749, 0.0649, 0.0835,\n",
      "        ...            0.0725]\n",
      "        >>> petersburg = [0.0974, 0.1352, 0.0817, 0.1016, 0.0968, 0.1064, 0.105]\n",
      "        >>> magadan = [0.1033, 0.0915, 0.0781, 0.0685, 0.0677, 0.0697, 0.0764,\n",
      "        ...            0.0689]\n",
      "        >>> tvarminne = [0.0703, 0.1026, 0.0956, 0.0973, 0.1039, 0.1045]\n",
      "        >>> stats.f_oneway(tillamook, newport, petersburg, magadan, tvarminne)\n",
      "        (7.1210194716424473, 0.00028122423145345439)\n",
      "    \n",
      "    find_repeats(arr)\n",
      "        Find repeats and repeat counts.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        arr : array_like\n",
      "            Input array. This is cast to float64.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        values : ndarray\n",
      "            The unique values from the (flattened) input that are repeated.\n",
      "        \n",
      "        counts : ndarray\n",
      "            Number of times the corresponding 'value' is repeated.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        In numpy >= 1.9 `numpy.unique` provides similar functionality. The main\n",
      "        difference is that `find_repeats` only returns repeated values.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> stats.find_repeats([2, 1, 2, 3, 2, 2, 5])\n",
      "        RepeatedResults(values=array([2.]), counts=array([4]))\n",
      "        \n",
      "        >>> stats.find_repeats([[10, 20, 1, 2], [5, 5, 4, 4]])\n",
      "        RepeatedResults(values=array([4.,  5.]), counts=array([2, 2]))\n",
      "    \n",
      "    fisher_exact(table, alternative='two-sided')\n",
      "        Perform a Fisher exact test on a 2x2 contingency table.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        table : array_like of ints\n",
      "            A 2x2 contingency table.  Elements should be non-negative integers.\n",
      "        alternative : {'two-sided', 'less', 'greater'}, optional\n",
      "            Defines the alternative hypothesis.\n",
      "            The following options are available (default is 'two-sided'):\n",
      "        \n",
      "              * 'two-sided'\n",
      "              * 'less': one-sided\n",
      "              * 'greater': one-sided\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        oddsratio : float\n",
      "            This is prior odds ratio and not a posterior estimate.\n",
      "        p_value : float\n",
      "            P-value, the probability of obtaining a distribution at least as\n",
      "            extreme as the one that was actually observed, assuming that the\n",
      "            null hypothesis is true.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        chi2_contingency : Chi-square test of independence of variables in a\n",
      "            contingency table.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The calculated odds ratio is different from the one R uses. This scipy\n",
      "        implementation returns the (more common) \"unconditional Maximum\n",
      "        Likelihood Estimate\", while R uses the \"conditional Maximum Likelihood\n",
      "        Estimate\".\n",
      "        \n",
      "        For tables with large numbers, the (inexact) chi-square test implemented\n",
      "        in the function `chi2_contingency` can also be used.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Say we spend a few days counting whales and sharks in the Atlantic and\n",
      "        Indian oceans. In the Atlantic ocean we find 8 whales and 1 shark, in the\n",
      "        Indian ocean 2 whales and 5 sharks. Then our contingency table is::\n",
      "        \n",
      "                    Atlantic  Indian\n",
      "            whales     8        2\n",
      "            sharks     1        5\n",
      "        \n",
      "        We use this table to find the p-value:\n",
      "        \n",
      "        >>> import scipy.stats as stats\n",
      "        >>> oddsratio, pvalue = stats.fisher_exact([[8, 2], [1, 5]])\n",
      "        >>> pvalue\n",
      "        0.0349...\n",
      "        \n",
      "        The probability that we would observe this or an even more imbalanced ratio\n",
      "        by chance is about 3.5%.  A commonly used significance level is 5%--if we\n",
      "        adopt that, we can therefore conclude that our observed imbalance is\n",
      "        statistically significant; whales prefer the Atlantic while sharks prefer\n",
      "        the Indian ocean.\n",
      "    \n",
      "    fligner(*args, **kwds)\n",
      "        Perform Fligner-Killeen test for equality of variance.\n",
      "        \n",
      "        Fligner's test tests the null hypothesis that all input samples\n",
      "        are from populations with equal variances.  Fligner-Killeen's test is\n",
      "        distribution free when populations are identical [2]_.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        sample1, sample2, ... : array_like\n",
      "            Arrays of sample data.  Need not be the same length.\n",
      "        center : {'mean', 'median', 'trimmed'}, optional\n",
      "            Keyword argument controlling which function of the data is used in\n",
      "            computing the test statistic.  The default is 'median'.\n",
      "        proportiontocut : float, optional\n",
      "            When `center` is 'trimmed', this gives the proportion of data points\n",
      "            to cut from each end. (See `scipy.stats.trim_mean`.)\n",
      "            Default is 0.05.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float\n",
      "            The test statistic.\n",
      "        pvalue : float\n",
      "            The p-value for the hypothesis test.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        bartlett : A parametric test for equality of k variances in normal samples\n",
      "        levene : A robust parametric test for equality of k variances\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        As with Levene's test there are three variants of Fligner's test that\n",
      "        differ by the measure of central tendency used in the test.  See `levene`\n",
      "        for more information.\n",
      "        \n",
      "        Conover et al. (1981) examine many of the existing parametric and\n",
      "        nonparametric tests by extensive simulations and they conclude that the\n",
      "        tests proposed by Fligner and Killeen (1976) and Levene (1960) appear to be\n",
      "        superior in terms of robustness of departures from normality and power [3]_.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Park, C. and Lindsay, B. G. (1999). Robust Scale Estimation and\n",
      "               Hypothesis Testing based on Quadratic Inference Function. Technical\n",
      "               Report #99-03, Center for Likelihood Studies, Pennsylvania State\n",
      "               University.\n",
      "               https://cecas.clemson.edu/~cspark/cv/paper/qif/draftqif2.pdf\n",
      "        \n",
      "        .. [2] Fligner, M.A. and Killeen, T.J. (1976). Distribution-free two-sample\n",
      "               tests for scale. 'Journal of the American Statistical Association.'\n",
      "               71(353), 210-213.\n",
      "        \n",
      "        .. [3] Park, C. and Lindsay, B. G. (1999). Robust Scale Estimation and\n",
      "               Hypothesis Testing based on Quadratic Inference Function. Technical\n",
      "               Report #99-03, Center for Likelihood Studies, Pennsylvania State\n",
      "               University.\n",
      "        \n",
      "        .. [4] Conover, W. J., Johnson, M. E. and Johnson M. M. (1981). A\n",
      "               comparative study of tests for homogeneity of variances, with\n",
      "               applications to the outer continental shelf biding data.\n",
      "               Technometrics, 23(4), 351-361.\n",
      "    \n",
      "    friedmanchisquare(*args)\n",
      "        Compute the Friedman test for repeated measurements.\n",
      "        \n",
      "        The Friedman test tests the null hypothesis that repeated measurements of\n",
      "        the same individuals have the same distribution.  It is often used\n",
      "        to test for consistency among measurements obtained in different ways.\n",
      "        For example, if two measurement techniques are used on the same set of\n",
      "        individuals, the Friedman test can be used to determine if the two\n",
      "        measurement techniques are consistent.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        measurements1, measurements2, measurements3... : array_like\n",
      "            Arrays of measurements.  All of the arrays must have the same number\n",
      "            of elements.  At least 3 sets of measurements must be given.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float\n",
      "            The test statistic, correcting for ties.\n",
      "        pvalue : float\n",
      "            The associated p-value assuming that the test statistic has a chi\n",
      "            squared distribution.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Due to the assumption that the test statistic has a chi squared\n",
      "        distribution, the p-value is only reliable for n > 10 and more than\n",
      "        6 repeated measurements.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] https://en.wikipedia.org/wiki/Friedman_test\n",
      "    \n",
      "    gmean(a, axis=0, dtype=None)\n",
      "        Compute the geometric mean along the specified axis.\n",
      "        \n",
      "        Return the geometric average of the array elements.\n",
      "        That is:  n-th root of (x1 * x2 * ... * xn)\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Input array or object that can be converted to an array.\n",
      "        axis : int or None, optional\n",
      "            Axis along which the geometric mean is computed. Default is 0.\n",
      "            If None, compute over the whole array `a`.\n",
      "        dtype : dtype, optional\n",
      "            Type of the returned array and of the accumulator in which the\n",
      "            elements are summed. If dtype is not specified, it defaults to the\n",
      "            dtype of a, unless a has an integer dtype with a precision less than\n",
      "            that of the default platform integer. In that case, the default\n",
      "            platform integer is used.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        gmean : ndarray\n",
      "            See `dtype` parameter above.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        numpy.mean : Arithmetic average\n",
      "        numpy.average : Weighted average\n",
      "        hmean : Harmonic mean\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The geometric average is computed over a single dimension of the input\n",
      "        array, axis=0 by default, or all values in the array if axis=None.\n",
      "        float64 intermediate and return values are used for integer inputs.\n",
      "        \n",
      "        Use masked arrays to ignore any non-finite values in the input or that\n",
      "        arise in the calculations such as Not a Number and infinity because masked\n",
      "        arrays automatically mask any non-finite values.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.stats import gmean\n",
      "        >>> gmean([1, 4])\n",
      "        2.0\n",
      "        >>> gmean([1, 2, 3, 4, 5, 6, 7])\n",
      "        3.3800151591412964\n",
      "    \n",
      "    gstd(a, axis=0, ddof=1)\n",
      "        Calculate the geometric standard deviation of an array.\n",
      "        \n",
      "        The geometric standard deviation describes the spread of a set of numbers\n",
      "        where the geometric mean is preferred. It is a multiplicative factor, and\n",
      "        so a dimensionless quantity.\n",
      "        \n",
      "        It is defined as the exponent of the standard deviation of ``log(a)``.\n",
      "        Mathematically the population geometric standard deviation can be\n",
      "        evaluated as::\n",
      "        \n",
      "            gstd = exp(std(log(a)))\n",
      "        \n",
      "        .. versionadded:: 1.3.0\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            An array like object containing the sample data.\n",
      "        axis : int, tuple or None, optional\n",
      "            Axis along which to operate. Default is 0. If None, compute over\n",
      "            the whole array `a`.\n",
      "        ddof : int, optional\n",
      "            Degree of freedom correction in the calculation of the\n",
      "            geometric standard deviation. Default is 1.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ndarray or float\n",
      "            An array of the geometric standard deviation. If `axis` is None or `a`\n",
      "            is a 1d array a float is returned.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        As the calculation requires the use of logarithms the geometric standard\n",
      "        deviation only supports strictly positive values. Any non-positive or\n",
      "        infinite values will raise a `ValueError`.\n",
      "        The geometric standard deviation is sometimes confused with the exponent of\n",
      "        the standard deviation, ``exp(std(a))``. Instead the geometric standard\n",
      "        deviation is ``exp(std(log(a)))``.\n",
      "        The default value for `ddof` is different to the default value (0) used\n",
      "        by other ddof containing functions, such as ``np.std`` and ``np.nanstd``.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Find the geometric standard deviation of a log-normally distributed sample.\n",
      "        Note that the standard deviation of the distribution is one, on a\n",
      "        log scale this evaluates to approximately ``exp(1)``.\n",
      "        \n",
      "        >>> from scipy.stats import gstd\n",
      "        >>> np.random.seed(123)\n",
      "        >>> sample = np.random.lognormal(mean=0, sigma=1, size=1000)\n",
      "        >>> gstd(sample)\n",
      "        2.7217860664589946\n",
      "        \n",
      "        Compute the geometric standard deviation of a multidimensional array and\n",
      "        of a given axis.\n",
      "        \n",
      "        >>> a = np.arange(1, 25).reshape(2, 3, 4)\n",
      "        >>> gstd(a, axis=None)\n",
      "        2.2944076136018947\n",
      "        >>> gstd(a, axis=2)\n",
      "        array([[1.82424757, 1.22436866, 1.13183117],\n",
      "               [1.09348306, 1.07244798, 1.05914985]])\n",
      "        >>> gstd(a, axis=(1,2))\n",
      "        array([2.12939215, 1.22120169])\n",
      "        \n",
      "        The geometric standard deviation further handles masked arrays.\n",
      "        \n",
      "        >>> a = np.arange(1, 25).reshape(2, 3, 4)\n",
      "        >>> ma = np.ma.masked_where(a > 16, a)\n",
      "        >>> ma\n",
      "        masked_array(\n",
      "          data=[[[1, 2, 3, 4],\n",
      "                 [5, 6, 7, 8],\n",
      "                 [9, 10, 11, 12]],\n",
      "                [[13, 14, 15, 16],\n",
      "                 [--, --, --, --],\n",
      "                 [--, --, --, --]]],\n",
      "          mask=[[[False, False, False, False],\n",
      "                 [False, False, False, False],\n",
      "                 [False, False, False, False]],\n",
      "                [[False, False, False, False],\n",
      "                 [ True,  True,  True,  True],\n",
      "                 [ True,  True,  True,  True]]],\n",
      "          fill_value=999999)\n",
      "        >>> gstd(ma, axis=2)\n",
      "        masked_array(\n",
      "          data=[[1.8242475707663655, 1.2243686572447428, 1.1318311657788478],\n",
      "                [1.0934830582350938, --, --]],\n",
      "          mask=[[False, False, False],\n",
      "                [False,  True,  True]],\n",
      "          fill_value=999999)\n",
      "    \n",
      "    hmean(a, axis=0, dtype=None)\n",
      "        Calculate the harmonic mean along the specified axis.\n",
      "        \n",
      "        That is:  n / (1/x1 + 1/x2 + ... + 1/xn)\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Input array, masked array or object that can be converted to an array.\n",
      "        axis : int or None, optional\n",
      "            Axis along which the harmonic mean is computed. Default is 0.\n",
      "            If None, compute over the whole array `a`.\n",
      "        dtype : dtype, optional\n",
      "            Type of the returned array and of the accumulator in which the\n",
      "            elements are summed. If `dtype` is not specified, it defaults to the\n",
      "            dtype of `a`, unless `a` has an integer `dtype` with a precision less\n",
      "            than that of the default platform integer. In that case, the default\n",
      "            platform integer is used.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        hmean : ndarray\n",
      "            See `dtype` parameter above.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        numpy.mean : Arithmetic average\n",
      "        numpy.average : Weighted average\n",
      "        gmean : Geometric mean\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The harmonic mean is computed over a single dimension of the input\n",
      "        array, axis=0 by default, or all values in the array if axis=None.\n",
      "        float64 intermediate and return values are used for integer inputs.\n",
      "        \n",
      "        Use masked arrays to ignore any non-finite values in the input or that\n",
      "        arise in the calculations such as Not a Number and infinity.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.stats import hmean\n",
      "        >>> hmean([1, 4])\n",
      "        1.6000000000000001\n",
      "        >>> hmean([1, 2, 3, 4, 5, 6, 7])\n",
      "        2.6997245179063363\n",
      "    \n",
      "    iqr(x, axis=None, rng=(25, 75), scale='raw', nan_policy='propagate', interpolation='linear', keepdims=False)\n",
      "        Compute the interquartile range of the data along the specified axis.\n",
      "        \n",
      "        The interquartile range (IQR) is the difference between the 75th and\n",
      "        25th percentile of the data. It is a measure of the dispersion\n",
      "        similar to standard deviation or variance, but is much more robust\n",
      "        against outliers [2]_.\n",
      "        \n",
      "        The ``rng`` parameter allows this function to compute other\n",
      "        percentile ranges than the actual IQR. For example, setting\n",
      "        ``rng=(0, 100)`` is equivalent to `numpy.ptp`.\n",
      "        \n",
      "        The IQR of an empty array is `np.nan`.\n",
      "        \n",
      "        .. versionadded:: 0.18.0\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Input array or object that can be converted to an array.\n",
      "        axis : int or sequence of int, optional\n",
      "            Axis along which the range is computed. The default is to\n",
      "            compute the IQR for the entire array.\n",
      "        rng : Two-element sequence containing floats in range of [0,100] optional\n",
      "            Percentiles over which to compute the range. Each must be\n",
      "            between 0 and 100, inclusive. The default is the true IQR:\n",
      "            `(25, 75)`. The order of the elements is not important.\n",
      "        scale : scalar or str, optional\n",
      "            The numerical value of scale will be divided out of the final\n",
      "            result. The following string values are recognized:\n",
      "        \n",
      "              'raw' : No scaling, just return the raw IQR.\n",
      "              'normal' : Scale by :math:`2 \\sqrt{2} erf^{-1}(\\frac{1}{2}) \\approx 1.349`.\n",
      "        \n",
      "            The default is 'raw'. Array-like scale is also allowed, as long\n",
      "            as it broadcasts correctly to the output such that\n",
      "            ``out / scale`` is a valid operation. The output dimensions\n",
      "            depend on the input array, `x`, the `axis` argument, and the\n",
      "            `keepdims` flag.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan.\n",
      "            The following options are available (default is 'propagate'):\n",
      "        \n",
      "              * 'propagate': returns nan\n",
      "              * 'raise': throws an error\n",
      "              * 'omit': performs the calculations ignoring nan values\n",
      "        interpolation : {'linear', 'lower', 'higher', 'midpoint', 'nearest'}, optional\n",
      "            Specifies the interpolation method to use when the percentile\n",
      "            boundaries lie between two data points `i` and `j`.\n",
      "            The following options are available (default is 'linear'):\n",
      "        \n",
      "              * 'linear': `i + (j - i) * fraction`, where `fraction` is the\n",
      "                fractional part of the index surrounded by `i` and `j`.\n",
      "              * 'lower': `i`.\n",
      "              * 'higher': `j`.\n",
      "              * 'nearest': `i` or `j` whichever is nearest.\n",
      "              * 'midpoint': `(i + j) / 2`.\n",
      "        \n",
      "        keepdims : bool, optional\n",
      "            If this is set to `True`, the reduced axes are left in the\n",
      "            result as dimensions with size one. With this option, the result\n",
      "            will broadcast correctly against the original array `x`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        iqr : scalar or ndarray\n",
      "            If ``axis=None``, a scalar is returned. If the input contains\n",
      "            integers or floats of smaller precision than ``np.float64``, then the\n",
      "            output data-type is ``np.float64``. Otherwise, the output data-type is\n",
      "            the same as that of the input.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        numpy.std, numpy.var\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This function is heavily dependent on the version of `numpy` that is\n",
      "        installed. Versions greater than 1.11.0b3 are highly recommended, as they\n",
      "        include a number of enhancements and fixes to `numpy.percentile` and\n",
      "        `numpy.nanpercentile` that affect the operation of this function. The\n",
      "        following modifications apply:\n",
      "        \n",
      "        Below 1.10.0 : `nan_policy` is poorly defined.\n",
      "            The default behavior of `numpy.percentile` is used for 'propagate'. This\n",
      "            is a hybrid of 'omit' and 'propagate' that mostly yields a skewed\n",
      "            version of 'omit' since NaNs are sorted to the end of the data. A\n",
      "            warning is raised if there are NaNs in the data.\n",
      "        Below 1.9.0: `numpy.nanpercentile` does not exist.\n",
      "            This means that `numpy.percentile` is used regardless of `nan_policy`\n",
      "            and a warning is issued. See previous item for a description of the\n",
      "            behavior.\n",
      "        Below 1.9.0: `keepdims` and `interpolation` are not supported.\n",
      "            The keywords get ignored with a warning if supplied with non-default\n",
      "            values. However, multiple axes are still supported.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] \"Interquartile range\" https://en.wikipedia.org/wiki/Interquartile_range\n",
      "        .. [2] \"Robust measures of scale\" https://en.wikipedia.org/wiki/Robust_measures_of_scale\n",
      "        .. [3] \"Quantile\" https://en.wikipedia.org/wiki/Quantile\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.stats import iqr\n",
      "        >>> x = np.array([[10, 7, 4], [3, 2, 1]])\n",
      "        >>> x\n",
      "        array([[10,  7,  4],\n",
      "               [ 3,  2,  1]])\n",
      "        >>> iqr(x)\n",
      "        4.0\n",
      "        >>> iqr(x, axis=0)\n",
      "        array([ 3.5,  2.5,  1.5])\n",
      "        >>> iqr(x, axis=1)\n",
      "        array([ 3.,  1.])\n",
      "        >>> iqr(x, axis=1, keepdims=True)\n",
      "        array([[ 3.],\n",
      "               [ 1.]])\n",
      "    \n",
      "    itemfreq(*args, **kwds)\n",
      "        `itemfreq` is deprecated!\n",
      "        `itemfreq` is deprecated and will be removed in a future version. Use instead `np.unique(..., return_counts=True)`\n",
      "        \n",
      "            Return a 2-D array of item frequencies.\n",
      "        \n",
      "            Parameters\n",
      "            ----------\n",
      "            a : (N,) array_like\n",
      "                Input array.\n",
      "        \n",
      "            Returns\n",
      "            -------\n",
      "            itemfreq : (K, 2) ndarray\n",
      "                A 2-D frequency table.  Column 1 contains sorted, unique values from\n",
      "                `a`, column 2 contains their respective counts.\n",
      "        \n",
      "            Examples\n",
      "            --------\n",
      "            >>> from scipy import stats\n",
      "            >>> a = np.array([1, 1, 5, 0, 1, 2, 2, 0, 1, 4])\n",
      "            >>> stats.itemfreq(a)\n",
      "            array([[ 0.,  2.],\n",
      "                   [ 1.,  4.],\n",
      "                   [ 2.,  2.],\n",
      "                   [ 4.,  1.],\n",
      "                   [ 5.,  1.]])\n",
      "            >>> np.bincount(a)\n",
      "            array([2, 4, 2, 0, 1, 1])\n",
      "        \n",
      "            >>> stats.itemfreq(a/10.)\n",
      "            array([[ 0. ,  2. ],\n",
      "                   [ 0.1,  4. ],\n",
      "                   [ 0.2,  2. ],\n",
      "                   [ 0.4,  1. ],\n",
      "                   [ 0.5,  1. ]])\n",
      "    \n",
      "    jarque_bera(x)\n",
      "        Perform the Jarque-Bera goodness of fit test on sample data.\n",
      "        \n",
      "        The Jarque-Bera test tests whether the sample data has the skewness and\n",
      "        kurtosis matching a normal distribution.\n",
      "        \n",
      "        Note that this test only works for a large enough number of data samples\n",
      "        (>2000) as the test statistic asymptotically has a Chi-squared distribution\n",
      "        with 2 degrees of freedom.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Observations of a random variable.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        jb_value : float\n",
      "            The test statistic.\n",
      "        p : float\n",
      "            The p-value for the hypothesis test.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Jarque, C. and Bera, A. (1980) \"Efficient tests for normality,\n",
      "               homoscedasticity and serial independence of regression residuals\",\n",
      "               6 Econometric Letters 255-259.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> np.random.seed(987654321)\n",
      "        >>> x = np.random.normal(0, 1, 100000)\n",
      "        >>> y = np.random.rayleigh(1, 100000)\n",
      "        >>> stats.jarque_bera(x)\n",
      "        (4.7165707989581342, 0.09458225503041906)\n",
      "        >>> stats.jarque_bera(y)\n",
      "        (6713.7098548143422, 0.0)\n",
      "    \n",
      "    kendalltau(x, y, initial_lexsort=None, nan_policy='propagate', method='auto')\n",
      "        Calculate Kendall's tau, a correlation measure for ordinal data.\n",
      "        \n",
      "        Kendall's tau is a measure of the correspondence between two rankings.\n",
      "        Values close to 1 indicate strong agreement, values close to -1 indicate\n",
      "        strong disagreement.  This is the 1945 \"tau-b\" version of Kendall's\n",
      "        tau [2]_, which can account for ties and which reduces to the 1938 \"tau-a\"\n",
      "        version [1]_ in absence of ties.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x, y : array_like\n",
      "            Arrays of rankings, of the same shape. If arrays are not 1-D, they will\n",
      "            be flattened to 1-D.\n",
      "        initial_lexsort : bool, optional\n",
      "            Unused (deprecated).\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan.\n",
      "            The following options are available (default is 'propagate'):\n",
      "        \n",
      "              * 'propagate': returns nan\n",
      "              * 'raise': throws an error\n",
      "              * 'omit': performs the calculations ignoring nan values\n",
      "        method : {'auto', 'asymptotic', 'exact'}, optional\n",
      "            Defines which method is used to calculate the p-value [5]_.\n",
      "            The following options are available (default is 'auto'):\n",
      "        \n",
      "              * 'auto': selects the appropriate method based on a trade-off between\n",
      "                speed and accuracy\n",
      "              * 'asymptotic': uses a normal approximation valid for large samples\n",
      "              * 'exact': computes the exact p-value, but can only be used if no ties\n",
      "                are present\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        correlation : float\n",
      "           The tau statistic.\n",
      "        pvalue : float\n",
      "           The two-sided p-value for a hypothesis test whose null hypothesis is\n",
      "           an absence of association, tau = 0.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        spearmanr : Calculates a Spearman rank-order correlation coefficient.\n",
      "        theilslopes : Computes the Theil-Sen estimator for a set of points (x, y).\n",
      "        weightedtau : Computes a weighted version of Kendall's tau.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The definition of Kendall's tau that is used is [2]_::\n",
      "        \n",
      "          tau = (P - Q) / sqrt((P + Q + T) * (P + Q + U))\n",
      "        \n",
      "        where P is the number of concordant pairs, Q the number of discordant\n",
      "        pairs, T the number of ties only in `x`, and U the number of ties only in\n",
      "        `y`.  If a tie occurs for the same pair in both `x` and `y`, it is not\n",
      "        added to either T or U.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Maurice G. Kendall, \"A New Measure of Rank Correlation\", Biometrika\n",
      "               Vol. 30, No. 1/2, pp. 81-93, 1938.\n",
      "        .. [2] Maurice G. Kendall, \"The treatment of ties in ranking problems\",\n",
      "               Biometrika Vol. 33, No. 3, pp. 239-251. 1945.\n",
      "        .. [3] Gottfried E. Noether, \"Elements of Nonparametric Statistics\", John\n",
      "               Wiley & Sons, 1967.\n",
      "        .. [4] Peter M. Fenwick, \"A new data structure for cumulative frequency\n",
      "               tables\", Software: Practice and Experience, Vol. 24, No. 3,\n",
      "               pp. 327-336, 1994.\n",
      "        .. [5] Maurice G. Kendall, \"Rank Correlation Methods\" (4th Edition),\n",
      "               Charles Griffin & Co., 1970.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> x1 = [12, 2, 1, 12, 2]\n",
      "        >>> x2 = [1, 4, 7, 1, 0]\n",
      "        >>> tau, p_value = stats.kendalltau(x1, x2)\n",
      "        >>> tau\n",
      "        -0.47140452079103173\n",
      "        >>> p_value\n",
      "        0.2827454599327748\n",
      "    \n",
      "    kruskal(*args, **kwargs)\n",
      "        Compute the Kruskal-Wallis H-test for independent samples.\n",
      "        \n",
      "        The Kruskal-Wallis H-test tests the null hypothesis that the population\n",
      "        median of all of the groups are equal.  It is a non-parametric version of\n",
      "        ANOVA.  The test works on 2 or more independent samples, which may have\n",
      "        different sizes.  Note that rejecting the null hypothesis does not\n",
      "        indicate which of the groups differs.  Post hoc comparisons between\n",
      "        groups are required to determine which groups are different.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        sample1, sample2, ... : array_like\n",
      "           Two or more arrays with the sample measurements can be given as\n",
      "           arguments.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan.\n",
      "            The following options are available (default is 'propagate'):\n",
      "        \n",
      "              * 'propagate': returns nan\n",
      "              * 'raise': throws an error\n",
      "              * 'omit': performs the calculations ignoring nan values\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float\n",
      "           The Kruskal-Wallis H statistic, corrected for ties.\n",
      "        pvalue : float\n",
      "           The p-value for the test using the assumption that H has a chi\n",
      "           square distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        f_oneway : 1-way ANOVA.\n",
      "        mannwhitneyu : Mann-Whitney rank test on two samples.\n",
      "        friedmanchisquare : Friedman test for repeated measurements.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Due to the assumption that H has a chi square distribution, the number\n",
      "        of samples in each group must not be too small.  A typical rule is\n",
      "        that each sample must have at least 5 measurements.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] W. H. Kruskal & W. W. Wallis, \"Use of Ranks in\n",
      "           One-Criterion Variance Analysis\", Journal of the American Statistical\n",
      "           Association, Vol. 47, Issue 260, pp. 583-621, 1952.\n",
      "        .. [2] https://en.wikipedia.org/wiki/Kruskal-Wallis_one-way_analysis_of_variance\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> x = [1, 3, 5, 7, 9]\n",
      "        >>> y = [2, 4, 6, 8, 10]\n",
      "        >>> stats.kruskal(x, y)\n",
      "        KruskalResult(statistic=0.2727272727272734, pvalue=0.6015081344405895)\n",
      "        \n",
      "        >>> x = [1, 1, 1]\n",
      "        >>> y = [2, 2, 2]\n",
      "        >>> z = [2, 2]\n",
      "        >>> stats.kruskal(x, y, z)\n",
      "        KruskalResult(statistic=7.0, pvalue=0.0301973834223185)\n",
      "    \n",
      "    ks_2samp(data1, data2, alternative='two-sided', mode='auto')\n",
      "        Compute the Kolmogorov-Smirnov statistic on 2 samples.\n",
      "        \n",
      "        This is a two-sided test for the null hypothesis that 2 independent samples\n",
      "        are drawn from the same continuous distribution.  The alternative hypothesis\n",
      "        can be either 'two-sided' (default), 'less' or 'greater'.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data1, data2 : sequence of 1-D ndarrays\n",
      "            Two arrays of sample observations assumed to be drawn from a continuous\n",
      "            distribution, sample sizes can be different.\n",
      "        alternative : {'two-sided', 'less', 'greater'}, optional\n",
      "            Defines the alternative hypothesis.\n",
      "            The following options are available (default is 'two-sided'):\n",
      "        \n",
      "              * 'two-sided'\n",
      "              * 'less': one-sided, see explanation in Notes\n",
      "              * 'greater': one-sided, see explanation in Notes\n",
      "        mode : {'auto', 'exact', 'asymp'}, optional\n",
      "            Defines the method used for calculating the p-value.\n",
      "            The following options are available (default is 'auto'):\n",
      "        \n",
      "              * 'auto' : use 'exact' for small size arrays, 'asymp' for large\n",
      "              * 'exact' : use approximation to exact distribution of test statistic\n",
      "              * 'asymp' : use asymptotic distribution of test statistic\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float\n",
      "            KS statistic.\n",
      "        pvalue : float\n",
      "            Two-tailed p-value.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        kstest\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This tests whether 2 samples are drawn from the same distribution. Note\n",
      "        that, like in the case of the one-sample KS test, the distribution is\n",
      "        assumed to be continuous.\n",
      "        \n",
      "        In the one-sided test, the alternative is that the empirical\n",
      "        cumulative distribution function F(x) of the data1 variable is \"less\"\n",
      "        or \"greater\" than the empirical cumulative distribution function G(x)\n",
      "        of the data2 variable, ``F(x)<=G(x)``, resp. ``F(x)>=G(x)``.\n",
      "        \n",
      "        If the KS statistic is small or the p-value is high, then we cannot\n",
      "        reject the hypothesis that the distributions of the two samples\n",
      "        are the same.\n",
      "        \n",
      "        If the mode is 'auto', the computation is exact if the sample sizes are\n",
      "        less than 10000.  For larger sizes, the computation uses the\n",
      "        Kolmogorov-Smirnov distributions to compute an approximate value.\n",
      "        \n",
      "        We generally follow Hodges' treatment of Drion/Gnedenko/Korolyuk [1]_.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Hodges, J.L. Jr.,  \"The Significance Probability of the Smirnov\n",
      "               Two-Sample Test,\" Arkiv fiur Matematik, 3, No. 43 (1958), 469-86.\n",
      "        \n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> np.random.seed(12345678)  #fix random seed to get the same result\n",
      "        >>> n1 = 200  # size of first sample\n",
      "        >>> n2 = 300  # size of second sample\n",
      "        \n",
      "        For a different distribution, we can reject the null hypothesis since the\n",
      "        pvalue is below 1%:\n",
      "        \n",
      "        >>> rvs1 = stats.norm.rvs(size=n1, loc=0., scale=1)\n",
      "        >>> rvs2 = stats.norm.rvs(size=n2, loc=0.5, scale=1.5)\n",
      "        >>> stats.ks_2samp(rvs1, rvs2)\n",
      "        (0.20833333333333334, 5.129279597781977e-05)\n",
      "        \n",
      "        For a slightly different distribution, we cannot reject the null hypothesis\n",
      "        at a 10% or lower alpha since the p-value at 0.144 is higher than 10%\n",
      "        \n",
      "        >>> rvs3 = stats.norm.rvs(size=n2, loc=0.01, scale=1.0)\n",
      "        >>> stats.ks_2samp(rvs1, rvs3)\n",
      "        (0.10333333333333333, 0.14691437867433876)\n",
      "        \n",
      "        For an identical distribution, we cannot reject the null hypothesis since\n",
      "        the p-value is high, 41%:\n",
      "        \n",
      "        >>> rvs4 = stats.norm.rvs(size=n2, loc=0.0, scale=1.0)\n",
      "        >>> stats.ks_2samp(rvs1, rvs4)\n",
      "        (0.07999999999999996, 0.41126949729859719)\n",
      "    \n",
      "    kstat(data, n=2)\n",
      "        Return the nth k-statistic (1<=n<=4 so far).\n",
      "        \n",
      "        The nth k-statistic k_n is the unique symmetric unbiased estimator of the\n",
      "        nth cumulant kappa_n.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data : array_like\n",
      "            Input array. Note that n-D input gets flattened.\n",
      "        n : int, {1, 2, 3, 4}, optional\n",
      "            Default is equal to 2.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        kstat : float\n",
      "            The nth k-statistic.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        kstatvar: Returns an unbiased estimator of the variance of the k-statistic.\n",
      "        moment: Returns the n-th central moment about the mean for a sample.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        For a sample size n, the first few k-statistics are given by:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            k_{1} = \\mu\n",
      "            k_{2} = \\frac{n}{n-1} m_{2}\n",
      "            k_{3} = \\frac{ n^{2} } {(n-1) (n-2)} m_{3}\n",
      "            k_{4} = \\frac{ n^{2} [(n + 1)m_{4} - 3(n - 1) m^2_{2}]} {(n-1) (n-2) (n-3)}\n",
      "        \n",
      "        where :math:`\\mu` is the sample mean, :math:`m_2` is the sample\n",
      "        variance, and :math:`m_i` is the i-th sample central moment.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        http://mathworld.wolfram.com/k-Statistic.html\n",
      "        \n",
      "        http://mathworld.wolfram.com/Cumulant.html\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> rndm = np.random.RandomState(1234)\n",
      "        \n",
      "        As sample size increases, n-th moment and n-th k-statistic converge to the\n",
      "        same number (although they aren't identical). In the case of the normal\n",
      "        distribution, they converge to zero.\n",
      "        \n",
      "        >>> for n in [2, 3, 4, 5, 6, 7]:\n",
      "        ...     x = rndm.normal(size=10**n)\n",
      "        ...     m, k = stats.moment(x, 3), stats.kstat(x, 3)\n",
      "        ...     print(\"%.3g %.3g %.3g\" % (m, k, m-k))\n",
      "        -0.631 -0.651 0.0194\n",
      "        0.0282 0.0283 -8.49e-05\n",
      "        -0.0454 -0.0454 1.36e-05\n",
      "        7.53e-05 7.53e-05 -2.26e-09\n",
      "        0.00166 0.00166 -4.99e-09\n",
      "        -2.88e-06 -2.88e-06 8.63e-13\n",
      "    \n",
      "    kstatvar(data, n=2)\n",
      "        Return an unbiased estimator of the variance of the k-statistic.\n",
      "        \n",
      "        See `kstat` for more details of the k-statistic.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data : array_like\n",
      "            Input array. Note that n-D input gets flattened.\n",
      "        n : int, {1, 2}, optional\n",
      "            Default is equal to 2.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        kstatvar : float\n",
      "            The nth k-statistic variance.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        kstat: Returns the n-th k-statistic.\n",
      "        moment: Returns the n-th central moment about the mean for a sample.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The variances of the first few k-statistics are given by:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            var(k_{1}) = \\frac{\\kappa^2}{n}\n",
      "            var(k_{2}) = \\frac{\\kappa^4}{n} + \\frac{2\\kappa^2_{2}}{n - 1}\n",
      "            var(k_{3}) = \\frac{\\kappa^6}{n} + \\frac{9 \\kappa_2 \\kappa_4}{n - 1} +\n",
      "                         \\frac{9 \\kappa^2_{3}}{n - 1} +\n",
      "                         \\frac{6 n \\kappa^3_{2}}{(n-1) (n-2)}\n",
      "            var(k_{4}) = \\frac{\\kappa^8}{n} + \\frac{16 \\kappa_2 \\kappa_6}{n - 1} +\n",
      "                         \\frac{48 \\kappa_{3} \\kappa_5}{n - 1} +\n",
      "                         \\frac{34 \\kappa^2_{4}}{n-1} + \\frac{72 n \\kappa^2_{2} \\kappa_4}{(n - 1) (n - 2)} +\n",
      "                         \\frac{144 n \\kappa_{2} \\kappa^2_{3}}{(n - 1) (n - 2)} +\n",
      "                         \\frac{24 (n + 1) n \\kappa^4_{2}}{(n - 1) (n - 2) (n - 3)}\n",
      "    \n",
      "    kstest(rvs, cdf, args=(), N=20, alternative='two-sided', mode='approx')\n",
      "        Perform the Kolmogorov-Smirnov test for goodness of fit.\n",
      "        \n",
      "        This performs a test of the distribution F(x) of an observed\n",
      "        random variable against a given distribution G(x). Under the null\n",
      "        hypothesis, the two distributions are identical, F(x)=G(x). The\n",
      "        alternative hypothesis can be either 'two-sided' (default), 'less'\n",
      "        or 'greater'. The KS test is only valid for continuous distributions.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        rvs : str, array_like, or callable\n",
      "            If a string, it should be the name of a distribution in `scipy.stats`.\n",
      "            If an array, it should be a 1-D array of observations of random\n",
      "            variables.\n",
      "            If a callable, it should be a function to generate random variables;\n",
      "            it is required to have a keyword argument `size`.\n",
      "        cdf : str or callable\n",
      "            If a string, it should be the name of a distribution in `scipy.stats`.\n",
      "            If `rvs` is a string then `cdf` can be False or the same as `rvs`.\n",
      "            If a callable, that callable is used to calculate the cdf.\n",
      "        args : tuple, sequence, optional\n",
      "            Distribution parameters, used if `rvs` or `cdf` are strings.\n",
      "        N : int, optional\n",
      "            Sample size if `rvs` is string or callable.  Default is 20.\n",
      "        alternative : {'two-sided', 'less', 'greater'}, optional\n",
      "            Defines the alternative hypothesis.\n",
      "            The following options are available (default is 'two-sided'):\n",
      "        \n",
      "              * 'two-sided'\n",
      "              * 'less': one-sided, see explanation in Notes\n",
      "              * 'greater': one-sided, see explanation in Notes\n",
      "        mode : {'approx', 'asymp'}, optional\n",
      "            Defines the distribution used for calculating the p-value.\n",
      "            The following options are available (default is 'approx'):\n",
      "        \n",
      "              * 'approx': use approximation to exact distribution of test statistic\n",
      "              * 'asymp': use asymptotic distribution of test statistic\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float\n",
      "            KS test statistic, either D, D+ or D-.\n",
      "        pvalue :  float\n",
      "            One-tailed or two-tailed p-value.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        ks_2samp\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        In the one-sided test, the alternative is that the empirical\n",
      "        cumulative distribution function of the random variable is \"less\"\n",
      "        or \"greater\" than the cumulative distribution function G(x) of the\n",
      "        hypothesis, ``F(x)<=G(x)``, resp. ``F(x)>=G(x)``.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        \n",
      "        >>> x = np.linspace(-15, 15, 9)\n",
      "        >>> stats.kstest(x, 'norm')\n",
      "        (0.44435602715924361, 0.038850142705171065)\n",
      "        \n",
      "        >>> np.random.seed(987654321) # set random seed to get the same result\n",
      "        >>> stats.kstest('norm', False, N=100)\n",
      "        (0.058352892479417884, 0.88531190944151261)\n",
      "        \n",
      "        The above lines are equivalent to:\n",
      "        \n",
      "        >>> np.random.seed(987654321)\n",
      "        >>> stats.kstest(stats.norm.rvs(size=100), 'norm')\n",
      "        (0.058352892479417884, 0.88531190944151261)\n",
      "        \n",
      "        *Test against one-sided alternative hypothesis*\n",
      "        \n",
      "        Shift distribution to larger values, so that ``cdf_dgp(x) < norm.cdf(x)``:\n",
      "        \n",
      "        >>> np.random.seed(987654321)\n",
      "        >>> x = stats.norm.rvs(loc=0.2, size=100)\n",
      "        >>> stats.kstest(x,'norm', alternative = 'less')\n",
      "        (0.12464329735846891, 0.040989164077641749)\n",
      "        \n",
      "        Reject equal distribution against alternative hypothesis: less\n",
      "        \n",
      "        >>> stats.kstest(x,'norm', alternative = 'greater')\n",
      "        (0.0072115233216311081, 0.98531158590396395)\n",
      "        \n",
      "        Don't reject equal distribution against alternative hypothesis: greater\n",
      "        \n",
      "        >>> stats.kstest(x,'norm', mode='asymp')\n",
      "        (0.12464329735846891, 0.08944488871182088)\n",
      "        \n",
      "        *Testing t distributed random variables against normal distribution*\n",
      "        \n",
      "        With 100 degrees of freedom the t distribution looks close to the normal\n",
      "        distribution, and the K-S test does not reject the hypothesis that the\n",
      "        sample came from the normal distribution:\n",
      "        \n",
      "        >>> np.random.seed(987654321)\n",
      "        >>> stats.kstest(stats.t.rvs(100,size=100),'norm')\n",
      "        (0.072018929165471257, 0.67630062862479168)\n",
      "        \n",
      "        With 3 degrees of freedom the t distribution looks sufficiently different\n",
      "        from the normal distribution, that we can reject the hypothesis that the\n",
      "        sample came from the normal distribution at the 10% level:\n",
      "        \n",
      "        >>> np.random.seed(987654321)\n",
      "        >>> stats.kstest(stats.t.rvs(3,size=100),'norm')\n",
      "        (0.131016895759829, 0.058826222555312224)\n",
      "    \n",
      "    kurtosis(a, axis=0, fisher=True, bias=True, nan_policy='propagate')\n",
      "        Compute the kurtosis (Fisher or Pearson) of a dataset.\n",
      "        \n",
      "        Kurtosis is the fourth central moment divided by the square of the\n",
      "        variance. If Fisher's definition is used, then 3.0 is subtracted from\n",
      "        the result to give 0.0 for a normal distribution.\n",
      "        \n",
      "        If bias is False then the kurtosis is calculated using k statistics to\n",
      "        eliminate bias coming from biased moment estimators\n",
      "        \n",
      "        Use `kurtosistest` to see if result is close enough to normal.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array\n",
      "            Data for which the kurtosis is calculated.\n",
      "        axis : int or None, optional\n",
      "            Axis along which the kurtosis is calculated. Default is 0.\n",
      "            If None, compute over the whole array `a`.\n",
      "        fisher : bool, optional\n",
      "            If True, Fisher's definition is used (normal ==> 0.0). If False,\n",
      "            Pearson's definition is used (normal ==> 3.0).\n",
      "        bias : bool, optional\n",
      "            If False, then the calculations are corrected for statistical bias.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan. 'propagate' returns nan,\n",
      "            'raise' throws an error, 'omit' performs the calculations ignoring nan\n",
      "            values. Default is 'propagate'.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        kurtosis : array\n",
      "            The kurtosis of values along an axis. If all values are equal,\n",
      "            return -3 for Fisher's definition and 0 for Pearson's definition.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Zwillinger, D. and Kokoska, S. (2000). CRC Standard\n",
      "           Probability and Statistics Tables and Formulae. Chapman & Hall: New\n",
      "           York. 2000.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        In Fisher's definiton, the kurtosis of the normal distribution is zero.\n",
      "        In the following example, the kurtosis is close to zero, because it was\n",
      "        calculated from the dataset, not from the continuous distribution.\n",
      "        \n",
      "        >>> from scipy.stats import norm, kurtosis\n",
      "        >>> data = norm.rvs(size=1000, random_state=3)\n",
      "        >>> kurtosis(data)\n",
      "        -0.06928694200380558\n",
      "        \n",
      "        The distribution with a higher kurtosis has a heavier tail.\n",
      "        The zero valued kurtosis of the normal distribution in Fisher's definition\n",
      "        can serve as a reference point.\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> import scipy.stats as stats\n",
      "        >>> from scipy.stats import kurtosis\n",
      "        \n",
      "        >>> x = np.linspace(-5, 5, 100)\n",
      "        >>> ax = plt.subplot()\n",
      "        >>> distnames = ['laplace', 'norm', 'uniform']\n",
      "        \n",
      "        >>> for distname in distnames:\n",
      "        ...     if distname == 'uniform':\n",
      "        ...         dist = getattr(stats, distname)(loc=-2, scale=4)\n",
      "        ...     else:\n",
      "        ...         dist = getattr(stats, distname)\n",
      "        ...     data = dist.rvs(size=1000)\n",
      "        ...     kur = kurtosis(data, fisher=True)\n",
      "        ...     y = dist.pdf(x)\n",
      "        ...     ax.plot(x, y, label=\"{}, {}\".format(distname, round(kur, 3)))\n",
      "        ...     ax.legend()\n",
      "        \n",
      "        The Laplace distribution has a heavier tail than the normal distribution.\n",
      "        The uniform distribution (which has negative kurtosis) has the thinnest\n",
      "        tail.\n",
      "    \n",
      "    kurtosistest(a, axis=0, nan_policy='propagate')\n",
      "        Test whether a dataset has normal kurtosis.\n",
      "        \n",
      "        This function tests the null hypothesis that the kurtosis\n",
      "        of the population from which the sample was drawn is that\n",
      "        of the normal distribution: ``kurtosis = 3(n-1)/(n+1)``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array\n",
      "            Array of the sample data.\n",
      "        axis : int or None, optional\n",
      "           Axis along which to compute test. Default is 0. If None,\n",
      "           compute over the whole array `a`.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan.\n",
      "            The following options are available (default is 'propagate'):\n",
      "        \n",
      "              * 'propagate': returns nan\n",
      "              * 'raise': throws an error\n",
      "              * 'omit': performs the calculations ignoring nan values\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float\n",
      "            The computed z-score for this test.\n",
      "        pvalue : float\n",
      "            The two-sided p-value for the hypothesis test.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Valid only for n>20. This function uses the method described in [1]_.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] see e.g. F. J. Anscombe, W. J. Glynn, \"Distribution of the kurtosis\n",
      "           statistic b2 for normal samples\", Biometrika, vol. 70, pp. 227-234, 1983.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.stats import kurtosistest\n",
      "        >>> kurtosistest(list(range(20)))\n",
      "        KurtosistestResult(statistic=-1.7058104152122062, pvalue=0.08804338332528348)\n",
      "        \n",
      "        >>> np.random.seed(28041990)\n",
      "        >>> s = np.random.normal(0, 1, 1000)\n",
      "        >>> kurtosistest(s)\n",
      "        KurtosistestResult(statistic=1.2317590987707365, pvalue=0.21803908613450895)\n",
      "    \n",
      "    levene(*args, **kwds)\n",
      "        Perform Levene test for equal variances.\n",
      "        \n",
      "        The Levene test tests the null hypothesis that all input samples\n",
      "        are from populations with equal variances.  Levene's test is an\n",
      "        alternative to Bartlett's test `bartlett` in the case where\n",
      "        there are significant deviations from normality.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        sample1, sample2, ... : array_like\n",
      "            The sample data, possibly with different lengths. Only one-dimensional\n",
      "            samples are accepted.\n",
      "        center : {'mean', 'median', 'trimmed'}, optional\n",
      "            Which function of the data to use in the test.  The default\n",
      "            is 'median'.\n",
      "        proportiontocut : float, optional\n",
      "            When `center` is 'trimmed', this gives the proportion of data points\n",
      "            to cut from each end. (See `scipy.stats.trim_mean`.)\n",
      "            Default is 0.05.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float\n",
      "            The test statistic.\n",
      "        pvalue : float\n",
      "            The p-value for the test.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Three variations of Levene's test are possible.  The possibilities\n",
      "        and their recommended usages are:\n",
      "        \n",
      "          * 'median' : Recommended for skewed (non-normal) distributions>\n",
      "          * 'mean' : Recommended for symmetric, moderate-tailed distributions.\n",
      "          * 'trimmed' : Recommended for heavy-tailed distributions.\n",
      "        \n",
      "        The test version using the mean was proposed in the original article\n",
      "        of Levene ([2]_) while the median and trimmed mean have been studied by\n",
      "        Brown and Forsythe ([3]_), sometimes also referred to as Brown-Forsythe\n",
      "        test.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1]  https://www.itl.nist.gov/div898/handbook/eda/section3/eda35a.htm\n",
      "        .. [2]   Levene, H. (1960). In Contributions to Probability and Statistics:\n",
      "                   Essays in Honor of Harold Hotelling, I. Olkin et al. eds.,\n",
      "                   Stanford University Press, pp. 278-292.\n",
      "        .. [3]  Brown, M. B. and Forsythe, A. B. (1974), Journal of the American\n",
      "                  Statistical Association, 69, 364-367\n",
      "    \n",
      "    linregress(x, y=None)\n",
      "        Calculate a linear least-squares regression for two sets of measurements.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x, y : array_like\n",
      "            Two sets of measurements.  Both arrays should have the same length.  If\n",
      "            only `x` is given (and ``y=None``), then it must be a two-dimensional\n",
      "            array where one dimension has length 2.  The two sets of measurements\n",
      "            are then found by splitting the array along the length-2 dimension.  In\n",
      "            the case where ``y=None`` and `x` is a 2x2 array, ``linregress(x)`` is\n",
      "            equivalent to ``linregress(x[0], x[1])``.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        slope : float\n",
      "            Slope of the regression line.\n",
      "        intercept : float\n",
      "            Intercept of the regression line.\n",
      "        rvalue : float\n",
      "            Correlation coefficient.\n",
      "        pvalue : float\n",
      "            Two-sided p-value for a hypothesis test whose null hypothesis is\n",
      "            that the slope is zero, using Wald Test with t-distribution of\n",
      "            the test statistic.\n",
      "        stderr : float\n",
      "            Standard error of the estimated gradient.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        :func:`scipy.optimize.curve_fit` : Use non-linear\n",
      "         least squares to fit a function to data.\n",
      "        :func:`scipy.optimize.leastsq` : Minimize the sum of\n",
      "         squares of a set of equations.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Missing values are considered pair-wise: if a value is missing in `x`,\n",
      "        the corresponding value in `y` is masked.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> from scipy import stats\n",
      "        \n",
      "        Generate some data:\n",
      "        \n",
      "        >>> np.random.seed(12345678)\n",
      "        >>> x = np.random.random(10)\n",
      "        >>> y = 1.6*x + np.random.random(10)\n",
      "        \n",
      "        Perform the linear regression:\n",
      "        \n",
      "        >>> slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
      "        >>> print(\"slope: %f    intercept: %f\" % (slope, intercept))\n",
      "        slope: 1.944864    intercept: 0.268578\n",
      "        \n",
      "        To get coefficient of determination (R-squared):\n",
      "        \n",
      "        >>> print(\"R-squared: %f\" % r_value**2)\n",
      "        R-squared: 0.735498\n",
      "        \n",
      "        Plot the data along with the fitted line:\n",
      "        \n",
      "        >>> plt.plot(x, y, 'o', label='original data')\n",
      "        >>> plt.plot(x, intercept + slope*x, 'r', label='fitted line')\n",
      "        >>> plt.legend()\n",
      "        >>> plt.show()\n",
      "        \n",
      "        Example for the case where only x is provided as a 2x2 array:\n",
      "        \n",
      "        >>> x = np.array([[0, 1], [0, 2]])\n",
      "        >>> r = stats.linregress(x)\n",
      "        >>> r.slope, r.intercept\n",
      "        (2.0, 0.0)\n",
      "    \n",
      "    mannwhitneyu(x, y, use_continuity=True, alternative=None)\n",
      "        Compute the Mann-Whitney rank test on samples x and y.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x, y : array_like\n",
      "            Array of samples, should be one-dimensional.\n",
      "        use_continuity : bool, optional\n",
      "                Whether a continuity correction (1/2.) should be taken into\n",
      "                account. Default is True.\n",
      "        alternative : {None, 'two-sided', 'less', 'greater'}, optional\n",
      "            Defines the alternative hypothesis.\n",
      "            The following options are available (default is None):\n",
      "        \n",
      "              * None: computes p-value half the size of the 'two-sided' p-value and\n",
      "                a different U statistic. The default behavior is not the same as\n",
      "                using 'less' or 'greater'; it only exists for backward compatibility\n",
      "                and is deprecated.\n",
      "              * 'two-sided'\n",
      "              * 'less': one-sided\n",
      "              * 'greater': one-sided\n",
      "        \n",
      "            Use of the None option is deprecated.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float\n",
      "            The Mann-Whitney U statistic, equal to min(U for x, U for y) if\n",
      "            `alternative` is equal to None (deprecated; exists for backward\n",
      "            compatibility), and U for y otherwise.\n",
      "        pvalue : float\n",
      "            p-value assuming an asymptotic normal distribution. One-sided or\n",
      "            two-sided, depending on the choice of `alternative`.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Use only when the number of observation in each sample is > 20 and\n",
      "        you have 2 independent samples of ranks. Mann-Whitney U is\n",
      "        significant if the u-obtained is LESS THAN or equal to the critical\n",
      "        value of U.\n",
      "        \n",
      "        This test corrects for ties and by default uses a continuity correction.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] https://en.wikipedia.org/wiki/Mann-Whitney_U_test\n",
      "        \n",
      "        .. [2] H.B. Mann and D.R. Whitney, \"On a Test of Whether one of Two Random\n",
      "               Variables is Stochastically Larger than the Other,\" The Annals of\n",
      "               Mathematical Statistics, vol. 18, no. 1, pp. 50-60, 1947.\n",
      "    \n",
      "    median_absolute_deviation(x, axis=0, center=<function median at 0x7ff328307d40>, scale=1.4826, nan_policy='propagate')\n",
      "        Compute the median absolute deviation of the data along the given axis.\n",
      "        \n",
      "        The median absolute deviation (MAD, [1]_) computes the median over the\n",
      "        absolute deviations from the median. It is a measure of dispersion\n",
      "        similar to the standard deviation but more robust to outliers [2]_.\n",
      "        \n",
      "        The MAD of an empty array is ``np.nan``.\n",
      "        \n",
      "        .. versionadded:: 1.3.0\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Input array or object that can be converted to an array.\n",
      "        axis : int or None, optional\n",
      "            Axis along which the range is computed. Default is 0. If None, compute\n",
      "            the MAD over the entire array.\n",
      "        center : callable, optional\n",
      "            A function that will return the central value. The default is to use\n",
      "            np.median. Any user defined function used will need to have the function\n",
      "            signature ``func(arr, axis)``.\n",
      "        scale : int, optional\n",
      "            The scaling factor applied to the MAD. The default scale (1.4826)\n",
      "            ensures consistency with the standard deviation for normally distributed\n",
      "            data.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan.\n",
      "            The following options are available (default is 'propagate'):\n",
      "        \n",
      "              * 'propagate': returns nan\n",
      "              * 'raise': throws an error\n",
      "              * 'omit': performs the calculations ignoring nan values\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        mad : scalar or ndarray\n",
      "            If ``axis=None``, a scalar is returned. If the input contains\n",
      "            integers or floats of smaller precision than ``np.float64``, then the\n",
      "            output data-type is ``np.float64``. Otherwise, the output data-type is\n",
      "            the same as that of the input.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        numpy.std, numpy.var, numpy.median, scipy.stats.iqr, scipy.stats.tmean,\n",
      "        scipy.stats.tstd, scipy.stats.tvar\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The `center` argument only affects the calculation of the central value\n",
      "        around which the MAD is calculated. That is, passing in ``center=np.mean``\n",
      "        will calculate the MAD around the mean - it will not calculate the *mean*\n",
      "        absolute deviation.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] \"Median absolute deviation\" https://en.wikipedia.org/wiki/Median_absolute_deviation\n",
      "        .. [2] \"Robust measures of scale\" https://en.wikipedia.org/wiki/Robust_measures_of_scale\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        When comparing the behavior of `median_absolute_deviation` with ``np.std``,\n",
      "        the latter is affected when we change a single value of an array to have an\n",
      "        outlier value while the MAD hardly changes:\n",
      "        \n",
      "        >>> from scipy import stats\n",
      "        >>> x = stats.norm.rvs(size=100, scale=1, random_state=123456)\n",
      "        >>> x.std()\n",
      "        0.9973906394005013\n",
      "        >>> stats.median_absolute_deviation(x)\n",
      "        1.2280762773108278\n",
      "        >>> x[0] = 345.6\n",
      "        >>> x.std()\n",
      "        34.42304872314415\n",
      "        >>> stats.median_absolute_deviation(x)\n",
      "        1.2340335571164334\n",
      "        \n",
      "        Axis handling example:\n",
      "        \n",
      "        >>> x = np.array([[10, 7, 4], [3, 2, 1]])\n",
      "        >>> x\n",
      "        array([[10,  7,  4],\n",
      "               [ 3,  2,  1]])\n",
      "        >>> stats.median_absolute_deviation(x)\n",
      "        array([5.1891, 3.7065, 2.2239])\n",
      "        >>> stats.median_absolute_deviation(x, axis=None)\n",
      "        2.9652\n",
      "    \n",
      "    median_test(*args, **kwds)\n",
      "        Perform a Mood's median test.\n",
      "        \n",
      "        Test that two or more samples come from populations with the same median.\n",
      "        \n",
      "        Let ``n = len(args)`` be the number of samples.  The \"grand median\" of\n",
      "        all the data is computed, and a contingency table is formed by\n",
      "        classifying the values in each sample as being above or below the grand\n",
      "        median.  The contingency table, along with `correction` and `lambda_`,\n",
      "        are passed to `scipy.stats.chi2_contingency` to compute the test statistic\n",
      "        and p-value.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        sample1, sample2, ... : array_like\n",
      "            The set of samples.  There must be at least two samples.\n",
      "            Each sample must be a one-dimensional sequence containing at least\n",
      "            one value.  The samples are not required to have the same length.\n",
      "        ties : str, optional\n",
      "            Determines how values equal to the grand median are classified in\n",
      "            the contingency table.  The string must be one of::\n",
      "        \n",
      "                \"below\":\n",
      "                    Values equal to the grand median are counted as \"below\".\n",
      "                \"above\":\n",
      "                    Values equal to the grand median are counted as \"above\".\n",
      "                \"ignore\":\n",
      "                    Values equal to the grand median are not counted.\n",
      "        \n",
      "            The default is \"below\".\n",
      "        correction : bool, optional\n",
      "            If True, *and* there are just two samples, apply Yates' correction\n",
      "            for continuity when computing the test statistic associated with\n",
      "            the contingency table.  Default is True.\n",
      "        lambda_ : float or str, optional\n",
      "            By default, the statistic computed in this test is Pearson's\n",
      "            chi-squared statistic.  `lambda_` allows a statistic from the\n",
      "            Cressie-Read power divergence family to be used instead.  See\n",
      "            `power_divergence` for details.\n",
      "            Default is 1 (Pearson's chi-squared statistic).\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan. 'propagate' returns nan,\n",
      "            'raise' throws an error, 'omit' performs the calculations ignoring nan\n",
      "            values. Default is 'propagate'.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        stat : float\n",
      "            The test statistic.  The statistic that is returned is determined by\n",
      "            `lambda_`.  The default is Pearson's chi-squared statistic.\n",
      "        p : float\n",
      "            The p-value of the test.\n",
      "        m : float\n",
      "            The grand median.\n",
      "        table : ndarray\n",
      "            The contingency table.  The shape of the table is (2, n), where\n",
      "            n is the number of samples.  The first row holds the counts of the\n",
      "            values above the grand median, and the second row holds the counts\n",
      "            of the values below the grand median.  The table allows further\n",
      "            analysis with, for example, `scipy.stats.chi2_contingency`, or with\n",
      "            `scipy.stats.fisher_exact` if there are two samples, without having\n",
      "            to recompute the table.  If ``nan_policy`` is \"propagate\" and there\n",
      "            are nans in the input, the return value for ``table`` is ``None``.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        kruskal : Compute the Kruskal-Wallis H-test for independent samples.\n",
      "        mannwhitneyu : Computes the Mann-Whitney rank test on samples x and y.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        .. versionadded:: 0.15.0\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Mood, A. M., Introduction to the Theory of Statistics. McGraw-Hill\n",
      "            (1950), pp. 394-399.\n",
      "        .. [2] Zar, J. H., Biostatistical Analysis, 5th ed. Prentice Hall (2010).\n",
      "            See Sections 8.12 and 10.15.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        A biologist runs an experiment in which there are three groups of plants.\n",
      "        Group 1 has 16 plants, group 2 has 15 plants, and group 3 has 17 plants.\n",
      "        Each plant produces a number of seeds.  The seed counts for each group\n",
      "        are::\n",
      "        \n",
      "            Group 1: 10 14 14 18 20 22 24 25 31 31 32 39 43 43 48 49\n",
      "            Group 2: 28 30 31 33 34 35 36 40 44 55 57 61 91 92 99\n",
      "            Group 3:  0  3  9 22 23 25 25 33 34 34 40 45 46 48 62 67 84\n",
      "        \n",
      "        The following code applies Mood's median test to these samples.\n",
      "        \n",
      "        >>> g1 = [10, 14, 14, 18, 20, 22, 24, 25, 31, 31, 32, 39, 43, 43, 48, 49]\n",
      "        >>> g2 = [28, 30, 31, 33, 34, 35, 36, 40, 44, 55, 57, 61, 91, 92, 99]\n",
      "        >>> g3 = [0, 3, 9, 22, 23, 25, 25, 33, 34, 34, 40, 45, 46, 48, 62, 67, 84]\n",
      "        >>> from scipy.stats import median_test\n",
      "        >>> stat, p, med, tbl = median_test(g1, g2, g3)\n",
      "        \n",
      "        The median is\n",
      "        \n",
      "        >>> med\n",
      "        34.0\n",
      "        \n",
      "        and the contingency table is\n",
      "        \n",
      "        >>> tbl\n",
      "        array([[ 5, 10,  7],\n",
      "               [11,  5, 10]])\n",
      "        \n",
      "        `p` is too large to conclude that the medians are not the same:\n",
      "        \n",
      "        >>> p\n",
      "        0.12609082774093244\n",
      "        \n",
      "        The \"G-test\" can be performed by passing ``lambda_=\"log-likelihood\"`` to\n",
      "        `median_test`.\n",
      "        \n",
      "        >>> g, p, med, tbl = median_test(g1, g2, g3, lambda_=\"log-likelihood\")\n",
      "        >>> p\n",
      "        0.12224779737117837\n",
      "        \n",
      "        The median occurs several times in the data, so we'll get a different\n",
      "        result if, for example, ``ties=\"above\"`` is used:\n",
      "        \n",
      "        >>> stat, p, med, tbl = median_test(g1, g2, g3, ties=\"above\")\n",
      "        >>> p\n",
      "        0.063873276069553273\n",
      "        \n",
      "        >>> tbl\n",
      "        array([[ 5, 11,  9],\n",
      "               [11,  4,  8]])\n",
      "        \n",
      "        This example demonstrates that if the data set is not large and there\n",
      "        are values equal to the median, the p-value can be sensitive to the\n",
      "        choice of `ties`.\n",
      "    \n",
      "    mode(a, axis=0, nan_policy='propagate')\n",
      "        Return an array of the modal (most common) value in the passed array.\n",
      "        \n",
      "        If there is more than one such value, only the smallest is returned.\n",
      "        The bin-count for the modal bins is also returned.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            n-dimensional array of which to find mode(s).\n",
      "        axis : int or None, optional\n",
      "            Axis along which to operate. Default is 0. If None, compute over\n",
      "            the whole array `a`.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan.\n",
      "            The following options are available (default is 'propagate'):\n",
      "        \n",
      "              * 'propagate': returns nan\n",
      "              * 'raise': throws an error\n",
      "              * 'omit': performs the calculations ignoring nan values\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        mode : ndarray\n",
      "            Array of modal values.\n",
      "        count : ndarray\n",
      "            Array of counts for each mode.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> a = np.array([[6, 8, 3, 0],\n",
      "        ...               [3, 2, 1, 7],\n",
      "        ...               [8, 1, 8, 4],\n",
      "        ...               [5, 3, 0, 5],\n",
      "        ...               [4, 7, 5, 9]])\n",
      "        >>> from scipy import stats\n",
      "        >>> stats.mode(a)\n",
      "        (array([[3, 1, 0, 0]]), array([[1, 1, 1, 1]]))\n",
      "        \n",
      "        To get mode of whole array, specify ``axis=None``:\n",
      "        \n",
      "        >>> stats.mode(a, axis=None)\n",
      "        (array([3]), array([3]))\n",
      "    \n",
      "    moment(a, moment=1, axis=0, nan_policy='propagate')\n",
      "        Calculate the nth moment about the mean for a sample.\n",
      "        \n",
      "        A moment is a specific quantitative measure of the shape of a set of\n",
      "        points. It is often used to calculate coefficients of skewness and kurtosis\n",
      "        due to its close relationship with them.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "           Input array.\n",
      "        moment : int or array_like of ints, optional\n",
      "           Order of central moment that is returned. Default is 1.\n",
      "        axis : int or None, optional\n",
      "           Axis along which the central moment is computed. Default is 0.\n",
      "           If None, compute over the whole array `a`.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan.\n",
      "            The following options are available (default is 'propagate'):\n",
      "        \n",
      "              * 'propagate': returns nan\n",
      "              * 'raise': throws an error\n",
      "              * 'omit': performs the calculations ignoring nan values\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        n-th central moment : ndarray or float\n",
      "           The appropriate moment along the given axis or over all values if axis\n",
      "           is None. The denominator for the moment calculation is the number of\n",
      "           observations, no degrees of freedom correction is done.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        kurtosis, skew, describe\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The k-th central moment of a data sample is:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            m_k = \\frac{1}{n} \\sum_{i = 1}^n (x_i - \\bar{x})^k\n",
      "        \n",
      "        Where n is the number of samples and x-bar is the mean. This function uses\n",
      "        exponentiation by squares [1]_ for efficiency.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] https://eli.thegreenplace.net/2009/03/21/efficient-integer-exponentiation-algorithms\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.stats import moment\n",
      "        >>> moment([1, 2, 3, 4, 5], moment=1)\n",
      "        0.0\n",
      "        >>> moment([1, 2, 3, 4, 5], moment=2)\n",
      "        2.0\n",
      "    \n",
      "    mood(x, y, axis=0)\n",
      "        Perform Mood's test for equal scale parameters.\n",
      "        \n",
      "        Mood's two-sample test for scale parameters is a non-parametric\n",
      "        test for the null hypothesis that two samples are drawn from the\n",
      "        same distribution with the same scale parameter.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x, y : array_like\n",
      "            Arrays of sample data.\n",
      "        axis : int, optional\n",
      "            The axis along which the samples are tested.  `x` and `y` can be of\n",
      "            different length along `axis`.\n",
      "            If `axis` is None, `x` and `y` are flattened and the test is done on\n",
      "            all values in the flattened arrays.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        z : scalar or ndarray\n",
      "            The z-score for the hypothesis test.  For 1-D inputs a scalar is\n",
      "            returned.\n",
      "        p-value : scalar ndarray\n",
      "            The p-value for the hypothesis test.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        fligner : A non-parametric test for the equality of k variances\n",
      "        ansari : A non-parametric test for the equality of 2 variances\n",
      "        bartlett : A parametric test for equality of k variances in normal samples\n",
      "        levene : A parametric test for equality of k variances\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The data are assumed to be drawn from probability distributions ``f(x)``\n",
      "        and ``f(x/s) / s`` respectively, for some probability density function f.\n",
      "        The null hypothesis is that ``s == 1``.\n",
      "        \n",
      "        For multi-dimensional arrays, if the inputs are of shapes\n",
      "        ``(n0, n1, n2, n3)``  and ``(n0, m1, n2, n3)``, then if ``axis=1``, the\n",
      "        resulting z and p values will have shape ``(n0, n2, n3)``.  Note that\n",
      "        ``n1`` and ``m1`` don't have to be equal, but the other dimensions do.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> np.random.seed(1234)\n",
      "        >>> x2 = np.random.randn(2, 45, 6, 7)\n",
      "        >>> x1 = np.random.randn(2, 30, 6, 7)\n",
      "        >>> z, p = stats.mood(x1, x2, axis=1)\n",
      "        >>> p.shape\n",
      "        (2, 6, 7)\n",
      "        \n",
      "        Find the number of points where the difference in scale is not significant:\n",
      "        \n",
      "        >>> (p > 0.1).sum()\n",
      "        74\n",
      "        \n",
      "        Perform the test with different scales:\n",
      "        \n",
      "        >>> x1 = np.random.randn(2, 30)\n",
      "        >>> x2 = np.random.randn(2, 35) * 10.0\n",
      "        >>> stats.mood(x1, x2, axis=1)\n",
      "        (array([-5.7178125 , -5.25342163]), array([  1.07904114e-08,   1.49299218e-07]))\n",
      "    \n",
      "    multiscale_graphcorr(x, y, compute_distance=<function _euclidean_dist at 0x7ff319238b90>, reps=1000, workers=1, is_twosamp=False, random_state=None)\n",
      "        Computes the Multiscale Graph Correlation (MGC) test statistic.\n",
      "        \n",
      "        Specifically, for each point, MGC finds the :math:`k`-nearest neighbors for\n",
      "        one property (e.g. cloud density), and the :math:`l`-nearest neighbors for\n",
      "        the other property (e.g. grass wetness) [1]_. This pair :math:`(k, l)` is\n",
      "        called the \"scale\". A priori, however, it is not know which scales will be\n",
      "        most informative. So, MGC computes all distance pairs, and then efficiently\n",
      "        computes the distance correlations for all scales. The local correlations\n",
      "        illustrate which scales are relatively informative about the relationship.\n",
      "        The key, therefore, to successfully discover and decipher relationships\n",
      "        between disparate data modalities is to adaptively determine which scales\n",
      "        are the most informative, and the geometric implication for the most\n",
      "        informative scales. Doing so not only provides an estimate of whether the\n",
      "        modalities are related, but also provides insight into how the\n",
      "        determination was made. This is especially important in high-dimensional\n",
      "        data, where simple visualizations do not reveal relationships to the\n",
      "        unaided human eye. Characterizations of this implementation in particular\n",
      "        have been derived from and benchmarked within in [2]_.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x, y : ndarray\n",
      "            If ``x`` and ``y`` have shapes ``(n, p)`` and ``(n, q)`` where `n` is\n",
      "            the number of samples and `p` and `q` are the number of dimensions,\n",
      "            then the MGC independence test will be run.  Alternatively, ``x`` and\n",
      "            ``y`` can have shapes ``(n, n)`` if they are distance or similarity\n",
      "            matrices, and ``compute_distance`` must be sent to ``None``. If ``x``\n",
      "            and ``y`` have shapes ``(n, p)`` and ``(m, p)``, an unpaired\n",
      "            two-sample MGC test will be run.\n",
      "        compute_distance : callable, optional\n",
      "            A function that computes the distance or similarity among the samples\n",
      "            within each data matrix. Set to ``None`` if ``x`` and ``y`` are\n",
      "            already distance matrices. The default uses the euclidean norm metric.\n",
      "            If you are calling a custom function, either create the distance\n",
      "            matrix before-hand or create a function of the form\n",
      "            ``compute_distance(x)`` where `x` is the data matrix for which\n",
      "            pairwise distances are calculated.\n",
      "        reps : int, optional\n",
      "            The number of replications used to estimate the null when using the\n",
      "            permutation test. The default is ``1000``.\n",
      "        workers : int or map-like callable, optional\n",
      "            If ``workers`` is an int the population is subdivided into ``workers``\n",
      "            sections and evaluated in parallel (uses ``multiprocessing.Pool\n",
      "            <multiprocessing>``). Supply ``-1`` to use all cores available to the\n",
      "            Process. Alternatively supply a map-like callable, such as\n",
      "            ``multiprocessing.Pool.map`` for evaluating the p-value in parallel.\n",
      "            This evaluation is carried out as ``workers(func, iterable)``.\n",
      "            Requires that `func` be pickleable. The default is ``1``.\n",
      "        is_twosamp : bool, optional\n",
      "            If `True`, a two sample test will be run. If ``x`` and ``y`` have\n",
      "            shapes ``(n, p)`` and ``(m, p)``, this optional will be overriden and\n",
      "            set to ``True``. Set to ``True`` if ``x`` and ``y`` both have shapes\n",
      "            ``(n, p)`` and a two sample test is desired. The default is ``False``.\n",
      "        random_state : int or np.random.RandomState instance, optional\n",
      "            If already a RandomState instance, use it.\n",
      "            If seed is an int, return a new RandomState instance seeded with seed.\n",
      "            If None, use np.random.RandomState. Default is None.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        stat : float\n",
      "            The sample MGC test statistic within `[-1, 1]`.\n",
      "        pvalue : float\n",
      "            The p-value obtained via permutation.\n",
      "        mgc_dict : dict\n",
      "            Contains additional useful additional returns containing the following\n",
      "            keys:\n",
      "        \n",
      "                - mgc_map : ndarray\n",
      "                    A 2D representation of the latent geometry of the relationship.\n",
      "                    of the relationship.\n",
      "                - opt_scale : (int, int)\n",
      "                    The estimated optimal scale as a `(x, y)` pair.\n",
      "                - null_dist : list\n",
      "                    The null distribution derived from the permuted matrices\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        pearsonr : Pearson correlation coefficient and p-value for testing\n",
      "                   non-correlation.\n",
      "        kendalltau : Calculates Kendall's tau.\n",
      "        spearmanr : Calculates a Spearman rank-order correlation coefficient.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        A description of the process of MGC and applications on neuroscience data\n",
      "        can be found in [1]_. It is performed using the following steps:\n",
      "        \n",
      "        #. Two distance matrices :math:`D^X` and :math:`D^Y` are computed and\n",
      "           modified to be mean zero columnwise. This results in two\n",
      "           :math:`n \\times n` distance matrices :math:`A` and :math:`B` (the\n",
      "           centering and unbiased modification) [3]_.\n",
      "        \n",
      "        #. For all values :math:`k` and :math:`l` from :math:`1, ..., n`,\n",
      "        \n",
      "           * The :math:`k`-nearest neighbor and :math:`l`-nearest neighbor graphs\n",
      "             are calculated for each property. Here, :math:`G_k (i, j)` indicates\n",
      "             the :math:`k`-smallest values of the :math:`i`-th row of :math:`A`\n",
      "             and :math:`H_l (i, j)` indicates the :math:`l` smallested values of\n",
      "             the :math:`i`-th row of :math:`B`\n",
      "        \n",
      "           * Let :math:`\\circ` denotes the entry-wise matrix product, then local\n",
      "             correlations are summed and normalized using the following statistic:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            c^{kl} = \\frac{\\sum_{ij} A G_k B H_l}\n",
      "                          {\\sqrt{\\sum_{ij} A^2 G_k \\times \\sum_{ij} B^2 H_l}}\n",
      "        \n",
      "        #. The MGC test statistic is the smoothed optimal local correlation of\n",
      "           :math:`\\{ c^{kl} \\}`. Denote the smoothing operation as :math:`R(\\cdot)`\n",
      "           (which essentially set all isolated large correlations) as 0 and\n",
      "           connected large correlations the same as before, see [3]_.) MGC is,\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            MGC_n (x, y) = \\max_{(k, l)} R \\left(c^{kl} \\left( x_n, y_n \\right)\n",
      "                                                        \\right)\n",
      "        \n",
      "        The test statistic returns a value between :math:`(-1, 1)` since it is\n",
      "        normalized.\n",
      "        \n",
      "        The p-value returned is calculated using a permutation test. This process\n",
      "        is completed by first randomly permuting :math:`y` to estimate the null\n",
      "        distribution and then calculating the probability of observing a test\n",
      "        statistic, under the null, at least as extreme as the observed test\n",
      "        statistic.\n",
      "        \n",
      "        MGC requires at least 5 samples to run with reliable results. It can also\n",
      "        handle high-dimensional data sets.\n",
      "        \n",
      "        In addition, by manipulating the input data matrices, the two-sample\n",
      "        testing problem can be reduced to the independence testing problem [4]_.\n",
      "        Given sample data :math:`U` and :math:`V` of sizes :math:`p \\times n`\n",
      "        :math:`p \\times m`, data matrix :math:`X` and :math:`Y` can be created as\n",
      "        follows:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            X = [U | V] \\in \\mathcal{R}^{p \\times (n + m)}\n",
      "        \n",
      "            Y = [0_{1 \\times n} | 1_{1 \\times m}] \\in \\mathcal{R}^{(n + m)}\n",
      "        \n",
      "        Then, the MGC statistic can be calculated as normal. This methodology can\n",
      "        be extended to similar tests such as distance correlation [4]_.\n",
      "        \n",
      "        .. versionadded:: 1.4.0\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Vogelstein, J. T., Bridgeford, E. W., Wang, Q., Priebe, C. E.,\n",
      "               Maggioni, M., & Shen, C. (2019). Discovering and deciphering\n",
      "               relationships across disparate data modalities. ELife.\n",
      "        .. [2] Panda, S., Palaniappan, S., Xiong, J., Swaminathan, A.,\n",
      "               Ramachandran, S., Bridgeford, E. W., ... Vogelstein, J. T. (2019).\n",
      "               mgcpy: A Comprehensive High Dimensional Independence Testing Python\n",
      "               Package. ArXiv:1907.02088 [Cs, Stat].\n",
      "        .. [3] Shen, C., Priebe, C.E., & Vogelstein, J. T. (2019). From distance\n",
      "               correlation to multiscale graph correlation. Journal of the American\n",
      "               Statistical Association.\n",
      "        .. [4] Shen, C. & Vogelstein, J. T. (2018). The Exact Equivalence of\n",
      "               Distance and Kernel Methods for Hypothesis Testing. ArXiv:1806.05514\n",
      "               [Cs, Stat].\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.stats import multiscale_graphcorr\n",
      "        >>> x = np.arange(100)\n",
      "        >>> y = x\n",
      "        >>> stat, pvalue, _ = multiscale_graphcorr(x, y, workers=-1)\n",
      "        >>> '%.1f, %.3f' % (stat, pvalue)\n",
      "        '1.0, 0.001'\n",
      "        \n",
      "        Alternatively,\n",
      "        \n",
      "        >>> x = np.arange(100)\n",
      "        >>> y = x\n",
      "        >>> mgc = multiscale_graphcorr(x, y)\n",
      "        >>> '%.1f, %.3f' % (mgc.stat, mgc.pvalue)\n",
      "        '1.0, 0.001'\n",
      "        \n",
      "        To run an unpaired two-sample test,\n",
      "        \n",
      "        >>> x = np.arange(100)\n",
      "        >>> y = np.arange(79)\n",
      "        >>> mgc = multiscale_graphcorr(x, y, random_state=1)\n",
      "        >>> '%.3f, %.2f' % (mgc.stat, mgc.pvalue)\n",
      "        '0.033, 0.02'\n",
      "        \n",
      "        or, if shape of the inputs are the same,\n",
      "        \n",
      "        >>> x = np.arange(100)\n",
      "        >>> y = x\n",
      "        >>> mgc = multiscale_graphcorr(x, y, is_twosamp=True)\n",
      "        >>> '%.3f, %.1f' % (mgc.stat, mgc.pvalue)\n",
      "        '-0.008, 1.0'\n",
      "    \n",
      "    mvsdist(data)\n",
      "        'Frozen' distributions for mean, variance, and standard deviation of data.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        data : array_like\n",
      "            Input array. Converted to 1-D using ravel.\n",
      "            Requires 2 or more data-points.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        mdist : \"frozen\" distribution object\n",
      "            Distribution object representing the mean of the data.\n",
      "        vdist : \"frozen\" distribution object\n",
      "            Distribution object representing the variance of the data.\n",
      "        sdist : \"frozen\" distribution object\n",
      "            Distribution object representing the standard deviation of the data.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        bayes_mvs\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The return values from ``bayes_mvs(data)`` is equivalent to\n",
      "        ``tuple((x.mean(), x.interval(0.90)) for x in mvsdist(data))``.\n",
      "        \n",
      "        In other words, calling ``<dist>.mean()`` and ``<dist>.interval(0.90)``\n",
      "        on the three distribution objects returned from this function will give\n",
      "        the same results that are returned from `bayes_mvs`.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        T.E. Oliphant, \"A Bayesian perspective on estimating mean, variance, and\n",
      "        standard-deviation from data\", https://scholarsarchive.byu.edu/facpub/278,\n",
      "        2006.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> data = [6, 9, 12, 7, 8, 8, 13]\n",
      "        >>> mean, var, std = stats.mvsdist(data)\n",
      "        \n",
      "        We now have frozen distribution objects \"mean\", \"var\" and \"std\" that we can\n",
      "        examine:\n",
      "        \n",
      "        >>> mean.mean()\n",
      "        9.0\n",
      "        >>> mean.interval(0.95)\n",
      "        (6.6120585482655692, 11.387941451734431)\n",
      "        >>> mean.std()\n",
      "        1.1952286093343936\n",
      "    \n",
      "    normaltest(a, axis=0, nan_policy='propagate')\n",
      "        Test whether a sample differs from a normal distribution.\n",
      "        \n",
      "        This function tests the null hypothesis that a sample comes\n",
      "        from a normal distribution.  It is based on D'Agostino and\n",
      "        Pearson's [1]_, [2]_ test that combines skew and kurtosis to\n",
      "        produce an omnibus test of normality.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            The array containing the sample to be tested.\n",
      "        axis : int or None, optional\n",
      "            Axis along which to compute test. Default is 0. If None,\n",
      "            compute over the whole array `a`.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan.\n",
      "            The following options are available (default is 'propagate'):\n",
      "        \n",
      "              * 'propagate': returns nan\n",
      "              * 'raise': throws an error\n",
      "              * 'omit': performs the calculations ignoring nan values\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float or array\n",
      "            ``s^2 + k^2``, where ``s`` is the z-score returned by `skewtest` and\n",
      "            ``k`` is the z-score returned by `kurtosistest`.\n",
      "        pvalue : float or array\n",
      "           A 2-sided chi squared probability for the hypothesis test.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] D'Agostino, R. B. (1971), \"An omnibus test of normality for\n",
      "               moderate and large sample size\", Biometrika, 58, 341-348\n",
      "        \n",
      "        .. [2] D'Agostino, R. and Pearson, E. S. (1973), \"Tests for departure from\n",
      "               normality\", Biometrika, 60, 613-622\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> pts = 1000\n",
      "        >>> np.random.seed(28041990)\n",
      "        >>> a = np.random.normal(0, 1, size=pts)\n",
      "        >>> b = np.random.normal(2, 1, size=pts)\n",
      "        >>> x = np.concatenate((a, b))\n",
      "        >>> k2, p = stats.normaltest(x)\n",
      "        >>> alpha = 1e-3\n",
      "        >>> print(\"p = {:g}\".format(p))\n",
      "        p = 3.27207e-11\n",
      "        >>> if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
      "        ...     print(\"The null hypothesis can be rejected\")\n",
      "        ... else:\n",
      "        ...     print(\"The null hypothesis cannot be rejected\")\n",
      "        The null hypothesis can be rejected\n",
      "    \n",
      "    obrientransform(*args)\n",
      "        Compute the O'Brien transform on input data (any number of arrays).\n",
      "        \n",
      "        Used to test for homogeneity of variance prior to running one-way stats.\n",
      "        Each array in ``*args`` is one level of a factor.\n",
      "        If `f_oneway` is run on the transformed data and found significant,\n",
      "        the variances are unequal.  From Maxwell and Delaney [1]_, p.112.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        args : tuple of array_like\n",
      "            Any number of arrays.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        obrientransform : ndarray\n",
      "            Transformed data for use in an ANOVA.  The first dimension\n",
      "            of the result corresponds to the sequence of transformed\n",
      "            arrays.  If the arrays given are all 1-D of the same length,\n",
      "            the return value is a 2-D array; otherwise it is a 1-D array\n",
      "            of type object, with each element being an ndarray.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] S. E. Maxwell and H. D. Delaney, \"Designing Experiments and\n",
      "               Analyzing Data: A Model Comparison Perspective\", Wadsworth, 1990.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        We'll test the following data sets for differences in their variance.\n",
      "        \n",
      "        >>> x = [10, 11, 13, 9, 7, 12, 12, 9, 10]\n",
      "        >>> y = [13, 21, 5, 10, 8, 14, 10, 12, 7, 15]\n",
      "        \n",
      "        Apply the O'Brien transform to the data.\n",
      "        \n",
      "        >>> from scipy.stats import obrientransform\n",
      "        >>> tx, ty = obrientransform(x, y)\n",
      "        \n",
      "        Use `scipy.stats.f_oneway` to apply a one-way ANOVA test to the\n",
      "        transformed data.\n",
      "        \n",
      "        >>> from scipy.stats import f_oneway\n",
      "        >>> F, p = f_oneway(tx, ty)\n",
      "        >>> p\n",
      "        0.1314139477040335\n",
      "        \n",
      "        If we require that ``p < 0.05`` for significance, we cannot conclude\n",
      "        that the variances are different.\n",
      "    \n",
      "    pearsonr(x, y)\n",
      "        Pearson correlation coefficient and p-value for testing non-correlation.\n",
      "        \n",
      "        The Pearson correlation coefficient [1]_ measures the linear relationship\n",
      "        between two datasets.  The calculation of the p-value relies on the\n",
      "        assumption that each dataset is normally distributed.  (See Kowalski [3]_\n",
      "        for a discussion of the effects of non-normality of the input on the\n",
      "        distribution of the correlation coefficient.)  Like other correlation\n",
      "        coefficients, this one varies between -1 and +1 with 0 implying no\n",
      "        correlation. Correlations of -1 or +1 imply an exact linear relationship.\n",
      "        Positive correlations imply that as x increases, so does y. Negative\n",
      "        correlations imply that as x increases, y decreases.\n",
      "        \n",
      "        The p-value roughly indicates the probability of an uncorrelated system\n",
      "        producing datasets that have a Pearson correlation at least as extreme\n",
      "        as the one computed from these datasets.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : (N,) array_like\n",
      "            Input array.\n",
      "        y : (N,) array_like\n",
      "            Input array.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        r : float\n",
      "            Pearson's correlation coefficient.\n",
      "        p-value : float\n",
      "            Two-tailed p-value.\n",
      "        \n",
      "        Warns\n",
      "        -----\n",
      "        PearsonRConstantInputWarning\n",
      "            Raised if an input is a constant array.  The correlation coefficient\n",
      "            is not defined in this case, so ``np.nan`` is returned.\n",
      "        \n",
      "        PearsonRNearConstantInputWarning\n",
      "            Raised if an input is \"nearly\" constant.  The array ``x`` is considered\n",
      "            nearly constant if ``norm(x - mean(x)) < 1e-13 * abs(mean(x))``.\n",
      "            Numerical errors in the calculation ``x - mean(x)`` in this case might\n",
      "            result in an inaccurate calculation of r.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        spearmanr : Spearman rank-order correlation coefficient.\n",
      "        kendalltau : Kendall's tau, a correlation measure for ordinal data.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The correlation coefficient is calculated as follows:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            r = \\frac{\\sum (x - m_x) (y - m_y)}\n",
      "                     {\\sqrt{\\sum (x - m_x)^2 \\sum (y - m_y)^2}}\n",
      "        \n",
      "        where :math:`m_x` is the mean of the vector :math:`x` and :math:`m_y` is\n",
      "        the mean of the vector :math:`y`.\n",
      "        \n",
      "        Under the assumption that x and y are drawn from independent normal\n",
      "        distributions (so the population correlation coefficient is 0), the\n",
      "        probability density function of the sample correlation coefficient r\n",
      "        is ([1]_, [2]_)::\n",
      "        \n",
      "                   (1 - r**2)**(n/2 - 2)\n",
      "            f(r) = ---------------------\n",
      "                      B(1/2, n/2 - 1)\n",
      "        \n",
      "        where n is the number of samples, and B is the beta function.  This\n",
      "        is sometimes referred to as the exact distribution of r.  This is\n",
      "        the distribution that is used in `pearsonr` to compute the p-value.\n",
      "        The distribution is a beta distribution on the interval [-1, 1],\n",
      "        with equal shape parameters a = b = n/2 - 1.  In terms of SciPy's\n",
      "        implementation of the beta distribution, the distribution of r is::\n",
      "        \n",
      "            dist = scipy.stats.beta(n/2 - 1, n/2 - 1, loc=-1, scale=2)\n",
      "        \n",
      "        The p-value returned by `pearsonr` is a two-sided p-value.  For a\n",
      "        given sample with correlation coefficient r, the p-value is\n",
      "        the probability that abs(r') of a random sample x' and y' drawn from\n",
      "        the population with zero correlation would be greater than or equal\n",
      "        to abs(r).  In terms of the object ``dist`` shown above, the p-value\n",
      "        for a given r and length n can be computed as::\n",
      "        \n",
      "            p = 2*dist.cdf(-abs(r))\n",
      "        \n",
      "        When n is 2, the above continuous distribution is not well-defined.\n",
      "        One can interpret the limit of the beta distribution as the shape\n",
      "        parameters a and b approach a = b = 0 as a discrete distribution with\n",
      "        equal probability masses at r = 1 and r = -1.  More directly, one\n",
      "        can observe that, given the data x = [x1, x2] and y = [y1, y2], and\n",
      "        assuming x1 != x2 and y1 != y2, the only possible values for r are 1\n",
      "        and -1.  Because abs(r') for any sample x' and y' with length 2 will\n",
      "        be 1, the two-sided p-value for a sample of length 2 is always 1.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] \"Pearson correlation coefficient\", Wikipedia,\n",
      "               https://en.wikipedia.org/wiki/Pearson_correlation_coefficient\n",
      "        .. [2] Student, \"Probable error of a correlation coefficient\",\n",
      "               Biometrika, Volume 6, Issue 2-3, 1 September 1908, pp. 302-310.\n",
      "        .. [3] C. J. Kowalski, \"On the Effects of Non-Normality on the Distribution\n",
      "               of the Sample Product-Moment Correlation Coefficient\"\n",
      "               Journal of the Royal Statistical Society. Series C (Applied\n",
      "               Statistics), Vol. 21, No. 1 (1972), pp. 1-12.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> a = np.array([0, 0, 0, 1, 1, 1, 1])\n",
      "        >>> b = np.arange(7)\n",
      "        >>> stats.pearsonr(a, b)\n",
      "        (0.8660254037844386, 0.011724811003954649)\n",
      "        \n",
      "        >>> stats.pearsonr([1, 2, 3, 4, 5], [10, 9, 2.5, 6, 4])\n",
      "        (-0.7426106572325057, 0.1505558088534455)\n",
      "    \n",
      "    percentileofscore(a, score, kind='rank')\n",
      "        Compute the percentile rank of a score relative to a list of scores.\n",
      "        \n",
      "        A `percentileofscore` of, for example, 80% means that 80% of the\n",
      "        scores in `a` are below the given score. In the case of gaps or\n",
      "        ties, the exact definition depends on the optional keyword, `kind`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Array of scores to which `score` is compared.\n",
      "        score : int or float\n",
      "            Score that is compared to the elements in `a`.\n",
      "        kind : {'rank', 'weak', 'strict', 'mean'}, optional\n",
      "            Specifies the interpretation of the resulting score.\n",
      "            The following options are available (default is 'rank'):\n",
      "        \n",
      "              * 'rank': Average percentage ranking of score.  In case of multiple\n",
      "                matches, average the percentage rankings of all matching scores.\n",
      "              * 'weak': This kind corresponds to the definition of a cumulative\n",
      "                distribution function.  A percentileofscore of 80% means that 80%\n",
      "                of values are less than or equal to the provided score.\n",
      "              * 'strict': Similar to \"weak\", except that only values that are\n",
      "                strictly less than the given score are counted.\n",
      "              * 'mean': The average of the \"weak\" and \"strict\" scores, often used\n",
      "                in testing.  See https://en.wikipedia.org/wiki/Percentile_rank\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        pcos : float\n",
      "            Percentile-position of score (0-100) relative to `a`.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        numpy.percentile\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Three-quarters of the given values lie below a given score:\n",
      "        \n",
      "        >>> from scipy import stats\n",
      "        >>> stats.percentileofscore([1, 2, 3, 4], 3)\n",
      "        75.0\n",
      "        \n",
      "        With multiple matches, note how the scores of the two matches, 0.6\n",
      "        and 0.8 respectively, are averaged:\n",
      "        \n",
      "        >>> stats.percentileofscore([1, 2, 3, 3, 4], 3)\n",
      "        70.0\n",
      "        \n",
      "        Only 2/5 values are strictly less than 3:\n",
      "        \n",
      "        >>> stats.percentileofscore([1, 2, 3, 3, 4], 3, kind='strict')\n",
      "        40.0\n",
      "        \n",
      "        But 4/5 values are less than or equal to 3:\n",
      "        \n",
      "        >>> stats.percentileofscore([1, 2, 3, 3, 4], 3, kind='weak')\n",
      "        80.0\n",
      "        \n",
      "        The average between the weak and the strict scores is:\n",
      "        \n",
      "        >>> stats.percentileofscore([1, 2, 3, 3, 4], 3, kind='mean')\n",
      "        60.0\n",
      "    \n",
      "    pointbiserialr(x, y)\n",
      "        Calculate a point biserial correlation coefficient and its p-value.\n",
      "        \n",
      "        The point biserial correlation is used to measure the relationship\n",
      "        between a binary variable, x, and a continuous variable, y. Like other\n",
      "        correlation coefficients, this one varies between -1 and +1 with 0\n",
      "        implying no correlation. Correlations of -1 or +1 imply a determinative\n",
      "        relationship.\n",
      "        \n",
      "        This function uses a shortcut formula but produces the same result as\n",
      "        `pearsonr`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like of bools\n",
      "            Input array.\n",
      "        y : array_like\n",
      "            Input array.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        correlation : float\n",
      "            R value.\n",
      "        pvalue : float\n",
      "            Two-sided p-value.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        `pointbiserialr` uses a t-test with ``n-1`` degrees of freedom.\n",
      "        It is equivalent to `pearsonr.`\n",
      "        \n",
      "        The value of the point-biserial correlation can be calculated from:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            r_{pb} = \\frac{\\overline{Y_{1}} -\n",
      "                     \\overline{Y_{0}}}{s_{y}}\\sqrt{\\frac{N_{1} N_{2}}{N (N - 1))}}\n",
      "        \n",
      "        Where :math:`Y_{0}` and :math:`Y_{1}` are means of the metric\n",
      "        observations coded 0 and 1 respectively; :math:`N_{0}` and :math:`N_{1}`\n",
      "        are number of observations coded 0 and 1 respectively; :math:`N` is the\n",
      "        total number of observations and :math:`s_{y}` is the standard\n",
      "        deviation of all the metric observations.\n",
      "        \n",
      "        A value of :math:`r_{pb}` that is significantly different from zero is\n",
      "        completely equivalent to a significant difference in means between the two\n",
      "        groups. Thus, an independent groups t Test with :math:`N-2` degrees of\n",
      "        freedom may be used to test whether :math:`r_{pb}` is nonzero. The\n",
      "        relation between the t-statistic for comparing two independent groups and\n",
      "        :math:`r_{pb}` is given by:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            t = \\sqrt{N - 2}\\frac{r_{pb}}{\\sqrt{1 - r^{2}_{pb}}}\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] J. Lev, \"The Point Biserial Coefficient of Correlation\", Ann. Math.\n",
      "               Statist., Vol. 20, no.1, pp. 125-126, 1949.\n",
      "        \n",
      "        .. [2] R.F. Tate, \"Correlation Between a Discrete and a Continuous\n",
      "               Variable. Point-Biserial Correlation.\", Ann. Math. Statist., Vol. 25,\n",
      "               np. 3, pp. 603-607, 1954.\n",
      "        \n",
      "        .. [3] D. Kornbrot \"Point Biserial Correlation\", In Wiley StatsRef:\n",
      "               Statistics Reference Online (eds N. Balakrishnan, et al.), 2014.\n",
      "               https://doi.org/10.1002/9781118445112.stat06227\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> a = np.array([0, 0, 0, 1, 1, 1, 1])\n",
      "        >>> b = np.arange(7)\n",
      "        >>> stats.pointbiserialr(a, b)\n",
      "        (0.8660254037844386, 0.011724811003954652)\n",
      "        >>> stats.pearsonr(a, b)\n",
      "        (0.86602540378443871, 0.011724811003954626)\n",
      "        >>> np.corrcoef(a, b)\n",
      "        array([[ 1.       ,  0.8660254],\n",
      "               [ 0.8660254,  1.       ]])\n",
      "    \n",
      "    power_divergence(f_obs, f_exp=None, ddof=0, axis=0, lambda_=None)\n",
      "        Cressie-Read power divergence statistic and goodness of fit test.\n",
      "        \n",
      "        This function tests the null hypothesis that the categorical data\n",
      "        has the given frequencies, using the Cressie-Read power divergence\n",
      "        statistic.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        f_obs : array_like\n",
      "            Observed frequencies in each category.\n",
      "        f_exp : array_like, optional\n",
      "            Expected frequencies in each category.  By default the categories are\n",
      "            assumed to be equally likely.\n",
      "        ddof : int, optional\n",
      "            \"Delta degrees of freedom\": adjustment to the degrees of freedom\n",
      "            for the p-value.  The p-value is computed using a chi-squared\n",
      "            distribution with ``k - 1 - ddof`` degrees of freedom, where `k`\n",
      "            is the number of observed frequencies.  The default value of `ddof`\n",
      "            is 0.\n",
      "        axis : int or None, optional\n",
      "            The axis of the broadcast result of `f_obs` and `f_exp` along which to\n",
      "            apply the test.  If axis is None, all values in `f_obs` are treated\n",
      "            as a single data set.  Default is 0.\n",
      "        lambda_ : float or str, optional\n",
      "            The power in the Cressie-Read power divergence statistic.  The default\n",
      "            is 1.  For convenience, `lambda_` may be assigned one of the following\n",
      "            strings, in which case the corresponding numerical value is used::\n",
      "        \n",
      "                String              Value   Description\n",
      "                \"pearson\"             1     Pearson's chi-squared statistic.\n",
      "                                            In this case, the function is\n",
      "                                            equivalent to `stats.chisquare`.\n",
      "                \"log-likelihood\"      0     Log-likelihood ratio. Also known as\n",
      "                                            the G-test [3]_.\n",
      "                \"freeman-tukey\"      -1/2   Freeman-Tukey statistic.\n",
      "                \"mod-log-likelihood\" -1     Modified log-likelihood ratio.\n",
      "                \"neyman\"             -2     Neyman's statistic.\n",
      "                \"cressie-read\"        2/3   The power recommended in [5]_.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float or ndarray\n",
      "            The Cressie-Read power divergence test statistic.  The value is\n",
      "            a float if `axis` is None or if` `f_obs` and `f_exp` are 1-D.\n",
      "        pvalue : float or ndarray\n",
      "            The p-value of the test.  The value is a float if `ddof` and the\n",
      "            return value `stat` are scalars.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        chisquare\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This test is invalid when the observed or expected frequencies in each\n",
      "        category are too small.  A typical rule is that all of the observed\n",
      "        and expected frequencies should be at least 5.\n",
      "        \n",
      "        When `lambda_` is less than zero, the formula for the statistic involves\n",
      "        dividing by `f_obs`, so a warning or error may be generated if any value\n",
      "        in `f_obs` is 0.\n",
      "        \n",
      "        Similarly, a warning or error may be generated if any value in `f_exp` is\n",
      "        zero when `lambda_` >= 0.\n",
      "        \n",
      "        The default degrees of freedom, k-1, are for the case when no parameters\n",
      "        of the distribution are estimated. If p parameters are estimated by\n",
      "        efficient maximum likelihood then the correct degrees of freedom are\n",
      "        k-1-p. If the parameters are estimated in a different way, then the\n",
      "        dof can be between k-1-p and k-1. However, it is also possible that\n",
      "        the asymptotic distribution is not a chisquare, in which case this\n",
      "        test is not appropriate.\n",
      "        \n",
      "        This function handles masked arrays.  If an element of `f_obs` or `f_exp`\n",
      "        is masked, then data at that position is ignored, and does not count\n",
      "        towards the size of the data set.\n",
      "        \n",
      "        .. versionadded:: 0.13.0\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Lowry, Richard.  \"Concepts and Applications of Inferential\n",
      "               Statistics\". Chapter 8.\n",
      "               https://web.archive.org/web/20171015035606/http://faculty.vassar.edu/lowry/ch8pt1.html\n",
      "        .. [2] \"Chi-squared test\", https://en.wikipedia.org/wiki/Chi-squared_test\n",
      "        .. [3] \"G-test\", https://en.wikipedia.org/wiki/G-test\n",
      "        .. [4] Sokal, R. R. and Rohlf, F. J. \"Biometry: the principles and\n",
      "               practice of statistics in biological research\", New York: Freeman\n",
      "               (1981)\n",
      "        .. [5] Cressie, N. and Read, T. R. C., \"Multinomial Goodness-of-Fit\n",
      "               Tests\", J. Royal Stat. Soc. Series B, Vol. 46, No. 3 (1984),\n",
      "               pp. 440-464.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        (See `chisquare` for more examples.)\n",
      "        \n",
      "        When just `f_obs` is given, it is assumed that the expected frequencies\n",
      "        are uniform and given by the mean of the observed frequencies.  Here we\n",
      "        perform a G-test (i.e. use the log-likelihood ratio statistic):\n",
      "        \n",
      "        >>> from scipy.stats import power_divergence\n",
      "        >>> power_divergence([16, 18, 16, 14, 12, 12], lambda_='log-likelihood')\n",
      "        (2.006573162632538, 0.84823476779463769)\n",
      "        \n",
      "        The expected frequencies can be given with the `f_exp` argument:\n",
      "        \n",
      "        >>> power_divergence([16, 18, 16, 14, 12, 12],\n",
      "        ...                  f_exp=[16, 16, 16, 16, 16, 8],\n",
      "        ...                  lambda_='log-likelihood')\n",
      "        (3.3281031458963746, 0.6495419288047497)\n",
      "        \n",
      "        When `f_obs` is 2-D, by default the test is applied to each column.\n",
      "        \n",
      "        >>> obs = np.array([[16, 18, 16, 14, 12, 12], [32, 24, 16, 28, 20, 24]]).T\n",
      "        >>> obs.shape\n",
      "        (6, 2)\n",
      "        >>> power_divergence(obs, lambda_=\"log-likelihood\")\n",
      "        (array([ 2.00657316,  6.77634498]), array([ 0.84823477,  0.23781225]))\n",
      "        \n",
      "        By setting ``axis=None``, the test is applied to all data in the array,\n",
      "        which is equivalent to applying the test to the flattened array.\n",
      "        \n",
      "        >>> power_divergence(obs, axis=None)\n",
      "        (23.31034482758621, 0.015975692534127565)\n",
      "        >>> power_divergence(obs.ravel())\n",
      "        (23.31034482758621, 0.015975692534127565)\n",
      "        \n",
      "        `ddof` is the change to make to the default degrees of freedom.\n",
      "        \n",
      "        >>> power_divergence([16, 18, 16, 14, 12, 12], ddof=1)\n",
      "        (2.0, 0.73575888234288467)\n",
      "        \n",
      "        The calculation of the p-values is done by broadcasting the\n",
      "        test statistic with `ddof`.\n",
      "        \n",
      "        >>> power_divergence([16, 18, 16, 14, 12, 12], ddof=[0,1,2])\n",
      "        (2.0, array([ 0.84914504,  0.73575888,  0.5724067 ]))\n",
      "        \n",
      "        `f_obs` and `f_exp` are also broadcast.  In the following, `f_obs` has\n",
      "        shape (6,) and `f_exp` has shape (2, 6), so the result of broadcasting\n",
      "        `f_obs` and `f_exp` has shape (2, 6).  To compute the desired chi-squared\n",
      "        statistics, we must use ``axis=1``:\n",
      "        \n",
      "        >>> power_divergence([16, 18, 16, 14, 12, 12],\n",
      "        ...                  f_exp=[[16, 16, 16, 16, 16, 8],\n",
      "        ...                         [8, 20, 20, 16, 12, 12]],\n",
      "        ...                  axis=1)\n",
      "        (array([ 3.5 ,  9.25]), array([ 0.62338763,  0.09949846]))\n",
      "    \n",
      "    ppcc_max(x, brack=(0.0, 1.0), dist='tukeylambda')\n",
      "        Calculate the shape parameter that maximizes the PPCC.\n",
      "        \n",
      "        The probability plot correlation coefficient (PPCC) plot can be used to\n",
      "        determine the optimal shape parameter for a one-parameter family of\n",
      "        distributions.  ppcc_max returns the shape parameter that would maximize the\n",
      "        probability plot correlation coefficient for the given data to a\n",
      "        one-parameter family of distributions.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Input array.\n",
      "        brack : tuple, optional\n",
      "            Triple (a,b,c) where (a<b<c). If bracket consists of two numbers (a, c)\n",
      "            then they are assumed to be a starting interval for a downhill bracket\n",
      "            search (see `scipy.optimize.brent`).\n",
      "        dist : str or stats.distributions instance, optional\n",
      "            Distribution or distribution function name.  Objects that look enough\n",
      "            like a stats.distributions instance (i.e. they have a ``ppf`` method)\n",
      "            are also accepted.  The default is ``'tukeylambda'``.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        shape_value : float\n",
      "            The shape parameter at which the probability plot correlation\n",
      "            coefficient reaches its max value.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        ppcc_plot, probplot, boxcox\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The brack keyword serves as a starting point which is useful in corner\n",
      "        cases. One can use a plot to obtain a rough visual estimate of the location\n",
      "        for the maximum to start the search near it.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] J.J. Filliben, \"The Probability Plot Correlation Coefficient Test for\n",
      "               Normality\", Technometrics, Vol. 17, pp. 111-117, 1975.\n",
      "        \n",
      "        .. [2] https://www.itl.nist.gov/div898/handbook/eda/section3/ppccplot.htm\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        First we generate some random data from a Tukey-Lambda distribution,\n",
      "        with shape parameter -0.7:\n",
      "        \n",
      "        >>> from scipy import stats\n",
      "        >>> x = stats.tukeylambda.rvs(-0.7, loc=2, scale=0.5, size=10000,\n",
      "        ...                           random_state=1234567) + 1e4\n",
      "        \n",
      "        Now we explore this data with a PPCC plot as well as the related\n",
      "        probability plot and Box-Cox normplot.  A red line is drawn where we\n",
      "        expect the PPCC value to be maximal (at the shape parameter -0.7 used\n",
      "        above):\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> fig = plt.figure(figsize=(8, 6))\n",
      "        >>> ax = fig.add_subplot(111)\n",
      "        >>> res = stats.ppcc_plot(x, -5, 5, plot=ax)\n",
      "        \n",
      "        We calculate the value where the shape should reach its maximum and a red\n",
      "        line is drawn there. The line should coincide with the highest point in the\n",
      "        ppcc_plot.\n",
      "        \n",
      "        >>> max = stats.ppcc_max(x)\n",
      "        >>> ax.vlines(max, 0, 1, colors='r', label='Expected shape value')\n",
      "        \n",
      "        >>> plt.show()\n",
      "    \n",
      "    ppcc_plot(x, a, b, dist='tukeylambda', plot=None, N=80)\n",
      "        Calculate and optionally plot probability plot correlation coefficient.\n",
      "        \n",
      "        The probability plot correlation coefficient (PPCC) plot can be used to\n",
      "        determine the optimal shape parameter for a one-parameter family of\n",
      "        distributions.  It cannot be used for distributions without shape parameters\n",
      "        (like the normal distribution) or with multiple shape parameters.\n",
      "        \n",
      "        By default a Tukey-Lambda distribution (`stats.tukeylambda`) is used. A\n",
      "        Tukey-Lambda PPCC plot interpolates from long-tailed to short-tailed\n",
      "        distributions via an approximately normal one, and is therefore particularly\n",
      "        useful in practice.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Input array.\n",
      "        a, b : scalar\n",
      "            Lower and upper bounds of the shape parameter to use.\n",
      "        dist : str or stats.distributions instance, optional\n",
      "            Distribution or distribution function name.  Objects that look enough\n",
      "            like a stats.distributions instance (i.e. they have a ``ppf`` method)\n",
      "            are also accepted.  The default is ``'tukeylambda'``.\n",
      "        plot : object, optional\n",
      "            If given, plots PPCC against the shape parameter.\n",
      "            `plot` is an object that has to have methods \"plot\" and \"text\".\n",
      "            The `matplotlib.pyplot` module or a Matplotlib Axes object can be used,\n",
      "            or a custom object with the same methods.\n",
      "            Default is None, which means that no plot is created.\n",
      "        N : int, optional\n",
      "            Number of points on the horizontal axis (equally distributed from\n",
      "            `a` to `b`).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        svals : ndarray\n",
      "            The shape values for which `ppcc` was calculated.\n",
      "        ppcc : ndarray\n",
      "            The calculated probability plot correlation coefficient values.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        ppcc_max, probplot, boxcox_normplot, tukeylambda\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        J.J. Filliben, \"The Probability Plot Correlation Coefficient Test for\n",
      "        Normality\", Technometrics, Vol. 17, pp. 111-117, 1975.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        First we generate some random data from a Tukey-Lambda distribution,\n",
      "        with shape parameter -0.7:\n",
      "        \n",
      "        >>> from scipy import stats\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> np.random.seed(1234567)\n",
      "        >>> x = stats.tukeylambda.rvs(-0.7, loc=2, scale=0.5, size=10000) + 1e4\n",
      "        \n",
      "        Now we explore this data with a PPCC plot as well as the related\n",
      "        probability plot and Box-Cox normplot.  A red line is drawn where we\n",
      "        expect the PPCC value to be maximal (at the shape parameter -0.7 used\n",
      "        above):\n",
      "        \n",
      "        >>> fig = plt.figure(figsize=(12, 4))\n",
      "        >>> ax1 = fig.add_subplot(131)\n",
      "        >>> ax2 = fig.add_subplot(132)\n",
      "        >>> ax3 = fig.add_subplot(133)\n",
      "        >>> res = stats.probplot(x, plot=ax1)\n",
      "        >>> res = stats.boxcox_normplot(x, -5, 5, plot=ax2)\n",
      "        >>> res = stats.ppcc_plot(x, -5, 5, plot=ax3)\n",
      "        >>> ax3.vlines(-0.7, 0, 1, colors='r', label='Expected shape value')\n",
      "        >>> plt.show()\n",
      "    \n",
      "    probplot(x, sparams=(), dist='norm', fit=True, plot=None, rvalue=False)\n",
      "        Calculate quantiles for a probability plot, and optionally show the plot.\n",
      "        \n",
      "        Generates a probability plot of sample data against the quantiles of a\n",
      "        specified theoretical distribution (the normal distribution by default).\n",
      "        `probplot` optionally calculates a best-fit line for the data and plots the\n",
      "        results using Matplotlib or a given plot function.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Sample/response data from which `probplot` creates the plot.\n",
      "        sparams : tuple, optional\n",
      "            Distribution-specific shape parameters (shape parameters plus location\n",
      "            and scale).\n",
      "        dist : str or stats.distributions instance, optional\n",
      "            Distribution or distribution function name. The default is 'norm' for a\n",
      "            normal probability plot.  Objects that look enough like a\n",
      "            stats.distributions instance (i.e. they have a ``ppf`` method) are also\n",
      "            accepted.\n",
      "        fit : bool, optional\n",
      "            Fit a least-squares regression (best-fit) line to the sample data if\n",
      "            True (default).\n",
      "        plot : object, optional\n",
      "            If given, plots the quantiles and least squares fit.\n",
      "            `plot` is an object that has to have methods \"plot\" and \"text\".\n",
      "            The `matplotlib.pyplot` module or a Matplotlib Axes object can be used,\n",
      "            or a custom object with the same methods.\n",
      "            Default is None, which means that no plot is created.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        (osm, osr) : tuple of ndarrays\n",
      "            Tuple of theoretical quantiles (osm, or order statistic medians) and\n",
      "            ordered responses (osr).  `osr` is simply sorted input `x`.\n",
      "            For details on how `osm` is calculated see the Notes section.\n",
      "        (slope, intercept, r) : tuple of floats, optional\n",
      "            Tuple  containing the result of the least-squares fit, if that is\n",
      "            performed by `probplot`. `r` is the square root of the coefficient of\n",
      "            determination.  If ``fit=False`` and ``plot=None``, this tuple is not\n",
      "            returned.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Even if `plot` is given, the figure is not shown or saved by `probplot`;\n",
      "        ``plt.show()`` or ``plt.savefig('figname.png')`` should be used after\n",
      "        calling `probplot`.\n",
      "        \n",
      "        `probplot` generates a probability plot, which should not be confused with\n",
      "        a Q-Q or a P-P plot.  Statsmodels has more extensive functionality of this\n",
      "        type, see ``statsmodels.api.ProbPlot``.\n",
      "        \n",
      "        The formula used for the theoretical quantiles (horizontal axis of the\n",
      "        probability plot) is Filliben's estimate::\n",
      "        \n",
      "            quantiles = dist.ppf(val), for\n",
      "        \n",
      "                    0.5**(1/n),                  for i = n\n",
      "              val = (i - 0.3175) / (n + 0.365),  for i = 2, ..., n-1\n",
      "                    1 - 0.5**(1/n),              for i = 1\n",
      "        \n",
      "        where ``i`` indicates the i-th ordered value and ``n`` is the total number\n",
      "        of values.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> nsample = 100\n",
      "        >>> np.random.seed(7654321)\n",
      "        \n",
      "        A t distribution with small degrees of freedom:\n",
      "        \n",
      "        >>> ax1 = plt.subplot(221)\n",
      "        >>> x = stats.t.rvs(3, size=nsample)\n",
      "        >>> res = stats.probplot(x, plot=plt)\n",
      "        \n",
      "        A t distribution with larger degrees of freedom:\n",
      "        \n",
      "        >>> ax2 = plt.subplot(222)\n",
      "        >>> x = stats.t.rvs(25, size=nsample)\n",
      "        >>> res = stats.probplot(x, plot=plt)\n",
      "        \n",
      "        A mixture of two normal distributions with broadcasting:\n",
      "        \n",
      "        >>> ax3 = plt.subplot(223)\n",
      "        >>> x = stats.norm.rvs(loc=[0,5], scale=[1,1.5],\n",
      "        ...                    size=(nsample//2,2)).ravel()\n",
      "        >>> res = stats.probplot(x, plot=plt)\n",
      "        \n",
      "        A standard normal distribution:\n",
      "        \n",
      "        >>> ax4 = plt.subplot(224)\n",
      "        >>> x = stats.norm.rvs(loc=0, scale=1, size=nsample)\n",
      "        >>> res = stats.probplot(x, plot=plt)\n",
      "        \n",
      "        Produce a new figure with a loggamma distribution, using the ``dist`` and\n",
      "        ``sparams`` keywords:\n",
      "        \n",
      "        >>> fig = plt.figure()\n",
      "        >>> ax = fig.add_subplot(111)\n",
      "        >>> x = stats.loggamma.rvs(c=2.5, size=500)\n",
      "        >>> res = stats.probplot(x, dist=stats.loggamma, sparams=(2.5,), plot=ax)\n",
      "        >>> ax.set_title(\"Probplot for loggamma dist with shape parameter 2.5\")\n",
      "        \n",
      "        Show the results with Matplotlib:\n",
      "        \n",
      "        >>> plt.show()\n",
      "    \n",
      "    rankdata(a, method='average')\n",
      "        Assign ranks to data, dealing with ties appropriately.\n",
      "        \n",
      "        Ranks begin at 1.  The `method` argument controls how ranks are assigned\n",
      "        to equal values.  See [1]_ for further discussion of ranking methods.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            The array of values to be ranked.  The array is first flattened.\n",
      "        method : {'average', 'min', 'max', 'dense', 'ordinal'}, optional\n",
      "            The method used to assign ranks to tied elements.\n",
      "            The following methods are available (default is 'average'):\n",
      "        \n",
      "              * 'average': The average of the ranks that would have been assigned to\n",
      "                all the tied values is assigned to each value.\n",
      "              * 'min': The minimum of the ranks that would have been assigned to all\n",
      "                the tied values is assigned to each value.  (This is also\n",
      "                referred to as \"competition\" ranking.)\n",
      "              * 'max': The maximum of the ranks that would have been assigned to all\n",
      "                the tied values is assigned to each value.\n",
      "              * 'dense': Like 'min', but the rank of the next highest element is\n",
      "                assigned the rank immediately after those assigned to the tied\n",
      "                elements.\n",
      "              * 'ordinal': All values are given a distinct rank, corresponding to\n",
      "                the order that the values occur in `a`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        ranks : ndarray\n",
      "             An array of length equal to the size of `a`, containing rank\n",
      "             scores.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] \"Ranking\", https://en.wikipedia.org/wiki/Ranking\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.stats import rankdata\n",
      "        >>> rankdata([0, 2, 3, 2])\n",
      "        array([ 1. ,  2.5,  4. ,  2.5])\n",
      "        >>> rankdata([0, 2, 3, 2], method='min')\n",
      "        array([ 1,  2,  4,  2])\n",
      "        >>> rankdata([0, 2, 3, 2], method='max')\n",
      "        array([ 1,  3,  4,  3])\n",
      "        >>> rankdata([0, 2, 3, 2], method='dense')\n",
      "        array([ 1,  2,  3,  2])\n",
      "        >>> rankdata([0, 2, 3, 2], method='ordinal')\n",
      "        array([ 1,  2,  4,  3])\n",
      "    \n",
      "    ranksums(x, y)\n",
      "        Compute the Wilcoxon rank-sum statistic for two samples.\n",
      "        \n",
      "        The Wilcoxon rank-sum test tests the null hypothesis that two sets\n",
      "        of measurements are drawn from the same distribution.  The alternative\n",
      "        hypothesis is that values in one sample are more likely to be\n",
      "        larger than the values in the other sample.\n",
      "        \n",
      "        This test should be used to compare two samples from continuous\n",
      "        distributions.  It does not handle ties between measurements\n",
      "        in x and y.  For tie-handling and an optional continuity correction\n",
      "        see `scipy.stats.mannwhitneyu`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x,y : array_like\n",
      "            The data from the two samples.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float\n",
      "            The test statistic under the large-sample approximation that the\n",
      "            rank sum statistic is normally distributed.\n",
      "        pvalue : float\n",
      "            The two-sided p-value of the test.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] https://en.wikipedia.org/wiki/Wilcoxon_rank-sum_test\n",
      "    \n",
      "    relfreq(a, numbins=10, defaultreallimits=None, weights=None)\n",
      "        Return a relative frequency histogram, using the histogram function.\n",
      "        \n",
      "        A relative frequency  histogram is a mapping of the number of\n",
      "        observations in each of the bins relative to the total of observations.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Input array.\n",
      "        numbins : int, optional\n",
      "            The number of bins to use for the histogram. Default is 10.\n",
      "        defaultreallimits : tuple (lower, upper), optional\n",
      "            The lower and upper values for the range of the histogram.\n",
      "            If no value is given, a range slightly larger than the range of the\n",
      "            values in a is used. Specifically ``(a.min() - s, a.max() + s)``,\n",
      "            where ``s = (1/2)(a.max() - a.min()) / (numbins - 1)``.\n",
      "        weights : array_like, optional\n",
      "            The weights for each value in `a`. Default is None, which gives each\n",
      "            value a weight of 1.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        frequency : ndarray\n",
      "            Binned values of relative frequency.\n",
      "        lowerlimit : float\n",
      "            Lower real limit.\n",
      "        binsize : float\n",
      "            Width of each bin.\n",
      "        extrapoints : int\n",
      "            Extra points.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> from scipy import stats\n",
      "        >>> a = np.array([2, 4, 1, 2, 3, 2])\n",
      "        >>> res = stats.relfreq(a, numbins=4)\n",
      "        >>> res.frequency\n",
      "        array([ 0.16666667, 0.5       , 0.16666667,  0.16666667])\n",
      "        >>> np.sum(res.frequency)  # relative frequencies should add up to 1\n",
      "        1.0\n",
      "        \n",
      "        Create a normal distribution with 1000 random values\n",
      "        \n",
      "        >>> rng = np.random.RandomState(seed=12345)\n",
      "        >>> samples = stats.norm.rvs(size=1000, random_state=rng)\n",
      "        \n",
      "        Calculate relative frequencies\n",
      "        \n",
      "        >>> res = stats.relfreq(samples, numbins=25)\n",
      "        \n",
      "        Calculate space of values for x\n",
      "        \n",
      "        >>> x = res.lowerlimit + np.linspace(0, res.binsize*res.frequency.size,\n",
      "        ...                                  res.frequency.size)\n",
      "        \n",
      "        Plot relative frequency histogram\n",
      "        \n",
      "        >>> fig = plt.figure(figsize=(5, 4))\n",
      "        >>> ax = fig.add_subplot(1, 1, 1)\n",
      "        >>> ax.bar(x, res.frequency, width=res.binsize)\n",
      "        >>> ax.set_title('Relative frequency histogram')\n",
      "        >>> ax.set_xlim([x.min(), x.max()])\n",
      "        \n",
      "        >>> plt.show()\n",
      "    \n",
      "    rvs_ratio_uniforms(pdf, umax, vmin, vmax, size=1, c=0, random_state=None)\n",
      "        Generate random samples from a probability density function using the\n",
      "        ratio-of-uniforms method.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        pdf : callable\n",
      "            A function with signature `pdf(x)` that is the probability\n",
      "            density function of the distribution.\n",
      "        umax : float\n",
      "            The upper bound of the bounding rectangle in the u-direction.\n",
      "        vmin : float\n",
      "            The lower bound of the bounding rectangle in the v-direction.\n",
      "        vmax : float\n",
      "            The upper bound of the bounding rectangle in the v-direction.\n",
      "        size : int or tuple of ints, optional\n",
      "            Defining number of random variates (default is 1).\n",
      "        c : float, optional.\n",
      "            Shift parameter of ratio-of-uniforms method, see Notes. Default is 0.\n",
      "        random_state : int or np.random.RandomState instance, optional\n",
      "            If already a RandomState instance, use it.\n",
      "            If seed is an int, return a new RandomState instance seeded with seed.\n",
      "            If None, use np.random.RandomState. Default is None.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        rvs : ndarray\n",
      "            The random variates distributed according to the probability\n",
      "            distribution defined by the pdf.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Given a univariate probability density function `pdf` and a constant `c`,\n",
      "        define the set ``A = {(u, v) : 0 < u <= sqrt(pdf(v/u + c))}``.\n",
      "        If `(U, V)` is a random vector uniformly distributed over `A`,\n",
      "        then `V/U + c` follows a distribution according to `pdf`.\n",
      "        \n",
      "        The above result (see [1]_, [2]_) can be used to sample random variables\n",
      "        using only the pdf, i.e. no inversion of the cdf is required. Typical\n",
      "        choices of `c` are zero or the mode of `pdf`. The set `A` is a subset of\n",
      "        the rectangle ``R = [0, umax] x [vmin, vmax]`` where\n",
      "        \n",
      "        - ``umax = sup sqrt(pdf(x))``\n",
      "        - ``vmin = inf (x - c) sqrt(pdf(x))``\n",
      "        - ``vmax = sup (x - c) sqrt(pdf(x))``\n",
      "        \n",
      "        In particular, these values are finite if `pdf` is bounded and\n",
      "        ``x**2 * pdf(x)`` is bounded (i.e. subquadratic tails).\n",
      "        One can generate `(U, V)` uniformly on `R` and return\n",
      "        `V/U + c` if `(U, V)` are also in `A` which can be directly\n",
      "        verified.\n",
      "        \n",
      "        Intuitively, the method works well if `A` fills up most of the\n",
      "        enclosing rectangle such that the probability is high that `(U, V)`\n",
      "        lies in `A` whenever it lies in `R` as the number of required\n",
      "        iterations becomes too large otherwise. To be more precise, note that\n",
      "        the expected number of iterations to draw `(U, V)` uniformly\n",
      "        distributed on `R` such that `(U, V)` is also in `A` is given by\n",
      "        the ratio ``area(R) / area(A) = 2 * umax * (vmax - vmin)``, using the fact\n",
      "        that the area of `A` is equal to 1/2 (Theorem 7.1 in [1]_). A warning\n",
      "        is displayed if this ratio is larger than 20. Moreover, if the sampling\n",
      "        fails to generate a single random variate after 50000 iterations (i.e.\n",
      "        not a single draw is in `A`), an exception is raised.\n",
      "        \n",
      "        If the bounding rectangle is not correctly specified (i.e. if it does not\n",
      "        contain `A`), the algorithm samples from a distribution different from\n",
      "        the one given by `pdf`. It is therefore recommended to perform a\n",
      "        test such as `~scipy.stats.kstest` as a check.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] L. Devroye, \"Non-Uniform Random Variate Generation\",\n",
      "           Springer-Verlag, 1986.\n",
      "        \n",
      "        .. [2] W. Hoermann and J. Leydold, \"Generating generalized inverse Gaussian\n",
      "           random variates\", Statistics and Computing, 24(4), p. 547--557, 2014.\n",
      "        \n",
      "        .. [3] A.J. Kinderman and J.F. Monahan, \"Computer Generation of Random\n",
      "           Variables Using the Ratio of Uniform Deviates\",\n",
      "           ACM Transactions on Mathematical Software, 3(3), p. 257--260, 1977.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        \n",
      "        Simulate normally distributed random variables. It is easy to compute the\n",
      "        bounding rectangle explicitly in that case.\n",
      "        \n",
      "        >>> f = stats.norm.pdf\n",
      "        >>> v_bound = np.sqrt(f(np.sqrt(2))) * np.sqrt(2)\n",
      "        >>> umax, vmin, vmax = np.sqrt(f(0)), -v_bound, v_bound\n",
      "        >>> np.random.seed(12345)\n",
      "        >>> rvs = stats.rvs_ratio_uniforms(f, umax, vmin, vmax, size=2500)\n",
      "        \n",
      "        The K-S test confirms that the random variates are indeed normally\n",
      "        distributed (normality is not rejected at 5% significance level):\n",
      "        \n",
      "        >>> stats.kstest(rvs, 'norm')[1]\n",
      "        0.3420173467307603\n",
      "        \n",
      "        The exponential distribution provides another example where the bounding\n",
      "        rectangle can be determined explicitly.\n",
      "        \n",
      "        >>> np.random.seed(12345)\n",
      "        >>> rvs = stats.rvs_ratio_uniforms(lambda x: np.exp(-x), umax=1,\n",
      "        ...                                vmin=0, vmax=2*np.exp(-1), size=1000)\n",
      "        >>> stats.kstest(rvs, 'expon')[1]\n",
      "        0.928454552559516\n",
      "        \n",
      "        Sometimes it can be helpful to use a non-zero shift parameter `c`, see e.g.\n",
      "        [2]_ above in the case of the generalized inverse Gaussian distribution.\n",
      "    \n",
      "    scoreatpercentile(a, per, limit=(), interpolation_method='fraction', axis=None)\n",
      "        Calculate the score at a given percentile of the input sequence.\n",
      "        \n",
      "        For example, the score at `per=50` is the median. If the desired quantile\n",
      "        lies between two data points, we interpolate between them, according to\n",
      "        the value of `interpolation`. If the parameter `limit` is provided, it\n",
      "        should be a tuple (lower, upper) of two values.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            A 1-D array of values from which to extract score.\n",
      "        per : array_like\n",
      "            Percentile(s) at which to extract score.  Values should be in range\n",
      "            [0,100].\n",
      "        limit : tuple, optional\n",
      "            Tuple of two scalars, the lower and upper limits within which to\n",
      "            compute the percentile. Values of `a` outside\n",
      "            this (closed) interval will be ignored.\n",
      "        interpolation_method : {'fraction', 'lower', 'higher'}, optional\n",
      "            Specifies the interpolation method to use,\n",
      "            when the desired quantile lies between two data points `i` and `j`\n",
      "            The following options are available (default is 'fraction'):\n",
      "        \n",
      "              * 'fraction': ``i + (j - i) * fraction`` where ``fraction`` is the\n",
      "                fractional part of the index surrounded by ``i`` and ``j``\n",
      "              * 'lower': ``i``\n",
      "              * 'higher': ``j``\n",
      "        \n",
      "        axis : int, optional\n",
      "            Axis along which the percentiles are computed. Default is None. If\n",
      "            None, compute over the whole array `a`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        score : float or ndarray\n",
      "            Score at percentile(s).\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        percentileofscore, numpy.percentile\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This function will become obsolete in the future.\n",
      "        For NumPy 1.9 and higher, `numpy.percentile` provides all the functionality\n",
      "        that `scoreatpercentile` provides.  And it's significantly faster.\n",
      "        Therefore it's recommended to use `numpy.percentile` for users that have\n",
      "        numpy >= 1.9.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> a = np.arange(100)\n",
      "        >>> stats.scoreatpercentile(a, 50)\n",
      "        49.5\n",
      "    \n",
      "    sem(a, axis=0, ddof=1, nan_policy='propagate')\n",
      "        Compute standard error of the mean.\n",
      "        \n",
      "        Calculate the standard error of the mean (or standard error of\n",
      "        measurement) of the values in the input array.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            An array containing the values for which the standard error is\n",
      "            returned.\n",
      "        axis : int or None, optional\n",
      "            Axis along which to operate. Default is 0. If None, compute over\n",
      "            the whole array `a`.\n",
      "        ddof : int, optional\n",
      "            Delta degrees-of-freedom. How many degrees of freedom to adjust\n",
      "            for bias in limited samples relative to the population estimate\n",
      "            of variance. Defaults to 1.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan.\n",
      "            The following options are available (default is 'propagate'):\n",
      "        \n",
      "              * 'propagate': returns nan\n",
      "              * 'raise': throws an error\n",
      "              * 'omit': performs the calculations ignoring nan values\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        s : ndarray or float\n",
      "            The standard error of the mean in the sample(s), along the input axis.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The default value for `ddof` is different to the default (0) used by other\n",
      "        ddof containing routines, such as np.std and np.nanstd.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Find standard error along the first axis:\n",
      "        \n",
      "        >>> from scipy import stats\n",
      "        >>> a = np.arange(20).reshape(5,4)\n",
      "        >>> stats.sem(a)\n",
      "        array([ 2.8284,  2.8284,  2.8284,  2.8284])\n",
      "        \n",
      "        Find standard error across the whole array, using n degrees of freedom:\n",
      "        \n",
      "        >>> stats.sem(a, axis=None, ddof=0)\n",
      "        1.2893796958227628\n",
      "    \n",
      "    shapiro(x)\n",
      "        Perform the Shapiro-Wilk test for normality.\n",
      "        \n",
      "        The Shapiro-Wilk test tests the null hypothesis that the\n",
      "        data was drawn from a normal distribution.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Array of sample data.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        W : float\n",
      "            The test statistic.\n",
      "        p-value : float\n",
      "            The p-value for the hypothesis test.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        anderson : The Anderson-Darling test for normality\n",
      "        kstest : The Kolmogorov-Smirnov test for goodness of fit.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The algorithm used is described in [4]_ but censoring parameters as\n",
      "        described are not implemented. For N > 5000 the W test statistic is accurate\n",
      "        but the p-value may not be.\n",
      "        \n",
      "        The chance of rejecting the null hypothesis when it is true is close to 5%\n",
      "        regardless of sample size.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm\n",
      "        .. [2] Shapiro, S. S. & Wilk, M.B (1965). An analysis of variance test for\n",
      "               normality (complete samples), Biometrika, Vol. 52, pp. 591-611.\n",
      "        .. [3] Razali, N. M. & Wah, Y. B. (2011) Power comparisons of Shapiro-Wilk,\n",
      "               Kolmogorov-Smirnov, Lilliefors and Anderson-Darling tests, Journal of\n",
      "               Statistical Modeling and Analytics, Vol. 2, pp. 21-33.\n",
      "        .. [4] ALGORITHM AS R94 APPL. STATIST. (1995) VOL. 44, NO. 4.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> np.random.seed(12345678)\n",
      "        >>> x = stats.norm.rvs(loc=5, scale=3, size=100)\n",
      "        >>> stats.shapiro(x)\n",
      "        (0.9772805571556091, 0.08144091814756393)\n",
      "    \n",
      "    siegelslopes(y, x=None, method='hierarchical')\n",
      "        Computes the Siegel estimator for a set of points (x, y).\n",
      "        \n",
      "        `siegelslopes` implements a method for robust linear regression\n",
      "        using repeated medians (see [1]_) to fit a line to the points (x, y).\n",
      "        The method is robust to outliers with an asymptotic breakdown point\n",
      "        of 50%.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y : array_like\n",
      "            Dependent variable.\n",
      "        x : array_like or None, optional\n",
      "            Independent variable. If None, use ``arange(len(y))`` instead.\n",
      "        method : {'hierarchical', 'separate'}\n",
      "            If 'hierarchical', estimate the intercept using the estimated\n",
      "            slope ``medslope`` (default option).\n",
      "            If 'separate', estimate the intercept independent of the estimated\n",
      "            slope. See Notes for details.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        medslope : float\n",
      "            Estimate of the slope of the regression line.\n",
      "        medintercept : float\n",
      "            Estimate of the intercept of the regression line.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        theilslopes : a similar technique without repeated medians\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        With ``n = len(y)``, compute ``m_j`` as the median of\n",
      "        the slopes from the point ``(x[j], y[j])`` to all other `n-1` points.\n",
      "        ``medslope`` is then the median of all slopes ``m_j``.\n",
      "        Two ways are given to estimate the intercept in [1]_ which can be chosen\n",
      "        via the parameter ``method``.\n",
      "        The hierarchical approach uses the estimated slope ``medslope``\n",
      "        and computes ``medintercept`` as the median of ``y - medslope*x``.\n",
      "        The other approach estimates the intercept separately as follows: for\n",
      "        each point ``(x[j], y[j])``, compute the intercepts of all the `n-1`\n",
      "        lines through the remaining points and take the median ``i_j``.\n",
      "        ``medintercept`` is the median of the ``i_j``.\n",
      "        \n",
      "        The implementation computes `n` times the median of a vector of size `n`\n",
      "        which can be slow for large vectors. There are more efficient algorithms\n",
      "        (see [2]_) which are not implemented here.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] A. Siegel, \"Robust Regression Using Repeated Medians\",\n",
      "               Biometrika, Vol. 69, pp. 242-244, 1982.\n",
      "        \n",
      "        .. [2] A. Stein and M. Werman, \"Finding the repeated median regression\n",
      "               line\", Proceedings of the Third Annual ACM-SIAM Symposium on\n",
      "               Discrete Algorithms, pp. 409-413, 1992.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        \n",
      "        >>> x = np.linspace(-5, 5, num=150)\n",
      "        >>> y = x + np.random.normal(size=x.size)\n",
      "        >>> y[11:15] += 10  # add outliers\n",
      "        >>> y[-5:] -= 7\n",
      "        \n",
      "        Compute the slope and intercept.  For comparison, also compute the\n",
      "        least-squares fit with `linregress`:\n",
      "        \n",
      "        >>> res = stats.siegelslopes(y, x)\n",
      "        >>> lsq_res = stats.linregress(x, y)\n",
      "        \n",
      "        Plot the results. The Siegel regression line is shown in red. The green\n",
      "        line shows the least-squares fit for comparison.\n",
      "        \n",
      "        >>> fig = plt.figure()\n",
      "        >>> ax = fig.add_subplot(111)\n",
      "        >>> ax.plot(x, y, 'b.')\n",
      "        >>> ax.plot(x, res[1] + res[0] * x, 'r-')\n",
      "        >>> ax.plot(x, lsq_res[1] + lsq_res[0] * x, 'g-')\n",
      "        >>> plt.show()\n",
      "    \n",
      "    sigmaclip(a, low=4.0, high=4.0)\n",
      "        Perform iterative sigma-clipping of array elements.\n",
      "        \n",
      "        Starting from the full sample, all elements outside the critical range are\n",
      "        removed, i.e. all elements of the input array `c` that satisfy either of\n",
      "        the following conditions::\n",
      "        \n",
      "            c < mean(c) - std(c)*low\n",
      "            c > mean(c) + std(c)*high\n",
      "        \n",
      "        The iteration continues with the updated sample until no\n",
      "        elements are outside the (updated) range.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Data array, will be raveled if not 1-D.\n",
      "        low : float, optional\n",
      "            Lower bound factor of sigma clipping. Default is 4.\n",
      "        high : float, optional\n",
      "            Upper bound factor of sigma clipping. Default is 4.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        clipped : ndarray\n",
      "            Input array with clipped elements removed.\n",
      "        lower : float\n",
      "            Lower threshold value use for clipping.\n",
      "        upper : float\n",
      "            Upper threshold value use for clipping.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.stats import sigmaclip\n",
      "        >>> a = np.concatenate((np.linspace(9.5, 10.5, 31),\n",
      "        ...                     np.linspace(0, 20, 5)))\n",
      "        >>> fact = 1.5\n",
      "        >>> c, low, upp = sigmaclip(a, fact, fact)\n",
      "        >>> c\n",
      "        array([  9.96666667,  10.        ,  10.03333333,  10.        ])\n",
      "        >>> c.var(), c.std()\n",
      "        (0.00055555555555555165, 0.023570226039551501)\n",
      "        >>> low, c.mean() - fact*c.std(), c.min()\n",
      "        (9.9646446609406727, 9.9646446609406727, 9.9666666666666668)\n",
      "        >>> upp, c.mean() + fact*c.std(), c.max()\n",
      "        (10.035355339059327, 10.035355339059327, 10.033333333333333)\n",
      "        \n",
      "        >>> a = np.concatenate((np.linspace(9.5, 10.5, 11),\n",
      "        ...                     np.linspace(-100, -50, 3)))\n",
      "        >>> c, low, upp = sigmaclip(a, 1.8, 1.8)\n",
      "        >>> (c == np.linspace(9.5, 10.5, 11)).all()\n",
      "        True\n",
      "    \n",
      "    skew(a, axis=0, bias=True, nan_policy='propagate')\n",
      "        Compute the sample skewness of a data set.\n",
      "        \n",
      "        For normally distributed data, the skewness should be about zero. For\n",
      "        unimodal continuous distributions, a skewness value greater than zero means\n",
      "        that there is more weight in the right tail of the distribution. The\n",
      "        function `skewtest` can be used to determine if the skewness value\n",
      "        is close enough to zero, statistically speaking.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : ndarray\n",
      "            Input array.\n",
      "        axis : int or None, optional\n",
      "            Axis along which skewness is calculated. Default is 0.\n",
      "            If None, compute over the whole array `a`.\n",
      "        bias : bool, optional\n",
      "            If False, then the calculations are corrected for statistical bias.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan.\n",
      "            The following options are available (default is 'propagate'):\n",
      "        \n",
      "              * 'propagate': returns nan\n",
      "              * 'raise': throws an error\n",
      "              * 'omit': performs the calculations ignoring nan values\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        skewness : ndarray\n",
      "            The skewness of values along an axis, returning 0 where all values are\n",
      "            equal.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The sample skewness is computed as the Fisher-Pearson coefficient\n",
      "        of skewness, i.e.\n",
      "        \n",
      "        .. math:: \n",
      "        \n",
      "            g_1=\\frac{m_3}{m_2^{3/2}}\n",
      "        \n",
      "        where\n",
      "        \n",
      "        .. math:: \n",
      "        \n",
      "            m_i=\\frac{1}{N}\\sum_{n=1}^N(x[n]-\\bar{x})^i\n",
      "        \n",
      "        is the biased sample :math:`i\\texttt{th}` central moment, and :math:`\\bar{x}` is\n",
      "        the sample mean.  If ``bias`` is False, the calculations are\n",
      "        corrected for bias and the value computed is the adjusted\n",
      "        Fisher-Pearson standardized moment coefficient, i.e.\n",
      "        \n",
      "        .. math:: \n",
      "        \n",
      "            G_1=\\frac{k_3}{k_2^{3/2}}=\n",
      "                \\frac{\\sqrt{N(N-1)}}{N-2}\\frac{m_3}{m_2^{3/2}}.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Zwillinger, D. and Kokoska, S. (2000). CRC Standard\n",
      "           Probability and Statistics Tables and Formulae. Chapman & Hall: New\n",
      "           York. 2000.\n",
      "           Section 2.2.24.1\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.stats import skew\n",
      "        >>> skew([1, 2, 3, 4, 5])\n",
      "        0.0\n",
      "        >>> skew([2, 8, 0, 4, 1, 9, 9, 0])\n",
      "        0.2650554122698573\n",
      "    \n",
      "    skewtest(a, axis=0, nan_policy='propagate')\n",
      "        Test whether the skew is different from the normal distribution.\n",
      "        \n",
      "        This function tests the null hypothesis that the skewness of\n",
      "        the population that the sample was drawn from is the same\n",
      "        as that of a corresponding normal distribution.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array\n",
      "            The data to be tested.\n",
      "        axis : int or None, optional\n",
      "           Axis along which statistics are calculated. Default is 0.\n",
      "           If None, compute over the whole array `a`.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan.\n",
      "            The following options are available (default is 'propagate'):\n",
      "        \n",
      "              * 'propagate': returns nan\n",
      "              * 'raise': throws an error\n",
      "              * 'omit': performs the calculations ignoring nan values\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float\n",
      "            The computed z-score for this test.\n",
      "        pvalue : float\n",
      "            Two-sided p-value for the hypothesis test.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The sample size must be at least 8.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] R. B. D'Agostino, A. J. Belanger and R. B. D'Agostino Jr.,\n",
      "                \"A suggestion for using powerful and informative tests of\n",
      "                normality\", American Statistician 44, pp. 316-321, 1990.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.stats import skewtest\n",
      "        >>> skewtest([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "        SkewtestResult(statistic=1.0108048609177787, pvalue=0.3121098361421897)\n",
      "        >>> skewtest([2, 8, 0, 4, 1, 9, 9, 0])\n",
      "        SkewtestResult(statistic=0.44626385374196975, pvalue=0.6554066631275459)\n",
      "        >>> skewtest([1, 2, 3, 4, 5, 6, 7, 8000])\n",
      "        SkewtestResult(statistic=3.571773510360407, pvalue=0.0003545719905823133)\n",
      "        >>> skewtest([100, 100, 100, 100, 100, 100, 100, 101])\n",
      "        SkewtestResult(statistic=3.5717766638478072, pvalue=0.000354567720281634)\n",
      "    \n",
      "    spearmanr(a, b=None, axis=0, nan_policy='propagate')\n",
      "        Calculate a Spearman correlation coefficient with associated p-value.\n",
      "        \n",
      "        The Spearman rank-order correlation coefficient is a nonparametric measure\n",
      "        of the monotonicity of the relationship between two datasets. Unlike the\n",
      "        Pearson correlation, the Spearman correlation does not assume that both\n",
      "        datasets are normally distributed. Like other correlation coefficients,\n",
      "        this one varies between -1 and +1 with 0 implying no correlation.\n",
      "        Correlations of -1 or +1 imply an exact monotonic relationship. Positive\n",
      "        correlations imply that as x increases, so does y. Negative correlations\n",
      "        imply that as x increases, y decreases.\n",
      "        \n",
      "        The p-value roughly indicates the probability of an uncorrelated system\n",
      "        producing datasets that have a Spearman correlation at least as extreme\n",
      "        as the one computed from these datasets. The p-values are not entirely\n",
      "        reliable but are probably reasonable for datasets larger than 500 or so.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a, b : 1D or 2D array_like, b is optional\n",
      "            One or two 1-D or 2-D arrays containing multiple variables and\n",
      "            observations. When these are 1-D, each represents a vector of\n",
      "            observations of a single variable. For the behavior in the 2-D case,\n",
      "            see under ``axis``, below.\n",
      "            Both arrays need to have the same length in the ``axis`` dimension.\n",
      "        axis : int or None, optional\n",
      "            If axis=0 (default), then each column represents a variable, with\n",
      "            observations in the rows. If axis=1, the relationship is transposed:\n",
      "            each row represents a variable, while the columns contain observations.\n",
      "            If axis=None, then both arrays will be raveled.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan.\n",
      "            The following options are available (default is 'propagate'):\n",
      "        \n",
      "              * 'propagate': returns nan\n",
      "              * 'raise': throws an error\n",
      "              * 'omit': performs the calculations ignoring nan values\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        correlation : float or ndarray (2-D square)\n",
      "            Spearman correlation matrix or correlation coefficient (if only 2\n",
      "            variables are given as parameters. Correlation matrix is square with\n",
      "            length equal to total number of variables (columns or rows) in ``a``\n",
      "            and ``b`` combined.\n",
      "        pvalue : float\n",
      "            The two-sided p-value for a hypothesis test whose null hypothesis is\n",
      "            that two sets of data are uncorrelated, has same dimension as rho.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Zwillinger, D. and Kokoska, S. (2000). CRC Standard\n",
      "           Probability and Statistics Tables and Formulae. Chapman & Hall: New\n",
      "           York. 2000.\n",
      "           Section  14.7\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> stats.spearmanr([1,2,3,4,5], [5,6,7,8,7])\n",
      "        (0.82078268166812329, 0.088587005313543798)\n",
      "        >>> np.random.seed(1234321)\n",
      "        >>> x2n = np.random.randn(100, 2)\n",
      "        >>> y2n = np.random.randn(100, 2)\n",
      "        >>> stats.spearmanr(x2n)\n",
      "        (0.059969996999699973, 0.55338590803773591)\n",
      "        >>> stats.spearmanr(x2n[:,0], x2n[:,1])\n",
      "        (0.059969996999699973, 0.55338590803773591)\n",
      "        >>> rho, pval = stats.spearmanr(x2n, y2n)\n",
      "        >>> rho\n",
      "        array([[ 1.        ,  0.05997   ,  0.18569457,  0.06258626],\n",
      "               [ 0.05997   ,  1.        ,  0.110003  ,  0.02534653],\n",
      "               [ 0.18569457,  0.110003  ,  1.        ,  0.03488749],\n",
      "               [ 0.06258626,  0.02534653,  0.03488749,  1.        ]])\n",
      "        >>> pval\n",
      "        array([[ 0.        ,  0.55338591,  0.06435364,  0.53617935],\n",
      "               [ 0.55338591,  0.        ,  0.27592895,  0.80234077],\n",
      "               [ 0.06435364,  0.27592895,  0.        ,  0.73039992],\n",
      "               [ 0.53617935,  0.80234077,  0.73039992,  0.        ]])\n",
      "        >>> rho, pval = stats.spearmanr(x2n.T, y2n.T, axis=1)\n",
      "        >>> rho\n",
      "        array([[ 1.        ,  0.05997   ,  0.18569457,  0.06258626],\n",
      "               [ 0.05997   ,  1.        ,  0.110003  ,  0.02534653],\n",
      "               [ 0.18569457,  0.110003  ,  1.        ,  0.03488749],\n",
      "               [ 0.06258626,  0.02534653,  0.03488749,  1.        ]])\n",
      "        >>> stats.spearmanr(x2n, y2n, axis=None)\n",
      "        (0.10816770419260482, 0.1273562188027364)\n",
      "        >>> stats.spearmanr(x2n.ravel(), y2n.ravel())\n",
      "        (0.10816770419260482, 0.1273562188027364)\n",
      "        \n",
      "        >>> xint = np.random.randint(10, size=(100, 2))\n",
      "        >>> stats.spearmanr(xint)\n",
      "        (0.052760927029710199, 0.60213045837062351)\n",
      "    \n",
      "    theilslopes(y, x=None, alpha=0.95)\n",
      "        Computes the Theil-Sen estimator for a set of points (x, y).\n",
      "        \n",
      "        `theilslopes` implements a method for robust linear regression.  It\n",
      "        computes the slope as the median of all slopes between paired values.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        y : array_like\n",
      "            Dependent variable.\n",
      "        x : array_like or None, optional\n",
      "            Independent variable. If None, use ``arange(len(y))`` instead.\n",
      "        alpha : float, optional\n",
      "            Confidence degree between 0 and 1. Default is 95% confidence.\n",
      "            Note that `alpha` is symmetric around 0.5, i.e. both 0.1 and 0.9 are\n",
      "            interpreted as \"find the 90% confidence interval\".\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        medslope : float\n",
      "            Theil slope.\n",
      "        medintercept : float\n",
      "            Intercept of the Theil line, as ``median(y) - medslope*median(x)``.\n",
      "        lo_slope : float\n",
      "            Lower bound of the confidence interval on `medslope`.\n",
      "        up_slope : float\n",
      "            Upper bound of the confidence interval on `medslope`.\n",
      "        \n",
      "        See also\n",
      "        --------\n",
      "        siegelslopes : a similar technique using repeated medians\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The implementation of `theilslopes` follows [1]_. The intercept is\n",
      "        not defined in [1]_, and here it is defined as ``median(y) -\n",
      "        medslope*median(x)``, which is given in [3]_. Other definitions of\n",
      "        the intercept exist in the literature. A confidence interval for\n",
      "        the intercept is not given as this question is not addressed in\n",
      "        [1]_.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] P.K. Sen, \"Estimates of the regression coefficient based on Kendall's tau\",\n",
      "               J. Am. Stat. Assoc., Vol. 63, pp. 1379-1389, 1968.\n",
      "        .. [2] H. Theil, \"A rank-invariant method of linear and polynomial\n",
      "               regression analysis I, II and III\",  Nederl. Akad. Wetensch., Proc.\n",
      "               53:, pp. 386-392, pp. 521-525, pp. 1397-1412, 1950.\n",
      "        .. [3] W.L. Conover, \"Practical nonparametric statistics\", 2nd ed.,\n",
      "               John Wiley and Sons, New York, pp. 493.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        \n",
      "        >>> x = np.linspace(-5, 5, num=150)\n",
      "        >>> y = x + np.random.normal(size=x.size)\n",
      "        >>> y[11:15] += 10  # add outliers\n",
      "        >>> y[-5:] -= 7\n",
      "        \n",
      "        Compute the slope, intercept and 90% confidence interval.  For comparison,\n",
      "        also compute the least-squares fit with `linregress`:\n",
      "        \n",
      "        >>> res = stats.theilslopes(y, x, 0.90)\n",
      "        >>> lsq_res = stats.linregress(x, y)\n",
      "        \n",
      "        Plot the results. The Theil-Sen regression line is shown in red, with the\n",
      "        dashed red lines illustrating the confidence interval of the slope (note\n",
      "        that the dashed red lines are not the confidence interval of the regression\n",
      "        as the confidence interval of the intercept is not included). The green\n",
      "        line shows the least-squares fit for comparison.\n",
      "        \n",
      "        >>> fig = plt.figure()\n",
      "        >>> ax = fig.add_subplot(111)\n",
      "        >>> ax.plot(x, y, 'b.')\n",
      "        >>> ax.plot(x, res[1] + res[0] * x, 'r-')\n",
      "        >>> ax.plot(x, res[1] + res[2] * x, 'r--')\n",
      "        >>> ax.plot(x, res[1] + res[3] * x, 'r--')\n",
      "        >>> ax.plot(x, lsq_res[1] + lsq_res[0] * x, 'g-')\n",
      "        >>> plt.show()\n",
      "    \n",
      "    tiecorrect(rankvals)\n",
      "        Tie correction factor for Mann-Whitney U and Kruskal-Wallis H tests.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        rankvals : array_like\n",
      "            A 1-D sequence of ranks.  Typically this will be the array\n",
      "            returned by `~scipy.stats.rankdata`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        factor : float\n",
      "            Correction factor for U or H.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        rankdata : Assign ranks to the data\n",
      "        mannwhitneyu : Mann-Whitney rank test\n",
      "        kruskal : Kruskal-Wallis H test\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Siegel, S. (1956) Nonparametric Statistics for the Behavioral\n",
      "               Sciences.  New York: McGraw-Hill.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.stats import tiecorrect, rankdata\n",
      "        >>> tiecorrect([1, 2.5, 2.5, 4])\n",
      "        0.9\n",
      "        >>> ranks = rankdata([1, 3, 2, 4, 5, 7, 2, 8, 4])\n",
      "        >>> ranks\n",
      "        array([ 1. ,  4. ,  2.5,  5.5,  7. ,  8. ,  2.5,  9. ,  5.5])\n",
      "        >>> tiecorrect(ranks)\n",
      "        0.9833333333333333\n",
      "    \n",
      "    tmax(a, upperlimit=None, axis=0, inclusive=True, nan_policy='propagate')\n",
      "        Compute the trimmed maximum.\n",
      "        \n",
      "        This function computes the maximum value of an array along a given axis,\n",
      "        while ignoring values larger than a specified upper limit.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Array of values.\n",
      "        upperlimit : None or float, optional\n",
      "            Values in the input array greater than the given limit will be ignored.\n",
      "            When upperlimit is None, then all values are used. The default value\n",
      "            is None.\n",
      "        axis : int or None, optional\n",
      "            Axis along which to operate. Default is 0. If None, compute over the\n",
      "            whole array `a`.\n",
      "        inclusive : {True, False}, optional\n",
      "            This flag determines whether values exactly equal to the upper limit\n",
      "            are included.  The default value is True.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan.\n",
      "            The following options are available (default is 'propagate'):\n",
      "        \n",
      "              * 'propagate': returns nan\n",
      "              * 'raise': throws an error\n",
      "              * 'omit': performs the calculations ignoring nan values\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        tmax : float, int or ndarray\n",
      "            Trimmed maximum.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> x = np.arange(20)\n",
      "        >>> stats.tmax(x)\n",
      "        19\n",
      "        \n",
      "        >>> stats.tmax(x, 13)\n",
      "        13\n",
      "        \n",
      "        >>> stats.tmax(x, 13, inclusive=False)\n",
      "        12\n",
      "    \n",
      "    tmean(a, limits=None, inclusive=(True, True), axis=None)\n",
      "        Compute the trimmed mean.\n",
      "        \n",
      "        This function finds the arithmetic mean of given values, ignoring values\n",
      "        outside the given `limits`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Array of values.\n",
      "        limits : None or (lower limit, upper limit), optional\n",
      "            Values in the input array less than the lower limit or greater than the\n",
      "            upper limit will be ignored.  When limits is None (default), then all\n",
      "            values are used.  Either of the limit values in the tuple can also be\n",
      "            None representing a half-open interval.\n",
      "        inclusive : (bool, bool), optional\n",
      "            A tuple consisting of the (lower flag, upper flag).  These flags\n",
      "            determine whether values exactly equal to the lower or upper limits\n",
      "            are included.  The default value is (True, True).\n",
      "        axis : int or None, optional\n",
      "            Axis along which to compute test. Default is None.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        tmean : float\n",
      "            Trimmed mean.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        trim_mean : Returns mean after trimming a proportion from both tails.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> x = np.arange(20)\n",
      "        >>> stats.tmean(x)\n",
      "        9.5\n",
      "        >>> stats.tmean(x, (3,17))\n",
      "        10.0\n",
      "    \n",
      "    tmin(a, lowerlimit=None, axis=0, inclusive=True, nan_policy='propagate')\n",
      "        Compute the trimmed minimum.\n",
      "        \n",
      "        This function finds the miminum value of an array `a` along the\n",
      "        specified axis, but only considering values greater than a specified\n",
      "        lower limit.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Array of values.\n",
      "        lowerlimit : None or float, optional\n",
      "            Values in the input array less than the given limit will be ignored.\n",
      "            When lowerlimit is None, then all values are used. The default value\n",
      "            is None.\n",
      "        axis : int or None, optional\n",
      "            Axis along which to operate. Default is 0. If None, compute over the\n",
      "            whole array `a`.\n",
      "        inclusive : {True, False}, optional\n",
      "            This flag determines whether values exactly equal to the lower limit\n",
      "            are included.  The default value is True.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan.\n",
      "            The following options are available (default is 'propagate'):\n",
      "        \n",
      "              * 'propagate': returns nan\n",
      "              * 'raise': throws an error\n",
      "              * 'omit': performs the calculations ignoring nan values\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        tmin : float, int or ndarray\n",
      "            Trimmed minimum.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> x = np.arange(20)\n",
      "        >>> stats.tmin(x)\n",
      "        0\n",
      "        \n",
      "        >>> stats.tmin(x, 13)\n",
      "        13\n",
      "        \n",
      "        >>> stats.tmin(x, 13, inclusive=False)\n",
      "        14\n",
      "    \n",
      "    trim1(a, proportiontocut, tail='right', axis=0)\n",
      "        Slice off a proportion from ONE end of the passed array distribution.\n",
      "        \n",
      "        If `proportiontocut` = 0.1, slices off 'leftmost' or 'rightmost'\n",
      "        10% of scores. The lowest or highest values are trimmed (depending on\n",
      "        the tail).\n",
      "        Slice off less if proportion results in a non-integer slice index\n",
      "        (i.e. conservatively slices off `proportiontocut` ).\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Input array.\n",
      "        proportiontocut : float\n",
      "            Fraction to cut off of 'left' or 'right' of distribution.\n",
      "        tail : {'left', 'right'}, optional\n",
      "            Defaults to 'right'.\n",
      "        axis : int or None, optional\n",
      "            Axis along which to trim data. Default is 0. If None, compute over\n",
      "            the whole array `a`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        trim1 : ndarray\n",
      "            Trimmed version of array `a`. The order of the trimmed content is\n",
      "            undefined.\n",
      "    \n",
      "    trim_mean(a, proportiontocut, axis=0)\n",
      "        Return mean of array after trimming distribution from both tails.\n",
      "        \n",
      "        If `proportiontocut` = 0.1, slices off 'leftmost' and 'rightmost' 10% of\n",
      "        scores. The input is sorted before slicing. Slices off less if proportion\n",
      "        results in a non-integer slice index (i.e., conservatively slices off\n",
      "        `proportiontocut` ).\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Input array.\n",
      "        proportiontocut : float\n",
      "            Fraction to cut off of both tails of the distribution.\n",
      "        axis : int or None, optional\n",
      "            Axis along which the trimmed means are computed. Default is 0.\n",
      "            If None, compute over the whole array `a`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        trim_mean : ndarray\n",
      "            Mean of trimmed array.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        trimboth\n",
      "        tmean : Compute the trimmed mean ignoring values outside given `limits`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> x = np.arange(20)\n",
      "        >>> stats.trim_mean(x, 0.1)\n",
      "        9.5\n",
      "        >>> x2 = x.reshape(5, 4)\n",
      "        >>> x2\n",
      "        array([[ 0,  1,  2,  3],\n",
      "               [ 4,  5,  6,  7],\n",
      "               [ 8,  9, 10, 11],\n",
      "               [12, 13, 14, 15],\n",
      "               [16, 17, 18, 19]])\n",
      "        >>> stats.trim_mean(x2, 0.25)\n",
      "        array([  8.,   9.,  10.,  11.])\n",
      "        >>> stats.trim_mean(x2, 0.25, axis=1)\n",
      "        array([  1.5,   5.5,   9.5,  13.5,  17.5])\n",
      "    \n",
      "    trimboth(a, proportiontocut, axis=0)\n",
      "        Slice off a proportion of items from both ends of an array.\n",
      "        \n",
      "        Slice off the passed proportion of items from both ends of the passed\n",
      "        array (i.e., with `proportiontocut` = 0.1, slices leftmost 10% **and**\n",
      "        rightmost 10% of scores). The trimmed values are the lowest and\n",
      "        highest ones.\n",
      "        Slice off less if proportion results in a non-integer slice index (i.e.\n",
      "        conservatively slices off `proportiontocut`).\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Data to trim.\n",
      "        proportiontocut : float\n",
      "            Proportion (in range 0-1) of total data set to trim of each end.\n",
      "        axis : int or None, optional\n",
      "            Axis along which to trim data. Default is 0. If None, compute over\n",
      "            the whole array `a`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray\n",
      "            Trimmed version of array `a`. The order of the trimmed content\n",
      "            is undefined.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        trim_mean\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> a = np.arange(20)\n",
      "        >>> b = stats.trimboth(a, 0.1)\n",
      "        >>> b.shape\n",
      "        (16,)\n",
      "    \n",
      "    tsem(a, limits=None, inclusive=(True, True), axis=0, ddof=1)\n",
      "        Compute the trimmed standard error of the mean.\n",
      "        \n",
      "        This function finds the standard error of the mean for given\n",
      "        values, ignoring values outside the given `limits`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Array of values.\n",
      "        limits : None or (lower limit, upper limit), optional\n",
      "            Values in the input array less than the lower limit or greater than the\n",
      "            upper limit will be ignored. When limits is None, then all values are\n",
      "            used. Either of the limit values in the tuple can also be None\n",
      "            representing a half-open interval.  The default value is None.\n",
      "        inclusive : (bool, bool), optional\n",
      "            A tuple consisting of the (lower flag, upper flag).  These flags\n",
      "            determine whether values exactly equal to the lower or upper limits\n",
      "            are included.  The default value is (True, True).\n",
      "        axis : int or None, optional\n",
      "            Axis along which to operate. Default is 0. If None, compute over the\n",
      "            whole array `a`.\n",
      "        ddof : int, optional\n",
      "            Delta degrees of freedom.  Default is 1.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        tsem : float\n",
      "            Trimmed standard error of the mean.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        `tsem` uses unbiased sample standard deviation, i.e. it uses a\n",
      "        correction factor ``n / (n - 1)``.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> x = np.arange(20)\n",
      "        >>> stats.tsem(x)\n",
      "        1.3228756555322954\n",
      "        >>> stats.tsem(x, (3,17))\n",
      "        1.1547005383792515\n",
      "    \n",
      "    tstd(a, limits=None, inclusive=(True, True), axis=0, ddof=1)\n",
      "        Compute the trimmed sample standard deviation.\n",
      "        \n",
      "        This function finds the sample standard deviation of given values,\n",
      "        ignoring values outside the given `limits`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Array of values.\n",
      "        limits : None or (lower limit, upper limit), optional\n",
      "            Values in the input array less than the lower limit or greater than the\n",
      "            upper limit will be ignored. When limits is None, then all values are\n",
      "            used. Either of the limit values in the tuple can also be None\n",
      "            representing a half-open interval.  The default value is None.\n",
      "        inclusive : (bool, bool), optional\n",
      "            A tuple consisting of the (lower flag, upper flag).  These flags\n",
      "            determine whether values exactly equal to the lower or upper limits\n",
      "            are included.  The default value is (True, True).\n",
      "        axis : int or None, optional\n",
      "            Axis along which to operate. Default is 0. If None, compute over the\n",
      "            whole array `a`.\n",
      "        ddof : int, optional\n",
      "            Delta degrees of freedom.  Default is 1.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        tstd : float\n",
      "            Trimmed sample standard deviation.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        `tstd` computes the unbiased sample standard deviation, i.e. it uses a\n",
      "        correction factor ``n / (n - 1)``.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> x = np.arange(20)\n",
      "        >>> stats.tstd(x)\n",
      "        5.9160797830996161\n",
      "        >>> stats.tstd(x, (3,17))\n",
      "        4.4721359549995796\n",
      "    \n",
      "    ttest_1samp(a, popmean, axis=0, nan_policy='propagate')\n",
      "        Calculate the T-test for the mean of ONE group of scores.\n",
      "        \n",
      "        This is a two-sided test for the null hypothesis that the expected value\n",
      "        (mean) of a sample of independent observations `a` is equal to the given\n",
      "        population mean, `popmean`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Sample observation.\n",
      "        popmean : float or array_like\n",
      "            Expected value in null hypothesis. If array_like, then it must have the\n",
      "            same shape as `a` excluding the axis dimension.\n",
      "        axis : int or None, optional\n",
      "            Axis along which to compute test. If None, compute over the whole\n",
      "            array `a`.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan.\n",
      "            The following options are available (default is 'propagate'):\n",
      "        \n",
      "              * 'propagate': returns nan\n",
      "              * 'raise': throws an error\n",
      "              * 'omit': performs the calculations ignoring nan values\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float or array\n",
      "            t-statistic.\n",
      "        pvalue : float or array\n",
      "            Two-sided p-value.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        \n",
      "        >>> np.random.seed(7654567)  # fix seed to get the same result\n",
      "        >>> rvs = stats.norm.rvs(loc=5, scale=10, size=(50,2))\n",
      "        \n",
      "        Test if mean of random sample is equal to true mean, and different mean.\n",
      "        We reject the null hypothesis in the second case and don't reject it in\n",
      "        the first case.\n",
      "        \n",
      "        >>> stats.ttest_1samp(rvs,5.0)\n",
      "        (array([-0.68014479, -0.04323899]), array([ 0.49961383,  0.96568674]))\n",
      "        >>> stats.ttest_1samp(rvs,0.0)\n",
      "        (array([ 2.77025808,  4.11038784]), array([ 0.00789095,  0.00014999]))\n",
      "        \n",
      "        Examples using axis and non-scalar dimension for population mean.\n",
      "        \n",
      "        >>> stats.ttest_1samp(rvs,[5.0,0.0])\n",
      "        (array([-0.68014479,  4.11038784]), array([  4.99613833e-01,   1.49986458e-04]))\n",
      "        >>> stats.ttest_1samp(rvs.T,[5.0,0.0],axis=1)\n",
      "        (array([-0.68014479,  4.11038784]), array([  4.99613833e-01,   1.49986458e-04]))\n",
      "        >>> stats.ttest_1samp(rvs,[[5.0],[0.0]])\n",
      "        (array([[-0.68014479, -0.04323899],\n",
      "               [ 2.77025808,  4.11038784]]), array([[  4.99613833e-01,   9.65686743e-01],\n",
      "               [  7.89094663e-03,   1.49986458e-04]]))\n",
      "    \n",
      "    ttest_ind(a, b, axis=0, equal_var=True, nan_policy='propagate')\n",
      "        Calculate the T-test for the means of *two independent* samples of scores.\n",
      "        \n",
      "        This is a two-sided test for the null hypothesis that 2 independent samples\n",
      "        have identical average (expected) values. This test assumes that the\n",
      "        populations have identical variances by default.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a, b : array_like\n",
      "            The arrays must have the same shape, except in the dimension\n",
      "            corresponding to `axis` (the first, by default).\n",
      "        axis : int or None, optional\n",
      "            Axis along which to compute test. If None, compute over the whole\n",
      "            arrays, `a`, and `b`.\n",
      "        equal_var : bool, optional\n",
      "            If True (default), perform a standard independent 2 sample test\n",
      "            that assumes equal population variances [1]_.\n",
      "            If False, perform Welch's t-test, which does not assume equal\n",
      "            population variance [2]_.\n",
      "        \n",
      "            .. versionadded:: 0.11.0\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan.\n",
      "            The following options are available (default is 'propagate'):\n",
      "        \n",
      "              * 'propagate': returns nan\n",
      "              * 'raise': throws an error\n",
      "              * 'omit': performs the calculations ignoring nan values\n",
      "        \n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float or array\n",
      "            The calculated t-statistic.\n",
      "        pvalue : float or array\n",
      "            The two-tailed p-value.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        We can use this test, if we observe two independent samples from\n",
      "        the same or different population, e.g. exam scores of boys and\n",
      "        girls or of two ethnic groups. The test measures whether the\n",
      "        average (expected) value differs significantly across samples. If\n",
      "        we observe a large p-value, for example larger than 0.05 or 0.1,\n",
      "        then we cannot reject the null hypothesis of identical average scores.\n",
      "        If the p-value is smaller than the threshold, e.g. 1%, 5% or 10%,\n",
      "        then we reject the null hypothesis of equal averages.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] https://en.wikipedia.org/wiki/T-test#Independent_two-sample_t-test\n",
      "        \n",
      "        .. [2] https://en.wikipedia.org/wiki/Welch%27s_t-test\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> np.random.seed(12345678)\n",
      "        \n",
      "        Test with sample with identical means:\n",
      "        \n",
      "        >>> rvs1 = stats.norm.rvs(loc=5,scale=10,size=500)\n",
      "        >>> rvs2 = stats.norm.rvs(loc=5,scale=10,size=500)\n",
      "        >>> stats.ttest_ind(rvs1,rvs2)\n",
      "        (0.26833823296239279, 0.78849443369564776)\n",
      "        >>> stats.ttest_ind(rvs1,rvs2, equal_var = False)\n",
      "        (0.26833823296239279, 0.78849452749500748)\n",
      "        \n",
      "        `ttest_ind` underestimates p for unequal variances:\n",
      "        \n",
      "        >>> rvs3 = stats.norm.rvs(loc=5, scale=20, size=500)\n",
      "        >>> stats.ttest_ind(rvs1, rvs3)\n",
      "        (-0.46580283298287162, 0.64145827413436174)\n",
      "        >>> stats.ttest_ind(rvs1, rvs3, equal_var = False)\n",
      "        (-0.46580283298287162, 0.64149646246569292)\n",
      "        \n",
      "        When n1 != n2, the equal variance t-statistic is no longer equal to the\n",
      "        unequal variance t-statistic:\n",
      "        \n",
      "        >>> rvs4 = stats.norm.rvs(loc=5, scale=20, size=100)\n",
      "        >>> stats.ttest_ind(rvs1, rvs4)\n",
      "        (-0.99882539442782481, 0.3182832709103896)\n",
      "        >>> stats.ttest_ind(rvs1, rvs4, equal_var = False)\n",
      "        (-0.69712570584654099, 0.48716927725402048)\n",
      "        \n",
      "        T-test with different means, variance, and n:\n",
      "        \n",
      "        >>> rvs5 = stats.norm.rvs(loc=8, scale=20, size=100)\n",
      "        >>> stats.ttest_ind(rvs1, rvs5)\n",
      "        (-1.4679669854490653, 0.14263895620529152)\n",
      "        >>> stats.ttest_ind(rvs1, rvs5, equal_var = False)\n",
      "        (-0.94365973617132992, 0.34744170334794122)\n",
      "    \n",
      "    ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2, equal_var=True)\n",
      "        T-test for means of two independent samples from descriptive statistics.\n",
      "        \n",
      "        This is a two-sided test for the null hypothesis that two independent\n",
      "        samples have identical average (expected) values.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        mean1 : array_like\n",
      "            The mean(s) of sample 1.\n",
      "        std1 : array_like\n",
      "            The standard deviation(s) of sample 1.\n",
      "        nobs1 : array_like\n",
      "            The number(s) of observations of sample 1.\n",
      "        mean2 : array_like\n",
      "            The mean(s) of sample 2.\n",
      "        std2 : array_like\n",
      "            The standard deviations(s) of sample 2.\n",
      "        nobs2 : array_like\n",
      "            The number(s) of observations of sample 2.\n",
      "        equal_var : bool, optional\n",
      "            If True (default), perform a standard independent 2 sample test\n",
      "            that assumes equal population variances [1]_.\n",
      "            If False, perform Welch's t-test, which does not assume equal\n",
      "            population variance [2]_.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float or array\n",
      "            The calculated t-statistics.\n",
      "        pvalue : float or array\n",
      "            The two-tailed p-value.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.stats.ttest_ind\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        .. versionadded:: 0.16.0\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] https://en.wikipedia.org/wiki/T-test#Independent_two-sample_t-test\n",
      "        \n",
      "        .. [2] https://en.wikipedia.org/wiki/Welch%27s_t-test\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Suppose we have the summary data for two samples, as follows::\n",
      "        \n",
      "                             Sample   Sample\n",
      "                       Size   Mean   Variance\n",
      "            Sample 1    13    15.0     87.5\n",
      "            Sample 2    11    12.0     39.0\n",
      "        \n",
      "        Apply the t-test to this data (with the assumption that the population\n",
      "        variances are equal):\n",
      "        \n",
      "        >>> from scipy.stats import ttest_ind_from_stats\n",
      "        >>> ttest_ind_from_stats(mean1=15.0, std1=np.sqrt(87.5), nobs1=13,\n",
      "        ...                      mean2=12.0, std2=np.sqrt(39.0), nobs2=11)\n",
      "        Ttest_indResult(statistic=0.9051358093310269, pvalue=0.3751996797581487)\n",
      "        \n",
      "        For comparison, here is the data from which those summary statistics\n",
      "        were taken.  With this data, we can compute the same result using\n",
      "        `scipy.stats.ttest_ind`:\n",
      "        \n",
      "        >>> a = np.array([1, 3, 4, 6, 11, 13, 15, 19, 22, 24, 25, 26, 26])\n",
      "        >>> b = np.array([2, 4, 6, 9, 11, 13, 14, 15, 18, 19, 21])\n",
      "        >>> from scipy.stats import ttest_ind\n",
      "        >>> ttest_ind(a, b)\n",
      "        Ttest_indResult(statistic=0.905135809331027, pvalue=0.3751996797581486)\n",
      "        \n",
      "        Suppose we instead have binary data and would like to apply a t-test to\n",
      "        compare the proportion of 1s in two independent groups::\n",
      "        \n",
      "                              Number of    Sample     Sample\n",
      "                        Size    ones        Mean     Variance\n",
      "            Sample 1    150      30         0.2        0.16\n",
      "            Sample 2    200      45         0.225      0.174375\n",
      "        \n",
      "        The sample mean :math:`\\hat{p}` is the proportion of ones in the sample\n",
      "        and the variance for a binary observation is estimated by\n",
      "        :math:`\\hat{p}(1-\\hat{p})`.\n",
      "        \n",
      "        >>> ttest_ind_from_stats(mean1=0.2, std1=np.sqrt(0.16), nobs1=150,\n",
      "        ...                      mean2=0.225, std2=np.sqrt(0.17437), nobs2=200)\n",
      "        Ttest_indResult(statistic=-0.564327545549774, pvalue=0.5728947691244874)\n",
      "        \n",
      "        For comparison, we could compute the t statistic and p-value using\n",
      "        arrays of 0s and 1s and `scipy.stat.ttest_ind`, as above.\n",
      "        \n",
      "        >>> group1 = np.array([1]*30 + [0]*(150-30))\n",
      "        >>> group2 = np.array([1]*45 + [0]*(200-45))\n",
      "        >>> ttest_ind(group1, group2)\n",
      "        Ttest_indResult(statistic=-0.5627179589855622, pvalue=0.573989277115258)\n",
      "    \n",
      "    ttest_rel(a, b, axis=0, nan_policy='propagate')\n",
      "        Calculate the t-test on TWO RELATED samples of scores, a and b.\n",
      "        \n",
      "        This is a two-sided test for the null hypothesis that 2 related or\n",
      "        repeated samples have identical average (expected) values.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a, b : array_like\n",
      "            The arrays must have the same shape.\n",
      "        axis : int or None, optional\n",
      "            Axis along which to compute test. If None, compute over the whole\n",
      "            arrays, `a`, and `b`.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan.\n",
      "            The following options are available (default is 'propagate'):\n",
      "        \n",
      "              * 'propagate': returns nan\n",
      "              * 'raise': throws an error\n",
      "              * 'omit': performs the calculations ignoring nan values\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float or array\n",
      "            t-statistic.\n",
      "        pvalue : float or array\n",
      "            Two-sided p-value.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Examples for use are scores of the same set of student in\n",
      "        different exams, or repeated sampling from the same units. The\n",
      "        test measures whether the average score differs significantly\n",
      "        across samples (e.g. exams). If we observe a large p-value, for\n",
      "        example greater than 0.05 or 0.1 then we cannot reject the null\n",
      "        hypothesis of identical average scores. If the p-value is smaller\n",
      "        than the threshold, e.g. 1%, 5% or 10%, then we reject the null\n",
      "        hypothesis of equal averages. Small p-values are associated with\n",
      "        large t-statistics.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        https://en.wikipedia.org/wiki/T-test#Dependent_t-test_for_paired_samples\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> np.random.seed(12345678) # fix random seed to get same numbers\n",
      "        \n",
      "        >>> rvs1 = stats.norm.rvs(loc=5,scale=10,size=500)\n",
      "        >>> rvs2 = (stats.norm.rvs(loc=5,scale=10,size=500) +\n",
      "        ...         stats.norm.rvs(scale=0.2,size=500))\n",
      "        >>> stats.ttest_rel(rvs1,rvs2)\n",
      "        (0.24101764965300962, 0.80964043445811562)\n",
      "        >>> rvs3 = (stats.norm.rvs(loc=8,scale=10,size=500) +\n",
      "        ...         stats.norm.rvs(scale=0.2,size=500))\n",
      "        >>> stats.ttest_rel(rvs1,rvs3)\n",
      "        (-3.9995108708727933, 7.3082402191726459e-005)\n",
      "    \n",
      "    tvar(a, limits=None, inclusive=(True, True), axis=0, ddof=1)\n",
      "        Compute the trimmed variance.\n",
      "        \n",
      "        This function computes the sample variance of an array of values,\n",
      "        while ignoring values which are outside of given `limits`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Array of values.\n",
      "        limits : None or (lower limit, upper limit), optional\n",
      "            Values in the input array less than the lower limit or greater than the\n",
      "            upper limit will be ignored. When limits is None, then all values are\n",
      "            used. Either of the limit values in the tuple can also be None\n",
      "            representing a half-open interval.  The default value is None.\n",
      "        inclusive : (bool, bool), optional\n",
      "            A tuple consisting of the (lower flag, upper flag).  These flags\n",
      "            determine whether values exactly equal to the lower or upper limits\n",
      "            are included.  The default value is (True, True).\n",
      "        axis : int or None, optional\n",
      "            Axis along which to operate. Default is 0. If None, compute over the\n",
      "            whole array `a`.\n",
      "        ddof : int, optional\n",
      "            Delta degrees of freedom.  Default is 1.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        tvar : float\n",
      "            Trimmed variance.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        `tvar` computes the unbiased sample variance, i.e. it uses a correction\n",
      "        factor ``n / (n - 1)``.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> x = np.arange(20)\n",
      "        >>> stats.tvar(x)\n",
      "        35.0\n",
      "        >>> stats.tvar(x, (3,17))\n",
      "        20.0\n",
      "    \n",
      "    variation(a, axis=0, nan_policy='propagate')\n",
      "        Compute the coefficient of variation.\n",
      "        \n",
      "        The coefficient of variation is the ratio of the biased standard\n",
      "        deviation to the mean.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            Input array.\n",
      "        axis : int or None, optional\n",
      "            Axis along which to calculate the coefficient of variation. Default\n",
      "            is 0. If None, compute over the whole array `a`.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan.\n",
      "            The following options are available (default is 'propagate'):\n",
      "        \n",
      "              * 'propagate': returns nan\n",
      "              * 'raise': throws an error\n",
      "              * 'omit': performs the calculations ignoring nan values\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        variation : ndarray\n",
      "            The calculated variation along the requested axis.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Zwillinger, D. and Kokoska, S. (2000). CRC Standard\n",
      "           Probability and Statistics Tables and Formulae. Chapman & Hall: New\n",
      "           York. 2000.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.stats import variation\n",
      "        >>> variation([1, 2, 3, 4, 5])\n",
      "        0.47140452079103173\n",
      "    \n",
      "    wasserstein_distance(u_values, v_values, u_weights=None, v_weights=None)\n",
      "        Compute the first Wasserstein distance between two 1D distributions.\n",
      "        \n",
      "        This distance is also known as the earth mover's distance, since it can be\n",
      "        seen as the minimum amount of \"work\" required to transform :math:`u` into\n",
      "        :math:`v`, where \"work\" is measured as the amount of distribution weight\n",
      "        that must be moved, multiplied by the distance it has to be moved.\n",
      "        \n",
      "        .. versionadded:: 1.0.0\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        u_values, v_values : array_like\n",
      "            Values observed in the (empirical) distribution.\n",
      "        u_weights, v_weights : array_like, optional\n",
      "            Weight for each value. If unspecified, each value is assigned the same\n",
      "            weight.\n",
      "            `u_weights` (resp. `v_weights`) must have the same length as\n",
      "            `u_values` (resp. `v_values`). If the weight sum differs from 1, it\n",
      "            must still be positive and finite so that the weights can be normalized\n",
      "            to sum to 1.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        distance : float\n",
      "            The computed distance between the distributions.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The first Wasserstein distance between the distributions :math:`u` and\n",
      "        :math:`v` is:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            l_1 (u, v) = \\inf_{\\pi \\in \\Gamma (u, v)} \\int_{\\mathbb{R} \\times\n",
      "            \\mathbb{R}} |x-y| \\mathrm{d} \\pi (x, y)\n",
      "        \n",
      "        where :math:`\\Gamma (u, v)` is the set of (probability) distributions on\n",
      "        :math:`\\mathbb{R} \\times \\mathbb{R}` whose marginals are :math:`u` and\n",
      "        :math:`v` on the first and second factors respectively.\n",
      "        \n",
      "        If :math:`U` and :math:`V` are the respective CDFs of :math:`u` and\n",
      "        :math:`v`, this distance also equals to:\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            l_1(u, v) = \\int_{-\\infty}^{+\\infty} |U-V|\n",
      "        \n",
      "        See [2]_ for a proof of the equivalence of both definitions.\n",
      "        \n",
      "        The input distributions can be empirical, therefore coming from samples\n",
      "        whose values are effectively inputs of the function, or they can be seen as\n",
      "        generalized functions, in which case they are weighted sums of Dirac delta\n",
      "        functions located at the specified values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] \"Wasserstein metric\", https://en.wikipedia.org/wiki/Wasserstein_metric\n",
      "        .. [2] Ramdas, Garcia, Cuturi \"On Wasserstein Two Sample Testing and Related\n",
      "               Families of Nonparametric Tests\" (2015). :arXiv:`1509.02237`.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.stats import wasserstein_distance\n",
      "        >>> wasserstein_distance([0, 1, 3], [5, 6, 8])\n",
      "        5.0\n",
      "        >>> wasserstein_distance([0, 1], [0, 1], [3, 1], [2, 2])\n",
      "        0.25\n",
      "        >>> wasserstein_distance([3.4, 3.9, 7.5, 7.8], [4.5, 1.4],\n",
      "        ...                      [1.4, 0.9, 3.1, 7.2], [3.2, 3.5])\n",
      "        4.0781331438047861\n",
      "    \n",
      "    weightedtau(x, y, rank=True, weigher=None, additive=True)\n",
      "        Compute a weighted version of Kendall's :math:`\\tau`.\n",
      "        \n",
      "        The weighted :math:`\\tau` is a weighted version of Kendall's\n",
      "        :math:`\\tau` in which exchanges of high weight are more influential than\n",
      "        exchanges of low weight. The default parameters compute the additive\n",
      "        hyperbolic version of the index, :math:`\\tau_\\mathrm h`, which has\n",
      "        been shown to provide the best balance between important and\n",
      "        unimportant elements [1]_.\n",
      "        \n",
      "        The weighting is defined by means of a rank array, which assigns a\n",
      "        nonnegative rank to each element, and a weigher function, which\n",
      "        assigns a weight based from the rank to each element. The weight of an\n",
      "        exchange is then the sum or the product of the weights of the ranks of\n",
      "        the exchanged elements. The default parameters compute\n",
      "        :math:`\\tau_\\mathrm h`: an exchange between elements with rank\n",
      "        :math:`r` and :math:`s` (starting from zero) has weight\n",
      "        :math:`1/(r+1) + 1/(s+1)`.\n",
      "        \n",
      "        Specifying a rank array is meaningful only if you have in mind an\n",
      "        external criterion of importance. If, as it usually happens, you do\n",
      "        not have in mind a specific rank, the weighted :math:`\\tau` is\n",
      "        defined by averaging the values obtained using the decreasing\n",
      "        lexicographical rank by (`x`, `y`) and by (`y`, `x`). This is the\n",
      "        behavior with default parameters.\n",
      "        \n",
      "        Note that if you are computing the weighted :math:`\\tau` on arrays of\n",
      "        ranks, rather than of scores (i.e., a larger value implies a lower\n",
      "        rank) you must negate the ranks, so that elements of higher rank are\n",
      "        associated with a larger value.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x, y : array_like\n",
      "            Arrays of scores, of the same shape. If arrays are not 1-D, they will\n",
      "            be flattened to 1-D.\n",
      "        rank : array_like of ints or bool, optional\n",
      "            A nonnegative rank assigned to each element. If it is None, the\n",
      "            decreasing lexicographical rank by (`x`, `y`) will be used: elements of\n",
      "            higher rank will be those with larger `x`-values, using `y`-values to\n",
      "            break ties (in particular, swapping `x` and `y` will give a different\n",
      "            result). If it is False, the element indices will be used\n",
      "            directly as ranks. The default is True, in which case this\n",
      "            function returns the average of the values obtained using the\n",
      "            decreasing lexicographical rank by (`x`, `y`) and by (`y`, `x`).\n",
      "        weigher : callable, optional\n",
      "            The weigher function. Must map nonnegative integers (zero\n",
      "            representing the most important element) to a nonnegative weight.\n",
      "            The default, None, provides hyperbolic weighing, that is,\n",
      "            rank :math:`r` is mapped to weight :math:`1/(r+1)`.\n",
      "        additive : bool, optional\n",
      "            If True, the weight of an exchange is computed by adding the\n",
      "            weights of the ranks of the exchanged elements; otherwise, the weights\n",
      "            are multiplied. The default is True.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        correlation : float\n",
      "           The weighted :math:`\\tau` correlation index.\n",
      "        pvalue : float\n",
      "           Presently ``np.nan``, as the null statistics is unknown (even in the\n",
      "           additive hyperbolic case).\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        kendalltau : Calculates Kendall's tau.\n",
      "        spearmanr : Calculates a Spearman rank-order correlation coefficient.\n",
      "        theilslopes : Computes the Theil-Sen estimator for a set of points (x, y).\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This function uses an :math:`O(n \\log n)`, mergesort-based algorithm\n",
      "        [1]_ that is a weighted extension of Knight's algorithm for Kendall's\n",
      "        :math:`\\tau` [2]_. It can compute Shieh's weighted :math:`\\tau` [3]_\n",
      "        between rankings without ties (i.e., permutations) by setting\n",
      "        `additive` and `rank` to False, as the definition given in [1]_ is a\n",
      "        generalization of Shieh's.\n",
      "        \n",
      "        NaNs are considered the smallest possible score.\n",
      "        \n",
      "        .. versionadded:: 0.19.0\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Sebastiano Vigna, \"A weighted correlation index for rankings with\n",
      "               ties\", Proceedings of the 24th international conference on World\n",
      "               Wide Web, pp. 1166-1176, ACM, 2015.\n",
      "        .. [2] W.R. Knight, \"A Computer Method for Calculating Kendall's Tau with\n",
      "               Ungrouped Data\", Journal of the American Statistical Association,\n",
      "               Vol. 61, No. 314, Part 1, pp. 436-439, 1966.\n",
      "        .. [3] Grace S. Shieh. \"A weighted Kendall's tau statistic\", Statistics &\n",
      "               Probability Letters, Vol. 39, No. 1, pp. 17-24, 1998.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> x = [12, 2, 1, 12, 2]\n",
      "        >>> y = [1, 4, 7, 1, 0]\n",
      "        >>> tau, p_value = stats.weightedtau(x, y)\n",
      "        >>> tau\n",
      "        -0.56694968153682723\n",
      "        >>> p_value\n",
      "        nan\n",
      "        >>> tau, p_value = stats.weightedtau(x, y, additive=False)\n",
      "        >>> tau\n",
      "        -0.62205716951801038\n",
      "        \n",
      "        NaNs are considered the smallest possible score:\n",
      "        \n",
      "        >>> x = [12, 2, 1, 12, 2]\n",
      "        >>> y = [1, 4, 7, 1, np.nan]\n",
      "        >>> tau, _ = stats.weightedtau(x, y)\n",
      "        >>> tau\n",
      "        -0.56694968153682723\n",
      "        \n",
      "        This is exactly Kendall's tau:\n",
      "        \n",
      "        >>> x = [12, 2, 1, 12, 2]\n",
      "        >>> y = [1, 4, 7, 1, 0]\n",
      "        >>> tau, _ = stats.weightedtau(x, y, weigher=lambda x: 1)\n",
      "        >>> tau\n",
      "        -0.47140452079103173\n",
      "        \n",
      "        >>> x = [12, 2, 1, 12, 2]\n",
      "        >>> y = [1, 4, 7, 1, 0]\n",
      "        >>> stats.weightedtau(x, y, rank=None)\n",
      "        WeightedTauResult(correlation=-0.4157652301037516, pvalue=nan)\n",
      "        >>> stats.weightedtau(y, x, rank=None)\n",
      "        WeightedTauResult(correlation=-0.7181341329699028, pvalue=nan)\n",
      "    \n",
      "    wilcoxon(x, y=None, zero_method='wilcox', correction=False, alternative='two-sided')\n",
      "        Calculate the Wilcoxon signed-rank test.\n",
      "        \n",
      "        The Wilcoxon signed-rank test tests the null hypothesis that two\n",
      "        related paired samples come from the same distribution. In particular,\n",
      "        it tests whether the distribution of the differences x - y is symmetric\n",
      "        about zero. It is a non-parametric version of the paired T-test.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Either the first set of measurements (in which case `y` is the second\n",
      "            set of measurements), or the differences between two sets of\n",
      "            measurements (in which case `y` is not to be specified.)  Must be\n",
      "            one-dimensional.\n",
      "        y : array_like, optional\n",
      "            Either the second set of measurements (if `x` is the first set of\n",
      "            measurements), or not specified (if `x` is the differences between\n",
      "            two sets of measurements.)  Must be one-dimensional.\n",
      "        zero_method : {'pratt', 'wilcox', 'zsplit'}, optional\n",
      "            The following options are available (default is 'wilcox'):\n",
      "         \n",
      "              * 'pratt': Includes zero-differences in the ranking process,\n",
      "                but drops the ranks of the zeros, see [4]_, (more conservative).\n",
      "              * 'wilcox': Discards all zero-differences, the default.\n",
      "              * 'zsplit': Includes zero-differences in the ranking process and \n",
      "                split the zero rank between positive and negative ones.\n",
      "        correction : bool, optional\n",
      "            If True, apply continuity correction by adjusting the Wilcoxon rank\n",
      "            statistic by 0.5 towards the mean value when computing the\n",
      "            z-statistic.  Default is False.\n",
      "        alternative : {\"two-sided\", \"greater\", \"less\"}, optional\n",
      "            The alternative hypothesis to be tested, see Notes. Default is\n",
      "            \"two-sided\".\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        statistic : float\n",
      "            If `alternative` is \"two-sided\", the sum of the ranks of the\n",
      "            differences above or below zero, whichever is smaller.\n",
      "            Otherwise the sum of the ranks of the differences above zero.\n",
      "        pvalue : float\n",
      "            The p-value for the test depending on `alternative`.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        kruskal, mannwhitneyu\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The test has been introduced in [4]_. Given n independent samples\n",
      "        (xi, yi) from a bivariate distribution (i.e. paired samples),\n",
      "        it computes the differences di = xi - yi. One assumption of the test\n",
      "        is that the differences are symmetric, see [2]_.\n",
      "        The two-sided test has the null hypothesis that the median of the\n",
      "        differences is zero against the alternative that it is different from\n",
      "        zero. The one-sided test has the null hypothesis that the median is \n",
      "        positive against the alternative that it is negative \n",
      "        (``alternative == 'less'``), or vice versa (``alternative == 'greater.'``).\n",
      "        \n",
      "        The test uses a normal approximation to derive the p-value (if\n",
      "        ``zero_method == 'pratt'``, the approximation is adjusted as in [5]_).\n",
      "        A typical rule is to require that n > 20 ([2]_, p. 383). For smaller n,\n",
      "        exact tables can be used to find critical values.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] https://en.wikipedia.org/wiki/Wilcoxon_signed-rank_test\n",
      "        .. [2] Conover, W.J., Practical Nonparametric Statistics, 1971.\n",
      "        .. [3] Pratt, J.W., Remarks on Zeros and Ties in the Wilcoxon Signed\n",
      "           Rank Procedures, Journal of the American Statistical Association,\n",
      "           Vol. 54, 1959, pp. 655-667. :doi:`10.1080/01621459.1959.10501526`\n",
      "        .. [4] Wilcoxon, F., Individual Comparisons by Ranking Methods,\n",
      "           Biometrics Bulletin, Vol. 1, 1945, pp. 80-83. :doi:`10.2307/3001968`\n",
      "        .. [5] Cureton, E.E., The Normal Approximation to the Signed-Rank\n",
      "           Sampling Distribution When Zero Differences are Present,\n",
      "           Journal of the American Statistical Association, Vol. 62, 1967,\n",
      "           pp. 1068-1069. :doi:`10.1080/01621459.1967.10500917`\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        In [4]_, the differences in height between cross- and self-fertilized\n",
      "        corn plants is given as follows:\n",
      "        \n",
      "        >>> d = [6, 8, 14, 16, 23, 24, 28, 29, 41, -48, 49, 56, 60, -67, 75]\n",
      "        \n",
      "        Cross-fertilized plants appear to be be higher. To test the null\n",
      "        hypothesis that there is no height difference, we can apply the\n",
      "        two-sided test:\n",
      "        \n",
      "        >>> from scipy.stats import wilcoxon\n",
      "        >>> w, p = wilcoxon(d)\n",
      "        >>> w, p\n",
      "        (24.0, 0.04088813291185591)\n",
      "        \n",
      "        Hence, we would reject the null hypothesis at a confidence level of 5%,\n",
      "        concluding that there is a difference in height between the groups.\n",
      "        To confirm that the median of the differences can be assumed to be\n",
      "        positive, we use:\n",
      "        \n",
      "        >>> w, p = wilcoxon(d, alternative='greater')\n",
      "        >>> w, p\n",
      "        (96.0, 0.020444066455927955)\n",
      "        \n",
      "        This shows that the null hypothesis that the median is negative can be\n",
      "        rejected at a confidence level of 5% in favor of the alternative that\n",
      "        the median is greater than zero. The p-value based on the approximation\n",
      "        is within the range of 0.019 and 0.054 given in [2]_.\n",
      "        Note that the statistic changed to 96 in the one-sided case (the sum\n",
      "        of ranks of positive differences) whereas it is 24 in the two-sided\n",
      "        case (the minimum of sum of ranks above and below zero).\n",
      "    \n",
      "    yeojohnson(x, lmbda=None)\n",
      "        Return a dataset transformed by a Yeo-Johnson power transformation.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : ndarray\n",
      "            Input array.  Should be 1-dimensional.\n",
      "        lmbda : float, optional\n",
      "            If ``lmbda`` is ``None``, find the lambda that maximizes the\n",
      "            log-likelihood function and return it as the second output argument.\n",
      "            Otherwise the transformation is done for the given value.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        yeojohnson: ndarray\n",
      "            Yeo-Johnson power transformed array.\n",
      "        maxlog : float, optional\n",
      "            If the `lmbda` parameter is None, the second returned argument is\n",
      "            the lambda that maximizes the log-likelihood function.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        probplot, yeojohnson_normplot, yeojohnson_normmax, yeojohnson_llf, boxcox\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The Yeo-Johnson transform is given by::\n",
      "        \n",
      "            y = ((x + 1)**lmbda - 1) / lmbda,                for x >= 0, lmbda != 0\n",
      "                log(x + 1),                                  for x >= 0, lmbda = 0\n",
      "                -((-x + 1)**(2 - lmbda) - 1) / (2 - lmbda),  for x < 0, lmbda != 2\n",
      "                -log(-x + 1),                                for x < 0, lmbda = 2\n",
      "        \n",
      "        Unlike `boxcox`, `yeojohnson` does not require the input data to be\n",
      "        positive.\n",
      "        \n",
      "        .. versionadded:: 1.2.0\n",
      "        \n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        I. Yeo and R.A. Johnson, \"A New Family of Power Transformations to\n",
      "        Improve Normality or Symmetry\", Biometrika 87.4 (2000):\n",
      "        \n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        \n",
      "        We generate some random variates from a non-normal distribution and make a\n",
      "        probability plot for it, to show it is non-normal in the tails:\n",
      "        \n",
      "        >>> fig = plt.figure()\n",
      "        >>> ax1 = fig.add_subplot(211)\n",
      "        >>> x = stats.loggamma.rvs(5, size=500) + 5\n",
      "        >>> prob = stats.probplot(x, dist=stats.norm, plot=ax1)\n",
      "        >>> ax1.set_xlabel('')\n",
      "        >>> ax1.set_title('Probplot against normal distribution')\n",
      "        \n",
      "        We now use `yeojohnson` to transform the data so it's closest to normal:\n",
      "        \n",
      "        >>> ax2 = fig.add_subplot(212)\n",
      "        >>> xt, lmbda = stats.yeojohnson(x)\n",
      "        >>> prob = stats.probplot(xt, dist=stats.norm, plot=ax2)\n",
      "        >>> ax2.set_title('Probplot after Yeo-Johnson transformation')\n",
      "        \n",
      "        >>> plt.show()\n",
      "    \n",
      "    yeojohnson_llf(lmb, data)\n",
      "        The yeojohnson log-likelihood function.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        lmb : scalar\n",
      "            Parameter for Yeo-Johnson transformation. See `yeojohnson` for\n",
      "            details.\n",
      "        data : array_like\n",
      "            Data to calculate Yeo-Johnson log-likelihood for. If `data` is\n",
      "            multi-dimensional, the log-likelihood is calculated along the first\n",
      "            axis.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        llf : float\n",
      "            Yeo-Johnson log-likelihood of `data` given `lmb`.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        yeojohnson, probplot, yeojohnson_normplot, yeojohnson_normmax\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The Yeo-Johnson log-likelihood function is defined here as\n",
      "        \n",
      "        .. math::\n",
      "        \n",
      "            llf = N/2 \\log(\\hat{\\sigma}^2) + (\\lambda - 1)\n",
      "                  \\sum_i \\text{ sign }(x_i)\\log(|x_i| + 1)\n",
      "        \n",
      "        where :math:`\\hat{\\sigma}^2` is estimated variance of the the Yeo-Johnson\n",
      "        transformed input data ``x``.\n",
      "        \n",
      "        .. versionadded:: 1.2.0\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
      "        >>> np.random.seed(1245)\n",
      "        \n",
      "        Generate some random variates and calculate Yeo-Johnson log-likelihood\n",
      "        values for them for a range of ``lmbda`` values:\n",
      "        \n",
      "        >>> x = stats.loggamma.rvs(5, loc=10, size=1000)\n",
      "        >>> lmbdas = np.linspace(-2, 10)\n",
      "        >>> llf = np.zeros(lmbdas.shape, dtype=float)\n",
      "        >>> for ii, lmbda in enumerate(lmbdas):\n",
      "        ...     llf[ii] = stats.yeojohnson_llf(lmbda, x)\n",
      "        \n",
      "        Also find the optimal lmbda value with `yeojohnson`:\n",
      "        \n",
      "        >>> x_most_normal, lmbda_optimal = stats.yeojohnson(x)\n",
      "        \n",
      "        Plot the log-likelihood as function of lmbda.  Add the optimal lmbda as a\n",
      "        horizontal line to check that that's really the optimum:\n",
      "        \n",
      "        >>> fig = plt.figure()\n",
      "        >>> ax = fig.add_subplot(111)\n",
      "        >>> ax.plot(lmbdas, llf, 'b.-')\n",
      "        >>> ax.axhline(stats.yeojohnson_llf(lmbda_optimal, x), color='r')\n",
      "        >>> ax.set_xlabel('lmbda parameter')\n",
      "        >>> ax.set_ylabel('Yeo-Johnson log-likelihood')\n",
      "        \n",
      "        Now add some probability plots to show that where the log-likelihood is\n",
      "        maximized the data transformed with `yeojohnson` looks closest to normal:\n",
      "        \n",
      "        >>> locs = [3, 10, 4]  # 'lower left', 'center', 'lower right'\n",
      "        >>> for lmbda, loc in zip([-1, lmbda_optimal, 9], locs):\n",
      "        ...     xt = stats.yeojohnson(x, lmbda=lmbda)\n",
      "        ...     (osm, osr), (slope, intercept, r_sq) = stats.probplot(xt)\n",
      "        ...     ax_inset = inset_axes(ax, width=\"20%\", height=\"20%\", loc=loc)\n",
      "        ...     ax_inset.plot(osm, osr, 'c.', osm, slope*osm + intercept, 'k-')\n",
      "        ...     ax_inset.set_xticklabels([])\n",
      "        ...     ax_inset.set_yticklabels([])\n",
      "        ...     ax_inset.set_title(r'$\\lambda=%1.2f$' % lmbda)\n",
      "        \n",
      "        >>> plt.show()\n",
      "    \n",
      "    yeojohnson_normmax(x, brack=(-2, 2))\n",
      "        Compute optimal Yeo-Johnson transform parameter.\n",
      "        \n",
      "        Compute optimal Yeo-Johnson transform parameter for input data, using\n",
      "        maximum likelihood estimation.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Input array.\n",
      "        brack : 2-tuple, optional\n",
      "            The starting interval for a downhill bracket search with\n",
      "            `optimize.brent`. Note that this is in most cases not critical; the\n",
      "            final result is allowed to be outside this bracket.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        maxlog : float\n",
      "            The optimal transform parameter found.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        yeojohnson, yeojohnson_llf, yeojohnson_normplot\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        .. versionadded:: 1.2.0\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> np.random.seed(1234)  # make this example reproducible\n",
      "        \n",
      "        Generate some data and determine optimal ``lmbda``\n",
      "        \n",
      "        >>> x = stats.loggamma.rvs(5, size=30) + 5\n",
      "        >>> lmax = stats.yeojohnson_normmax(x)\n",
      "        \n",
      "        >>> fig = plt.figure()\n",
      "        >>> ax = fig.add_subplot(111)\n",
      "        >>> prob = stats.yeojohnson_normplot(x, -10, 10, plot=ax)\n",
      "        >>> ax.axvline(lmax, color='r')\n",
      "        \n",
      "        >>> plt.show()\n",
      "    \n",
      "    yeojohnson_normplot(x, la, lb, plot=None, N=80)\n",
      "        Compute parameters for a Yeo-Johnson normality plot, optionally show it.\n",
      "        \n",
      "        A Yeo-Johnson normality plot shows graphically what the best\n",
      "        transformation parameter is to use in `yeojohnson` to obtain a\n",
      "        distribution that is close to normal.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            Input array.\n",
      "        la, lb : scalar\n",
      "            The lower and upper bounds for the ``lmbda`` values to pass to\n",
      "            `yeojohnson` for Yeo-Johnson transformations. These are also the\n",
      "            limits of the horizontal axis of the plot if that is generated.\n",
      "        plot : object, optional\n",
      "            If given, plots the quantiles and least squares fit.\n",
      "            `plot` is an object that has to have methods \"plot\" and \"text\".\n",
      "            The `matplotlib.pyplot` module or a Matplotlib Axes object can be used,\n",
      "            or a custom object with the same methods.\n",
      "            Default is None, which means that no plot is created.\n",
      "        N : int, optional\n",
      "            Number of points on the horizontal axis (equally distributed from\n",
      "            `la` to `lb`).\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        lmbdas : ndarray\n",
      "            The ``lmbda`` values for which a Yeo-Johnson transform was done.\n",
      "        ppcc : ndarray\n",
      "            Probability Plot Correlelation Coefficient, as obtained from `probplot`\n",
      "            when fitting the Box-Cox transformed input `x` against a normal\n",
      "            distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        probplot, yeojohnson, yeojohnson_normmax, yeojohnson_llf, ppcc_max\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        Even if `plot` is given, the figure is not shown or saved by\n",
      "        `boxcox_normplot`; ``plt.show()`` or ``plt.savefig('figname.png')``\n",
      "        should be used after calling `probplot`.\n",
      "        \n",
      "        .. versionadded:: 1.2.0\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy import stats\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        \n",
      "        Generate some non-normally distributed data, and create a Yeo-Johnson plot:\n",
      "        \n",
      "        >>> x = stats.loggamma.rvs(5, size=500) + 5\n",
      "        >>> fig = plt.figure()\n",
      "        >>> ax = fig.add_subplot(111)\n",
      "        >>> prob = stats.yeojohnson_normplot(x, -20, 20, plot=ax)\n",
      "        \n",
      "        Determine and plot the optimal ``lmbda`` to transform ``x`` and plot it in\n",
      "        the same plot:\n",
      "        \n",
      "        >>> _, maxlog = stats.yeojohnson(x)\n",
      "        >>> ax.axvline(maxlog, color='r')\n",
      "        \n",
      "        >>> plt.show()\n",
      "    \n",
      "    zmap(scores, compare, axis=0, ddof=0)\n",
      "        Calculate the relative z-scores.\n",
      "        \n",
      "        Return an array of z-scores, i.e., scores that are standardized to\n",
      "        zero mean and unit variance, where mean and variance are calculated\n",
      "        from the comparison array.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        scores : array_like\n",
      "            The input for which z-scores are calculated.\n",
      "        compare : array_like\n",
      "            The input from which the mean and standard deviation of the\n",
      "            normalization are taken; assumed to have the same dimension as\n",
      "            `scores`.\n",
      "        axis : int or None, optional\n",
      "            Axis over which mean and variance of `compare` are calculated.\n",
      "            Default is 0. If None, compute over the whole array `scores`.\n",
      "        ddof : int, optional\n",
      "            Degrees of freedom correction in the calculation of the\n",
      "            standard deviation. Default is 0.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        zscore : array_like\n",
      "            Z-scores, in the same shape as `scores`.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This function preserves ndarray subclasses, and works also with\n",
      "        matrices and masked arrays (it uses `asanyarray` instead of\n",
      "        `asarray` for parameters).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> from scipy.stats import zmap\n",
      "        >>> a = [0.5, 2.0, 2.5, 3]\n",
      "        >>> b = [0, 1, 2, 3, 4]\n",
      "        >>> zmap(a, b)\n",
      "        array([-1.06066017,  0.        ,  0.35355339,  0.70710678])\n",
      "    \n",
      "    zscore(a, axis=0, ddof=0, nan_policy='propagate')\n",
      "        Compute the z score.\n",
      "        \n",
      "        Compute the z score of each value in the sample, relative to the\n",
      "        sample mean and standard deviation.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : array_like\n",
      "            An array like object containing the sample data.\n",
      "        axis : int or None, optional\n",
      "            Axis along which to operate. Default is 0. If None, compute over\n",
      "            the whole array `a`.\n",
      "        ddof : int, optional\n",
      "            Degrees of freedom correction in the calculation of the\n",
      "            standard deviation. Default is 0.\n",
      "        nan_policy : {'propagate', 'raise', 'omit'}, optional\n",
      "            Defines how to handle when input contains nan. 'propagate' returns nan,\n",
      "            'raise' throws an error, 'omit' performs the calculations ignoring nan\n",
      "            values. Default is 'propagate'.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        zscore : array_like\n",
      "            The z-scores, standardized by mean and standard deviation of\n",
      "            input array `a`.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This function preserves ndarray subclasses, and works also with\n",
      "        matrices and masked arrays (it uses `asanyarray` instead of\n",
      "        `asarray` for parameters).\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> a = np.array([ 0.7972,  0.0767,  0.4383,  0.7866,  0.8091,\n",
      "        ...                0.1954,  0.6307,  0.6599,  0.1065,  0.0508])\n",
      "        >>> from scipy import stats\n",
      "        >>> stats.zscore(a)\n",
      "        array([ 1.1273, -1.247 , -0.0552,  1.0923,  1.1664, -0.8559,  0.5786,\n",
      "                0.6748, -1.1488, -1.3324])\n",
      "        \n",
      "        Computing along a specified axis, using n-1 degrees of freedom\n",
      "        (``ddof=1``) to calculate the standard deviation:\n",
      "        \n",
      "        >>> b = np.array([[ 0.3148,  0.0478,  0.6243,  0.4608],\n",
      "        ...               [ 0.7149,  0.0775,  0.6072,  0.9656],\n",
      "        ...               [ 0.6341,  0.1403,  0.9759,  0.4064],\n",
      "        ...               [ 0.5918,  0.6948,  0.904 ,  0.3721],\n",
      "        ...               [ 0.0921,  0.2481,  0.1188,  0.1366]])\n",
      "        >>> stats.zscore(b, axis=1, ddof=1)\n",
      "        array([[-0.19264823, -1.28415119,  1.07259584,  0.40420358],\n",
      "               [ 0.33048416, -1.37380874,  0.04251374,  1.00081084],\n",
      "               [ 0.26796377, -1.12598418,  1.23283094, -0.37481053],\n",
      "               [-0.22095197,  0.24468594,  1.19042819, -1.21416216],\n",
      "               [-0.82780366,  1.4457416 , -0.43867764, -0.1792603 ]])\n",
      "\n",
      "DATA\n",
      "    __all__ = ['PearsonRConstantInputWarning', 'PearsonRNearConstantInputW...\n",
      "    absolute_import = _Feature((2, 5, 0, 'alpha', 1), (3, 0, 0, 'alpha', 0...\n",
      "    alpha = <scipy.stats._continuous_distns.alpha_gen object>\n",
      "    anglit = <scipy.stats._continuous_distns.anglit_gen object>\n",
      "    arcsine = <scipy.stats._continuous_distns.arcsine_gen object>\n",
      "    argus = <scipy.stats._continuous_distns.argus_gen object>\n",
      "    bernoulli = <scipy.stats._discrete_distns.bernoulli_gen object>\n",
      "    beta = <scipy.stats._continuous_distns.beta_gen object>\n",
      "    betabinom = <scipy.stats._discrete_distns.betabinom_gen object>\n",
      "    betaprime = <scipy.stats._continuous_distns.betaprime_gen object>\n",
      "    binom = <scipy.stats._discrete_distns.binom_gen object>\n",
      "    boltzmann = <scipy.stats._discrete_distns.boltzmann_gen object>\n",
      "    bradford = <scipy.stats._continuous_distns.bradford_gen object>\n",
      "    burr = <scipy.stats._continuous_distns.burr_gen object>\n",
      "    burr12 = <scipy.stats._continuous_distns.burr12_gen object>\n",
      "    cauchy = <scipy.stats._continuous_distns.cauchy_gen object>\n",
      "    chi = <scipy.stats._continuous_distns.chi_gen object>\n",
      "    chi2 = <scipy.stats._continuous_distns.chi2_gen object>\n",
      "    cosine = <scipy.stats._continuous_distns.cosine_gen object>\n",
      "    crystalball = <scipy.stats._continuous_distns.crystalball_gen object>\n",
      "    dgamma = <scipy.stats._continuous_distns.dgamma_gen object>\n",
      "    dirichlet = <scipy.stats._multivariate.dirichlet_gen object>\n",
      "    division = _Feature((2, 2, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0), 8192...\n",
      "    dlaplace = <scipy.stats._discrete_distns.dlaplace_gen object>\n",
      "    dweibull = <scipy.stats._continuous_distns.dweibull_gen object>\n",
      "    erlang = <scipy.stats._continuous_distns.erlang_gen object>\n",
      "    expon = <scipy.stats._continuous_distns.expon_gen object>\n",
      "    exponnorm = <scipy.stats._continuous_distns.exponnorm_gen object>\n",
      "    exponpow = <scipy.stats._continuous_distns.exponpow_gen object>\n",
      "    exponweib = <scipy.stats._continuous_distns.exponweib_gen object>\n",
      "    f = <scipy.stats._continuous_distns.f_gen object>\n",
      "    fatiguelife = <scipy.stats._continuous_distns.fatiguelife_gen object>\n",
      "    fisk = <scipy.stats._continuous_distns.fisk_gen object>\n",
      "    foldcauchy = <scipy.stats._continuous_distns.foldcauchy_gen object>\n",
      "    foldnorm = <scipy.stats._continuous_distns.foldnorm_gen object>\n",
      "    frechet_l = <scipy.stats._continuous_distns.frechet_l_gen object>\n",
      "    frechet_r = <scipy.stats._continuous_distns.frechet_r_gen object>\n",
      "    gamma = <scipy.stats._continuous_distns.gamma_gen object>\n",
      "    gausshyper = <scipy.stats._continuous_distns.gausshyper_gen object>\n",
      "    genexpon = <scipy.stats._continuous_distns.genexpon_gen object>\n",
      "    genextreme = <scipy.stats._continuous_distns.genextreme_gen object>\n",
      "    gengamma = <scipy.stats._continuous_distns.gengamma_gen object>\n",
      "    genhalflogistic = <scipy.stats._continuous_distns.genhalflogistic_gen ...\n",
      "    geninvgauss = <scipy.stats._continuous_distns.geninvgauss_gen object>\n",
      "    genlogistic = <scipy.stats._continuous_distns.genlogistic_gen object>\n",
      "    gennorm = <scipy.stats._continuous_distns.gennorm_gen object>\n",
      "    genpareto = <scipy.stats._continuous_distns.genpareto_gen object>\n",
      "    geom = <scipy.stats._discrete_distns.geom_gen object>\n",
      "    gilbrat = <scipy.stats._continuous_distns.gilbrat_gen object>\n",
      "    gompertz = <scipy.stats._continuous_distns.gompertz_gen object>\n",
      "    gumbel_l = <scipy.stats._continuous_distns.gumbel_l_gen object>\n",
      "    gumbel_r = <scipy.stats._continuous_distns.gumbel_r_gen object>\n",
      "    halfcauchy = <scipy.stats._continuous_distns.halfcauchy_gen object>\n",
      "    halfgennorm = <scipy.stats._continuous_distns.halfgennorm_gen object>\n",
      "    halflogistic = <scipy.stats._continuous_distns.halflogistic_gen object...\n",
      "    halfnorm = <scipy.stats._continuous_distns.halfnorm_gen object>\n",
      "    hypergeom = <scipy.stats._discrete_distns.hypergeom_gen object>\n",
      "    hypsecant = <scipy.stats._continuous_distns.hypsecant_gen object>\n",
      "    invgamma = <scipy.stats._continuous_distns.invgamma_gen object>\n",
      "    invgauss = <scipy.stats._continuous_distns.invgauss_gen object>\n",
      "    invweibull = <scipy.stats._continuous_distns.invweibull_gen object>\n",
      "    invwishart = <scipy.stats._multivariate.invwishart_gen object>\n",
      "    johnsonsb = <scipy.stats._continuous_distns.johnsonsb_gen object>\n",
      "    johnsonsu = <scipy.stats._continuous_distns.johnsonsu_gen object>\n",
      "    kappa3 = <scipy.stats._continuous_distns.kappa3_gen object>\n",
      "    kappa4 = <scipy.stats._continuous_distns.kappa4_gen object>\n",
      "    ksone = <scipy.stats._continuous_distns.ksone_gen object>\n",
      "    kstwobign = <scipy.stats._continuous_distns.kstwobign_gen object>\n",
      "    laplace = <scipy.stats._continuous_distns.laplace_gen object>\n",
      "    levy = <scipy.stats._continuous_distns.levy_gen object>\n",
      "    levy_l = <scipy.stats._continuous_distns.levy_l_gen object>\n",
      "    levy_stable = <scipy.stats._continuous_distns.levy_stable_gen object>\n",
      "    loggamma = <scipy.stats._continuous_distns.loggamma_gen object>\n",
      "    logistic = <scipy.stats._continuous_distns.logistic_gen object>\n",
      "    loglaplace = <scipy.stats._continuous_distns.loglaplace_gen object>\n",
      "    lognorm = <scipy.stats._continuous_distns.lognorm_gen object>\n",
      "    logser = <scipy.stats._discrete_distns.logser_gen object>\n",
      "    loguniform = <scipy.stats._continuous_distns.reciprocal_gen object>\n",
      "    lomax = <scipy.stats._continuous_distns.lomax_gen object>\n",
      "    matrix_normal = <scipy.stats._multivariate.matrix_normal_gen object>\n",
      "    maxwell = <scipy.stats._continuous_distns.maxwell_gen object>\n",
      "    mielke = <scipy.stats._continuous_distns.mielke_gen object>\n",
      "    moyal = <scipy.stats._continuous_distns.moyal_gen object>\n",
      "    multinomial = <scipy.stats._multivariate.multinomial_gen object>\n",
      "    multivariate_normal = <scipy.stats._multivariate.multivariate_normal_g...\n",
      "    nakagami = <scipy.stats._continuous_distns.nakagami_gen object>\n",
      "    nbinom = <scipy.stats._discrete_distns.nbinom_gen object>\n",
      "    ncf = <scipy.stats._continuous_distns.ncf_gen object>\n",
      "    nct = <scipy.stats._continuous_distns.nct_gen object>\n",
      "    ncx2 = <scipy.stats._continuous_distns.ncx2_gen object>\n",
      "    norm = <scipy.stats._continuous_distns.norm_gen object>\n",
      "    norminvgauss = <scipy.stats._continuous_distns.norminvgauss_gen object...\n",
      "    ortho_group = <scipy.stats._multivariate.ortho_group_gen object>\n",
      "    pareto = <scipy.stats._continuous_distns.pareto_gen object>\n",
      "    pearson3 = <scipy.stats._continuous_distns.pearson3_gen object>\n",
      "    planck = <scipy.stats._discrete_distns.planck_gen object>\n",
      "    poisson = <scipy.stats._discrete_distns.poisson_gen object>\n",
      "    powerlaw = <scipy.stats._continuous_distns.powerlaw_gen object>\n",
      "    powerlognorm = <scipy.stats._continuous_distns.powerlognorm_gen object...\n",
      "    powernorm = <scipy.stats._continuous_distns.powernorm_gen object>\n",
      "    print_function = _Feature((2, 6, 0, 'alpha', 2), (3, 0, 0, 'alpha', 0)...\n",
      "    randint = <scipy.stats._discrete_distns.randint_gen object>\n",
      "    random_correlation = <scipy.stats._multivariate.random_correlation_gen...\n",
      "    rayleigh = <scipy.stats._continuous_distns.rayleigh_gen object>\n",
      "    rdist = <scipy.stats._continuous_distns.rdist_gen object>\n",
      "    recipinvgauss = <scipy.stats._continuous_distns.recipinvgauss_gen obje...\n",
      "    reciprocal = <scipy.stats._continuous_distns.reciprocal_gen object>\n",
      "    rice = <scipy.stats._continuous_distns.rice_gen object>\n",
      "    semicircular = <scipy.stats._continuous_distns.semicircular_gen object...\n",
      "    skellam = <scipy.stats._discrete_distns.skellam_gen object>\n",
      "    skewnorm = <scipy.stats._continuous_distns.skew_norm_gen object>\n",
      "    special_ortho_group = <scipy.stats._multivariate.special_ortho_group_g...\n",
      "    t = <scipy.stats._continuous_distns.t_gen object>\n",
      "    trapz = <scipy.stats._continuous_distns.trapz_gen object>\n",
      "    triang = <scipy.stats._continuous_distns.triang_gen object>\n",
      "    truncexpon = <scipy.stats._continuous_distns.truncexpon_gen object>\n",
      "    truncnorm = <scipy.stats._continuous_distns.truncnorm_gen object>\n",
      "    tukeylambda = <scipy.stats._continuous_distns.tukeylambda_gen object>\n",
      "    uniform = <scipy.stats._continuous_distns.uniform_gen object>\n",
      "    unitary_group = <scipy.stats._multivariate.unitary_group_gen object>\n",
      "    vonmises = <scipy.stats._continuous_distns.vonmises_gen object>\n",
      "    vonmises_line = <scipy.stats._continuous_distns.vonmises_gen object>\n",
      "    wald = <scipy.stats._continuous_distns.wald_gen object>\n",
      "    weibull_max = <scipy.stats._continuous_distns.weibull_max_gen object>\n",
      "    weibull_min = <scipy.stats._continuous_distns.weibull_min_gen object>\n",
      "    wishart = <scipy.stats._multivariate.wishart_gen object>\n",
      "    wrapcauchy = <scipy.stats._continuous_distns.wrapcauchy_gen object>\n",
      "    yulesimon = <scipy.stats._discrete_distns.yulesimon_gen object>\n",
      "    zipf = <scipy.stats._discrete_distns.zipf_gen object>\n",
      "\n",
      "FILE\n",
      "    /Users/sholaayodz/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(scipy.stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint\n",
    "\n",
    "uni = randint(1,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni.pmf(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni.cdf(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = uni.rvs(size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 0., 2., 0., 0., 2., 0., 1., 0., 3.]),\n",
       " array([1. , 1.4, 1.8, 2.2, 2.6, 3. , 3.4, 3.8, 4.2, 4.6, 5. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernoulli Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describes an experiment where the outcome can be classified as with a 'success' or as a failure.\n",
    "# Success is denoted by P, Failure is denoted by 1-P\n",
    "\n",
    "p = 0.8\n",
    "\n",
    "bern = scipy.stats.bernoulli(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19999999999999998"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# P of failure = 1-P\n",
    "bern.pmf(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19999999999999996"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bern.cdf(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff339200e90>]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numrange = range(-10, 10)\n",
    "plt.plot(numrange, bern.pmf(numarange), 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff308f53490>]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = 0.6\n",
    "bern = scipy.stats.bernoulli(p)\n",
    "plt.plot(numrange, bern.pmf(numrange), 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff3392e1b10>]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(numrange, bern.cdf(numarange))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4048.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,    0.,\n",
       "        5952.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = bern.rvs(size = 10000)\n",
    "plt.hist(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binomial Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.5\n",
    "n =2 \n",
    "binomial = scipy.stats.binom(n,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binomial.pmf(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff31a07c050>]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(numrange, binomial.pmf(numrange), 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binomial.cdf(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff3492d3310>]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAYjUlEQVR4nO3de4xb53nn8e8zd2l014xGqi6WLI1sXZrCycDxOmlqR3YsuYXVFm0hA0W7bVCjF+9u0e5iHWThDZx/mgbdAsW6TdVtkG3QxnHvQqAZ2a3ttMnGriaJbVGSlaFk2RprOJyxLHmokebGZ/8gpTI0R3OGc8hzyPl9AMI8PO+QD14e/nz08uV5zd0REZHa1xB1ASIiEg4FuohInVCgi4jUCQW6iEidUKCLiNSJpqheuKOjw7du3RrVy4uI1KTvfve7o+7eWWpfZIG+detW+vv7o3p5EZGaZGZvzbZPQy4iInVCgS4iUicU6CIidUKBLiJSJxToIiJ1Ys5AN7Mvm1nazBKz7Dcz+yMzS5rZ62b24fDLFBGRuQQ5Q/8KsP8W+w8A3fnbY8CfLLwsERGZrznnobv7v5jZ1ls0OQj8heeuw/uyma0ysw3uPhRSjSKSNzmd5cvffpPxiemoS5EF2Lerix/bvCr05w3jh0UbgQsF24P5xz4Q6Gb2GLmzeLZs2RLCS4ssLkdPDPF7vW8AYBZxMVK2dSvaYhvopQ6rkqtmuPth4DBAT0+PVtYQmae+RIquFa1854l9NDQo0eWHhTHLZRDYXLC9CbgYwvOKSIHxyWle+kGah/asV5hLSWEE+hHgl/KzXe4Brmj8XCR83zwzwvWpLPv3ro+6FImpOYdczOxrwH1Ah5kNAv8TaAZw9y8BR4GHgSQwDvxKpYoVWcx6EynWtLdw99Y1UZciMRVklsujc+x34LdCq0hEPmBieoYX3kjzUx/aQFOjfg8openIEKkB3xoYJTMxreEWuSUFukgN6E2kWN7WxL3bO6IuRWJMgS4Sc1MzWZ4/NcyDu7poadJHVmano0Mk5l4+9y5Xrk1puEXmpEAXibneRIqlLY18YmfJZSRFblKgi8TYTNZ57mSK++9cR1tzY9TlSMwp0EVirP/8JUYzkxzQcIsEoEAXibHeRIrWpgbuv2Nd1KVIDVCgi8RUNuscO5niEzs7aW8N4zp6Uu8U6CIx9drgZYauXNdwiwSmQBeJqb5EiuZGY9+urqhLkRqhQBeJIXenN5Hi3u0drFzSHHU5UiMU6CIxdGrofd6+NK7hFpkXBbpIDPUlUjQYPLhbwy0SnAJdJIZ6Eyk+um0ta5e1Rl2K1BAFukjMJNNjJNMZDvyohltkfhToIjHTeyIFwEN7FOgyPwp0kZjpTaT4yG2r6VrRFnUpUmMU6CIx8va745wael+zW6QsCnSRGOlNDAEabpHyKNBFYqQ3kWLvxhVsXrM06lKkBinQRWJi6Mo1Xr1wmQN7N0RditQoBbpITPQlcrNbtNSclEuBLhITvYkUO7uWsb1zWdSlSI1SoIvEwMjYBMfPX2K/hltkARToIjHw3KkU7mi6oiyIAl0kBvoSKbauXcqd65dHXYrUMAW6SMQuj0/ynbPvsn/vBsws6nKkhinQRSL2/KlhprOu4RZZMAW6SMT6Eik2rlrChzatjLoUqXEKdJEIjV2f4l8HRnloz3oNt8iCBQp0M9tvZmfMLGlmT5TYv8XMXjSz75vZ62b2cPilitSfF95IMzmT1bXPJRRzBrqZNQJPAweA3cCjZra7qNn/AJ5197uAQ8Afh12oSD3qS6ToXN7KR7asjroUqQNBztDvBpLufs7dJ4FngINFbRxYkb+/ErgYXoki9ena5AwvnRnhoT1dNDRouEUWLkigbwQuFGwP5h8r9DngF81sEDgK/KdST2Rmj5lZv5n1j4yMlFGuSP345g/SXJua0cW4JDRBAr3UqYMXbT8KfMXdNwEPA181sw88t7sfdvced+/p7Oycf7UidaQ3kWL10mY+um1N1KVInQgS6IPA5oLtTXxwSOXTwLMA7v4doA3oCKNAkXo0MT3DC6fTPLi7i6ZGTTaTcAQ5ko4D3Wa2zcxayH3peaSozdvAPgAz20Uu0DWmIjKLbydHGZuY1nCLhGrOQHf3aeBx4BhwmtxslpNm9pSZPZJv9rvAr5nZa8DXgP/o7sXDMiKS13sixfLWJu7dsTbqUqSONAVp5O5HyX3ZWfjYkwX3TwEfC7c0kfo0NZPl+dPD7Nu1jtamxqjLkTqiwTuRKnvl3CUuj0/p2ucSOgW6SJX1JoZY0tzIT+zUTC8JlwJdpIpmss6xk8Pcf2cnS1o03CLhUqCLVNHrg5cZzUzw0B5du0XCp0AXqaI3UmMAfFjXbpEKUKCLVNHAcIYlzY1sXLUk6lKkDinQRaooOZJh+7p2XYxLKkKBLlJFyeExdnQui7oMqVMKdJEqyUxMc/HKdbq7lkdditQpBbpIlZxNZwDYrjN0qRAFukiVJPOB3t2lQJfKUKCLVMlAOkNzo3HbmqVRlyJ1SoEuUiXJdIZtHe26/rlUjI4skSpJpsfYsU7DLVI5CnSRKrg+NcPbl8bZsU4zXKRyFOgiVfDm6FWyjs7QpaIU6CJVcGOGi35UJJWkQBepgoF0hgaD2zvboy5F6pgCXaQKzqYzbF6zlLZmXQNdKkeBLlIFA+kxujV+LhWmQBepsOmZLG+OXmW7Al0qTIEuUmFvXRpnasbp1pRFqTAFukiF3ZzhojN0qTAFukiFKdClWhToIhWWTGfYsLKNZa1NUZcidU6BLlJhA7qGi1SJAl2kgrJZ52z6qgJdqkKBLlJB71y+xrWpGc1wkapQoItUUHJEX4hK9SjQRSooOZxfdk6BLlUQKNDNbL+ZnTGzpJk9MUubXzCzU2Z20sz+KtwyRWpTMp1hbXsLq9tboi5FFoE551GZWSPwNPAgMAgcN7Mj7n6qoE038BngY+7+npmtq1TBIrVEM1ykmoKcod8NJN39nLtPAs8AB4va/BrwtLu/B+Du6XDLFKk97k4ynVGgS9UECfSNwIWC7cH8Y4V2AjvN7Ntm9rKZ7S/1RGb2mJn1m1n/yMhIeRWL1IiRsQnevz6t8XOpmiCBbiUe86LtJqAbuA94FPg/ZrbqA3/kftjde9y9p7Ozc761itSUf//Jv6YsSnUECfRBYHPB9ibgYok2/+juU+7+JnCGXMCLLFoD+UDv7tIZulRHkEA/DnSb2TYzawEOAUeK2vwDcD+AmXWQG4I5F2ahIrUmmc6wvLWJdctboy5FFok5A93dp4HHgWPAaeBZdz9pZk+Z2SP5ZseAd83sFPAi8N/c/d1KFS1SCwbSY+zoWoZZqVFLkfAFuvybux8FjhY99mTBfQd+J38TESCZvsr9d+i7Iqke/VJUpAIuj08ympnQ+LlUlQJdpAK0qIVEQYEuUgE3Al1XWZRqUqCLVMBAOkNbcwMbVy2JuhRZRBToIhWQTGfY3rmMhgbNcJHqUaCLVICu4SJRUKCLhOzqxDTvXL6ma7hI1SnQRUJ2VqsUSUQU6CIh00W5JCoKdJGQDaQzNDUYt61dGnUpssgo0EVClkxn2NbRTnOjPl5SXTriREKmGS4SFQW6SIgmpmd4692rmuEikVCgi4TozdGrZB22K9AlAgp0kRDpGi4SJQW6SIgGhjOYwe2d7VGXIouQAl0kRMmRDJtXL6WtuTHqUmQRUqCLhCg5nNEXohIZBbpISKZnsrw5elVTFiUyCnSRkLx9aZzJmawCXSKjQBcJiZadk6gp0EVCMqBAl4gp0EVCcjadYf2KNpa3NUddiixSCnSRkAykM3R36excoqNAFwlBNuucHcmtIyoSFQW6SAguXrnG+OSMztAlUgp0kRDcnOGiM3SJkAJdJAQ3L8rVpYtySXQU6CIhSKYzrGlvYU17S9SlyCKmQBcJwYBWKZIYUKCLLJC7a9k5iYVAgW5m+83sjJklzeyJW7T7OTNzM+sJr0SReBvJTHDl2pSusiiRmzPQzawReBo4AOwGHjWz3SXaLQf+M/BK2EWKxJmu4SJxEeQM/W4g6e7n3H0SeAY4WKLd54HfB66HWJ9I7GnZOYmLIIG+EbhQsD2Yf+wmM7sL2Ozu37jVE5nZY2bWb2b9IyMj8y5WJI6S6QzLWpvoWtEadSmyyAUJdCvxmN/cadYA/CHwu3M9kbsfdvced+/p7OwMXqVIjA0M574QNSv1URGpniCBPghsLtjeBFws2F4O7AVeMrPzwD3AEX0xKotFckQzXCQeggT6caDbzLaZWQtwCDhyY6e7X3H3Dnff6u5bgZeBR9y9vyIVi8TIlfEpRsYmNMNFYmHOQHf3aeBx4BhwGnjW3U+a2VNm9kilCxSJs+TIGKAZLhIPTUEauftR4GjRY0/O0va+hZclUhsGhjXDReJDvxQVWYBkOkNrUwMbVy+JuhQRBbrIQiTzi1o0NmiGi0RPgS6yADemLIrEgQJdpEzjk9O8c/maZrhIbCjQRcp0Nn0V0AwXiQ8FukiZbkxZ1DqiEhcKdJEyDQxnaGowblvbHnUpIoACXaRsyXSGrR3tNDfqYyTxoCNRpEzJdIYdnRpukfhQoIuUYWJ6hrcujWv8XGJFgS5ShvOj48xkXTNcJFYU6CJl0LJzEkcKdJEyDKTHMIPtGkOXGFGgi5Qhmc6wefVS2poboy5F5CYFukgZkmldw0XiR4EuMk/TM1nOjV5VoEvsKNBF5unCe9eYnM4q0CV2FOgi86QZLhJXCnSReRpIax1RiScFusg8JdMZula0sqKtOepSRH6IAl1knpLpjBaFllhSoIvMg7tryqLElgJdZB4uXrnO+OSMAl1iSYEuMg8nBq8AsLNLQy4SPwp0kXl47mSKlUuauWvLqqhLEfkABbpIQJPTWZ4/PcwDu7q0SpHEko5KkYD+39lRxq5Pc2Dv+qhLESlJgS4SUF8iRXtLIx/v7oi6FJGSFOgiAUzPZHnu1DCf3NWlS+ZKbCnQRQL4t/OXuHR1UsMtEmuBAt3M9pvZGTNLmtkTJfb/jpmdMrPXzeyfzey28EsViU5fIkVbcwP33dEZdSkis5oz0M2sEXgaOADsBh41s91Fzb4P9Lj7h4C/AX4/7EJFopLNOn2JFD+xs5OlLU1RlyMyqyBn6HcDSXc/5+6TwDPAwcIG7v6iu4/nN18GNoVbpkh0vn/hPdJjExzYuyHqUkRuKUigbwQuFGwP5h+bzaeB3lI7zOwxM+s3s/6RkZHgVYpEqPdEiuZG45O71kVdisgtBQl0K/GYl2xo9otAD/DFUvvd/bC797h7T2enxiIl/tyd3kSKj+/o0OVyJfaCBPogsLlgexNwsbiRmT0AfBZ4xN0nwilPJFqJd97nncvXNNwiNSFIoB8Hus1sm5m1AIeAI4UNzOwu4E/JhXk6/DJFotGbGKKxwXhwd1fUpYjMac5Ad/dp4HHgGHAaeNbdT5rZU2b2SL7ZF4FlwF+b2atmdmSWpxOpGe652S333L6G1e0tUZcjMqdAc7Dc/ShwtOixJwvuPxByXSKRG0hnODd6lV/5+LaoSxEJRL8UFZlF74kUZvDQHg23SG1QoIvMojcxRM9tq1m3vC3qUkQCUaCLlHB+9CpvpMbYr9ktUkMU6CIl9CZSAOzXxbikhijQRUroSwzxY5tWsnHVkqhLEQlMgS5S5J3L13ht8IqGW6TmKNBFivTlh1t07XOpNQp0kSJ9iSHuXL+crR3tUZciMi8KdJEC6bHr9L/1nq7dIjVJgS5S4NjJYdzhwI9quEVqjwJdpEBfYojbO9vpXrcs6lJE5k2BLpL33tVJXj53iQN712NWahkAkXhToIvkPX9qmJmss3+Pxs+lNinQRfJ6E0NsWr2EvRtXRF2KSFkU6CLA+9en+FZylP17NNwitUuBLgK8cDrN1IxrdovUNAW6CLnhlq4Vrdy1eXXUpYiUTYEui9745DTf/MEID+1ZT0ODhlukdinQZdF76cwI16eyulSu1DwFuix6vYkUa9pbuHvrmqhLEVkQBbosatenZnjh9DCf2t1FU6M+DlLbdATLovatgVGuTs5ouEXqggJdFrXeRIrlbU3cu70j6lJEFkyBLovW1EyWfzo9zIO7umhp0kdBap+OYlm0vnP2Xa5cm9Jwi9QNBbosWr2JFEtbGvnEzs6oSxEJhQJdFqWZrPP8qRT337mOtubGqMsRCYUCXRal4+cvMZqZ1ELQUlcU6LIo9SVStDY1cP8d66IuRSQ0CnRZdLJZpy+R4hM7O2lvbYq6HJHQKNBl0Xl18DKp969ruEXqTqBAN7P9ZnbGzJJm9kSJ/a1m9vX8/lfMbGvYhYqEpS+RornR2LerK+pSREI1Z6CbWSPwNHAA2A08ama7i5p9GnjP3XcAfwh8IexCRcLg7vQmhrh3ewcrlzRHXY5IqIIMIN4NJN39HICZPQMcBE4VtDkIfC5//2+A/21m5u4eYq0APHv8An/2r+fCflpZJGbcuXDpGr91346oSxEJXZBA3whcKNgeBD46Wxt3nzazK8BaYLSwkZk9BjwGsGXLlrIKXrW0me6uZWX9rQjAR7as5ic/tCHqMkRCFyTQSy3hUnzmHaQN7n4YOAzQ09NT1tn7p/as51N79GWWiEixIF+KDgKbC7Y3ARdna2NmTcBK4FIYBYqISDBBAv040G1m28ysBTgEHClqcwT45fz9nwNeqMT4uYiIzG7OIZf8mPjjwDGgEfiyu580s6eAfnc/Avw58FUzS5I7Mz9UyaJFROSDAv1Mzt2PAkeLHnuy4P514OfDLU1EROZDvxQVEakTCnQRkTqhQBcRqRMKdBGROmFRzS40sxHgrTL/vIOiX6HGjOpbGNW3cHGvUfWV7zZ3L7luYmSBvhBm1u/uPVHXMRvVtzCqb+HiXqPqqwwNuYiI1AkFuohInajVQD8cdQFzUH0Lo/oWLu41qr4KqMkxdBER+aBaPUMXEZEiCnQRkToR20A3s583s5NmljWznqJ9n8kvSH3GzB6a5e+35ResHsgvYN1SwVq/bmav5m/nzezVWdqdN7MT+Xb9laqnxOt+zszeKajx4Vna3XIx8ArW90Uze8PMXjezvzezVbO0q2r/xXlxdDPbbGYvmtnp/Ofkv5Roc5+ZXSl4358s9VwVrPGW75fl/FG+/143sw9XsbY7CvrlVTN738x+u6hNpP1XFneP5Q3YBdwBvAT0FDy+G3gNaAW2AWeBxhJ//yxwKH//S8BvVKnuPwCenGXfeaAjgr78HPBf52jTmO/L24GWfB/vrlJ9nwKa8ve/AHwh6v4L0h/AbwJfyt8/BHy9iu/pBuDD+fvLgR+UqO8+4BvVPt6Cvl/Aw0AvuRXP7gFeiajORiBF7gc7sem/cm6xPUN399PufqbEroPAM+4+4e5vAklyC1nfZGYGfJLcgtUA/xf46UrWW/C6vwB8rdKvVQE3FwN390ngxmLgFefuz7n7dH7zZXKrYkUtSH8cJHdsQe5Y25c/BirO3Yfc/Xv5+2PAaXJr+9aSg8BfeM7LwCozi2Kx133AWXcv95frsRHbQL+FUotWFx/Ia4HLBSFRqk0l/Dgw7O4Ds+x34Dkz+25+wexqejz/z9ovm9nqEvuD9Gs1/Cq5s7ZSqtl/QfrjhxZHB24sjl5V+aGeu4BXSuz+D2b2mpn1mtmeqhY29/sVl2PuELOfhEXZf/MWaIGLSjGzfwJKrfj8WXf/x9n+rMRjZS1aPR8Ba32UW5+df8zdL5rZOuB5M3vD3f9lIXUFqQ/4E+Dz5Prg8+SGhX61+ClK/G1oc1qD9J+ZfRaYBv5ylqepWP+VEMlxNl9mtgz4W+C33f39ot3fIzeMkMl/b/IPQHcVy5vr/YpD/7UAjwCfKbE76v6bt0gD3d0fKOPPgixaPUrun29N+TOnUm3mZa5aLbc49s8CH7nFc1zM/zdtZn9P7p/1oQRS0L40sz8DvlFiV5B+LVuA/vtl4KeAfZ4fwCzxHBXrvxLmszj6oEWwOLqZNZML8790978r3l8Y8O5+1Mz+2Mw63L0qF50K8H5V9JgL6ADwPXcfLt4Rdf+VoxaHXI4Ah/IzDLaR+z/mvxU2yAfCi+QWrIbcAtaznfGH5QHgDXcfLLXTzNrNbPmN++S+CExUuKYbr104Lvkzs7xukMXAK1XffuC/A4+4+/gsbardf7FeHD0/Vv/nwGl3/1+ztFl/Y0zfzO4m93l/t0r1BXm/jgC/lJ/tcg9wxd2HqlFfgVn/VR1l/5Ut6m9lZ7uRC55BYAIYBo4V7PssuRkIZ4ADBY8fBX4kf/92ckGfBP4aaK1wvV8Bfr3osR8BjhbU81r+dpLcUEO1+vKrwAngdXIfog3F9eW3HyY3W+JsletLkhtLfTV/+1JxfVH0X6n+AJ4i9z8egLb8sZXMH2u3V7HPPk5ueOL1gn57GPj1G8ch8Hi+r14j92XzvVWsr+T7VVSfAU/n+/cEBbPZqlTjUnIBvbLgsVj0X7k3/fRfRKRO1OKQi4iIlKBAFxGpEwp0EZE6oUAXEakTCnQRkTqhQBcRqRMKdBGROvH/ASTHc4exbhusAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(numrange, binomial.cdf(numrange))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([19.,  0.,  0.,  0.,  0., 61.,  0.,  0.,  0., 20.]),\n",
       " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = binomial.rvs(size = 100)\n",
    "plt.hist(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  4.,  6., 13., 16., 30., 11.,  8.,  8.,  3.]),\n",
       " array([ 4. ,  5.2,  6.4,  7.6,  8.8, 10. , 11.2, 12.4, 13.6, 14.8, 16. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "p = 0.5\n",
    "n = 20\n",
    "binomial = scipy.stats.binom(n,p)\n",
    "X = binomial.rvs(size = 100)\n",
    "plt.hist(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x7ff308990d10>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = range(20)\n",
    "plt.plot(x, binomial.pmf(numrange), 'o')\n",
    "\n",
    "plt.vlines(x, 0, binomial.pmf(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(0, 20)\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continous Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continous Uniform Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.31008546 0.70106834 0.36158006 0.25169615 0.59709027 0.24228774\n",
      " 0.7438743  0.9009814  0.63352796 0.87728186]\n",
      "0.3100854599548255\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import uniform\n",
    "\n",
    "cuni = uniform()\n",
    "test = cuni.rvs(size=10)\n",
    "print(test)\n",
    "print(test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = cuni.rvs(size = 10000)\n",
    "plt.hist(X, bins = 1000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = cuni.rvs(size = 10)\n",
    "plt.hist(X, bins = 10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff339256610>]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numrange = np.linspace(-0.1, 1.1, 100)\n",
    "plt.plot(numrange, cuni.pdf(numrange), 'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff31a1e8110>]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(numrange, cuni.cdf(numrange))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff2f870c290>]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cuni = uniform(0, 10)\n",
    "numrange = np.linspace(-1, 11, 100)\n",
    "plt.plot(numrange, cuni.pdf(numrange)) # one can also input 'o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff338a2c990>]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD4CAYAAADlwTGnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAZiUlEQVR4nO3df4xV533n8ffHMwanbowbPGldfmToQqtiZ5tNpiRSfqiJ1y5eNR1HhWbcbMNKrEgbs2oVZVVcyayLEmnp/vCqMs0uWdwlaL1g0XozVUlJK5J2U2UJQ42LsUV3QvEyxorHC6HGKcb33u/+cZ7BN9f33vMMM2SYcz8vaTTnPuc5Z87RgfO5z3meex9FBGZm1ntumOsDMDOzueEAMDPrUQ4AM7Me5QAwM+tRDgAzsx7VP9cHMB233XZbDA4OzvVhmJnNK0ePHn05IgZay+dVAAwODjI2NjbXh2FmNq9Ier5duR8BmZn1KAeAmVmPcgCYmfUoB4CZWY9yAJiZ9aisAJC0VtJJSeOStrRZv1DSvrT+sKTBlvXLJV2U9NncfZqZ2bVVGgCS+oAdwL3AauB+Satbqm0EzkfESuARYHvL+keAr0xzn2Zmdg3lfA5gDTAeEacAJO0FhoFnm+oMAw+n5f3Ao5IUESHpPuAU8Oo092kz8PeXXmfPN5/ntdfrc30oZjYL/tVdq7ixb3af2ucEwBLgTNPrCeC9nepERE3SBWCxpH8Afgu4G/hsu/pd9gmApE3AJoDly5dnHK4B/MXJSf7dwZMASHN8MGY2Y5/+8Epu7JvdfeYEQLvbR+ssMp3q/A7wSERc1PffhXL2WRRG7AR2AgwNDXn2mkyXaw0A/vJff5jli39ojo/GzK5HOQEwASxrer0UONuhzoSkfmARcI7iXf06Sb8L3Ao0JF0Cjmbs02ag3iiy8gaP8zKzDnIC4AiwStIK4AVgBPiVljqjwAbgm8A64FAUc01+cKqCpIeBixHxaAqJsn3aDNRSAPQ7Acysg9IASM/0NwMHgT7gsYg4IWkbMBYRo8AuYI+kcYp3/iNXs88Znos1qTeKR0B9N7gDwMzay/o20Ig4ABxoKdvatHwJWF+yj4fL9mmzp36lBeAAMLP2/HygoqYeAfX1OQDMrD0HQEW5BWBmZRwAFXWlBeAAMLMOHAAVVfcoIDMr4btDRU21ANwAMLNOHAAVVW806L9ByN8DYWYdOAAqqtYIP/83s64cABVVr4dHAJlZVw6AinILwMzKOAAqqt4I+mf5u8PNrFp8h6gotwDMrIwDoKKmRgGZmXXiAKgotwDMrIwDoKLqDY8CMrPuHAAV5RaAmZVxAFRU8TkAX14z6yzrDiFpraSTksYlbWmzfqGkfWn9YUmDqXyNpGPp52lJH2va5rSk42nd2GydkBXcAjCzMqUzgknqA3YAd1NM/n5E0mhEPNtUbSNwPiJWShoBtgMfB54BhtIUkLcDT0v644iope0+HBEvz+YJWaHeaNDvyWDMrIucFsAaYDwiTkXEZWAvMNxSZxjYnZb3A3dJUkR8r+lmfxMQs3HQVs4tADMrkxMAS4AzTa8nUlnbOumGfwFYDCDpvZJOAMeBX2sKhAC+KumopE2d/rikTZLGJI1NTk7mnJPhUUBmVi4nANrdRVrfyXesExGHI+IO4GeBByXdlNa/PyLeDdwLPCDpQ+3+eETsjIihiBgaGBjIOFwDtwDMrFxOAEwAy5peLwXOdqojqR9YBJxrrhARzwGvAnem12fT75eAJykeNdksKVoAHgVkZp3l3CGOAKskrZC0ABgBRlvqjAIb0vI64FBERNqmH0DSO4CfAk5LulnSW1P5zcA9FB3GNkvcAjCzMqWjgNIIns3AQaAPeCwiTkjaBoxFxCiwC9gjaZzinf9I2vwDwBZJrwMN4NMR8bKknwCeTLNV9QOPR8SfzvbJ9TJ/F5CZlSkNAICIOAAcaCnb2rR8CVjfZrs9wJ425aeAn5nuwVq+Wt0tADPrzg+JK6qYD8ABYGadOQAqqt4I+twJbGZd+A5RUTV/DsDMSjgAKqruUUBmVsIBUFE1jwIysxIOgIpyC8DMyjgAKsp9AGZWxgFQUfW6RwGZWXe+Q1RUzZ8DMLMSDoCKch+AmZVxAFSURwGZWRkHQAU1GkEjcAvAzLpyAFRQPYr5etwCMLNuHAAVVG8UAeBRQGbWje8QFVRruAVgZuUcABVUr0+1ABwAZtZZVgBIWivppKRxSVvarF8oaV9af1jSYCpfI+lY+nla0sdy92lXr9ZoAPhzAGbWVWkASOoDdgD3AquB+yWtbqm2ETgfESuBR4DtqfwZYCgi3gWsBf6LpP7MfdpVeqMPwAFgZp3ltADWAOMRcSoiLgN7geGWOsPA7rS8H7hLkiLiexFRS+U3ATGNfdpVch+AmeXICYAlwJmm1xOprG2ddMO/ACwGkPReSSeA48CvpfU5+yRtv0nSmKSxycnJjMM1jwIysxw5d4h2byMjt05EHI6IO4CfBR6UdFPmPknb74yIoYgYGhgYyDhccwvAzHLkBMAEsKzp9VLgbKc6kvqBRcC55goR8RzwKnBn5j7tKtVTJ7D7AMysm5wAOAKskrRC0gJgBBhtqTMKbEjL64BDERFpm34ASe8Afgo4nblPu0puAZhZjv6yChFRk7QZOAj0AY9FxAlJ24CxiBgFdgF7JI1TvPMfSZt/ANgi6XWgAXw6Il4GaLfPWT63nlXz5wDMLENpAABExAHgQEvZ1qblS8D6NtvtAfbk7tNmh4eBmlkODxOpoJoDwMwyOAAqqHHl20B9ec2sM98hKsh9AGaWwwFQQVN9AP4uIDPrxgFQQTV/DsDMMjgAKqjuzwGYWQYHQAV5FJCZ5XAAVNAbLQBfXjPrzHeICnILwMxyOAAqaOrL4NwHYGbdOAAqyJ8DMLMcDoAK8ucAzCyHA6CC3AdgZjkcABXkUUBmlsN3iApyC8DMcmQFgKS1kk5KGpe0pc36hZL2pfWHJQ2m8rslHZV0PP3+SNM2X0/7PJZ+3j5bJ9XrPArIzHKUTggjqQ/YAdxNMZfvEUmjEfFsU7WNwPmIWClpBNgOfBx4GfhoRJyVdCfFDGBLmrb7RESMzdK5WOIWgJnlyGkBrAHGI+JURFwG9gLDLXWGgd1peT9wlyRFxFMRMTXZ+wngJkkLZ+PArbN63d8FZGblcgJgCXCm6fUE3/8u/vvqREQNuAAsbqnzS8BTEfFaU9kfpMc/D0lqe7eStEnSmKSxycnJjMM1twDMLEdOALS7i8R06ki6g+Kx0Kea1n8iIt4JfDD9/Gq7Px4ROyNiKCKGBgYGMg7X6o2g7wbRIVPNzIC8AJgAljW9Xgqc7VRHUj+wCDiXXi8FngQ+GRHfntogIl5Iv18BHqd41GSzoJYCwMysm5wAOAKskrRC0gJgBBhtqTMKbEjL64BDERGSbgX+BHgwIv5qqrKkfkm3peUbgV8AnpnZqdiUeqPh5/9mVqo0ANIz/c0UI3ieA56IiBOStkn6xVRtF7BY0jjwGWBqqOhmYCXwUMtwz4XAQUl/AxwDXgC+OJsn1svcAjCzHKXDQAEi4gBwoKVsa9PyJWB9m+0+B3yuw27fk3+YNh31RrgFYGal/EngCipaAL60Ztad7xIVVK+7BWBm5RwAFeQ+ADPL4QCooHqj4bkAzKyUA6CC3AIwsxwOgAryKCAzy+EAqCCPAjKzHL5LVJBbAGaWwwFQQe4DMLMcDoAK8ncBmVkOB0AF1epuAZhZOQdABdUb4c8BmFkpB0AFeRSQmeXwXaKCPArIzHI4ACrIo4DMLIcDoII8CsjMcmQFgKS1kk5KGpe0pc36hZL2pfWHJQ2m8rslHZV0PP3+SNM270nl45J+T57BfNa4BWBmOUoDQFIfsAO4F1gN3C9pdUu1jcD5iFgJPAJsT+UvAx+NiHdSzBm8p2mbLwCbgFXpZ+0MzsOauA/AzHLktADWAOMRcSoiLgN7geGWOsPA7rS8H7hLkiLiqYg4m8pPADel1sLtwC0R8c2ICOBLwH0zPhsDpj4H4Kd7ZtZdzl1iCXCm6fVEKmtbJ00ifwFY3FLnl4CnIuK1VH+iZJ8ASNokaUzS2OTkZMbhmlsAZpYjJwDa3UliOnUk3UHxWOhT09hnURixMyKGImJoYGAg43Ct1gj6/EEwMyuREwATwLKm10uBs53qSOoHFgHn0uulwJPAJyPi2031l5bs066SRwGZWY6cADgCrJK0QtICYAQYbakzStHJC7AOOBQRIelW4E+AByPir6YqR8SLwCuS3pdG/3wS+PIMz8USjwIysxylAZCe6W8GDgLPAU9ExAlJ2yT9Yqq2C1gsaRz4DDA1VHQzsBJ4SNKx9PP2tO7Xgf8KjAPfBr4yWyfV69wHYGY5+nMqRcQB4EBL2dam5UvA+jbbfQ74XId9jgF3TudgLY+/C8jMcvguUUFuAZhZDgdAxUQEdfcBmFkGB0DF1BvFaFoHgJmVcQBUTM0BYGaZHAAVM9UCcB+AmZVxAFRMPdwCMLM8DoCKqdfdAjCzPA6AirnSB9DnS2tm3fkuUTHuAzCzXA6Aiqk1GoD7AMysnAOgYtwCMLNcDoCK8ecAzCyXA6Bi3mgB+NKaWXe+S1RMre4WgJnlcQBUjPsAzCyXA6BirowC8pzAZlYiKwAkrZV0UtK4pC1t1i+UtC+tPyxpMJUvlvQ1SRclPdqyzdfTPltnCrMZcAvAzHKVzggmqQ/YAdxNMZn7EUmjEfFsU7WNwPmIWClpBNgOfBy4BDxEMfNXu9m/PpFmBrNZ4lFAZpYrpwWwBhiPiFMRcRnYCwy31BkGdqfl/cBdkhQRr0bENyiCwH4APArIzHLl3CWWAGeaXk+ksrZ10iTyF4DFGfv+g/T45yFJbd+yStokaUzS2OTkZMYue5tbAGaWKycA2t1J4irqtPpERLwT+GD6+dV2lSJiZ0QMRcTQwMBA6cH2unrqBHYfgJmVyQmACWBZ0+ulwNlOdST1A4uAc912GhEvpN+vAI9TPGqyGfLnAMwsV04AHAFWSVohaQEwAoy21BkFNqTldcChiOjYApDUL+m2tHwj8AvAM9M9eHuzK30AHgZqZiVKRwFFRE3SZuAg0Ac8FhEnJG0DxiJiFNgF7JE0TvHOf2Rqe0mngVuABZLuA+4BngcOppt/H/DnwBdn9cx6VM3DQM0sU2kAAETEAeBAS9nWpuVLwPoO2w522O178g7RpqN+pRPYo4DMrDvfJSrGLQAzy+UAqJi6J4Qxs0wOgIpxC8DMcjkAKqbuD4KZWSYHQMVMfQ7AXwVhZmV8l6iYKy0Afw7AzEo4ACrGfQBmlssBUDEeBWRmuRwAFXPl20Dbf7mqmdkVDoCKqTeCGwQ3uAVgZiUcABVTa4RHAJlZFt8pKqbeCD//N7MsDoCKqdXDI4DMLIsDoGLqjYY/A2BmWRwAFVP0ATgAzKxcVgBIWivppKRxSVvarF8oaV9af1jSYCpfLOlrki5KerRlm/dIOp62+b1Ok8Lb9LgPwMxylQaApD5gB3AvsBq4X9LqlmobgfMRsRJ4BNieyi8BDwGfbbPrLwCbgFXpZ+3VnIB9P48CMrNcOXeKNcB4RJyKiMvAXmC4pc4wsDst7wfukqSIeDUivkERBFdIuh24JSK+meYO/hJw30xOxApuAZhZrpwAWAKcaXo9kcra1omIGnABWFyyz4mSfQIgaZOkMUljk5OTGYfb29wHYGa5cgKg3d0krqLOVdWPiJ0RMRQRQwMDA112aZBGATkAzCxDTgBMAMuaXi8FznaqI6kfWAScK9nn0pJ92lWo1f0IyMzy5ATAEWCVpBWSFgAjwGhLnVFgQ1peBxxKz/bbiogXgVckvS+N/vkk8OVpH729Sb0R9PtzAGaWob+sQkTUJG0GDgJ9wGMRcULSNmAsIkaBXcAeSeMU7/xHpraXdBq4BVgg6T7gnoh4Fvh14L8BbwG+kn5shmqNoM+jgMwsQ2kAAETEAeBAS9nWpuVLwPoO2w52KB8D7sw9UMtTdyewmWXyW8WKqbkT2MwyOQAqxi0AM8vlAKiYmj8IZmaZHAAV4xaAmeVyAFRM8TkAX1YzK+c7RcW4BWBmuRwAFeNRQGaWywFQMf42UDPL5QComHr4EZCZ5XEAVEzdXwZnZpkcABVT85fBmVkmB0DFuA/AzHI5ACrGcwKbWS7fKSrGLQAzy+UAqJhao+FRQGaWxQFQMW4BmFmurACQtFbSSUnjkra0Wb9Q0r60/rCkwaZ1D6byk5J+vqn8tKTjko5JGpuNk7GpPgAHgJmVK50RTFIfsAO4m2Iy9yOSRtO0jlM2AucjYqWkEWA78HFJqymmh7wD+HHgzyX9ZETU03YfjoiXZ/F8elqjEUTgL4Mzsyw5d4o1wHhEnIqIy8BeYLilzjCwOy3vB+5Kk70PA3sj4rWI+DtgPO3ProFaIwD8OQAzy5ITAEuAM02vJ1JZ2zoRUQMuAItLtg3gq5KOStrU6Y9L2iRpTNLY5ORkxuH2rnoKAPcBmFmOnABodzeJzDrdtn1/RLwbuBd4QNKH2v3xiNgZEUMRMTQwMJBxuL2r1mgAuA/AzLLkBMAEsKzp9VLgbKc6kvqBRcC5bttGxNTvl4An8aOhGXMLwMymIycAjgCrJK2QtICiU3e0pc4osCEtrwMORUSk8pE0SmgFsAr4lqSbJb0VQNLNwD3AMzM/nd52pQ/AAWBmGUpHAUVETdJm4CDQBzwWESckbQPGImIU2AXskTRO8c5/JG17QtITwLNADXggIuqSfhR4sugnph94PCL+9BqcX095owXgUUBmVq40AAAi4gBwoKVsa9PyJWB9h20/D3y+pewU8DPTPVjrzi0AM5sOv1WskHrdfQBmls8BUCFXRgH5cwBmlsEBUCEeBWRm0+EAqBD3AZjZdDgAKsSjgMxsOnynqBC3AMxsOhwAFVJPncDuAzCzHA6ACqnV3QIws3wOgArxKCAzmw4HQIV4PgAzmw4HQIV4FJCZTYfvFBXiUUBmNh0OgArxKCAzmw4HQIW4BWBm0+EAqBCPAjKz6XAAVMgbnwPwZTWzcll3CklrJZ2UNC5pS5v1CyXtS+sPSxpsWvdgKj8p6edz92nTd6UF4GGgZpahNAAk9QE7gHuB1cD9kla3VNsInI+IlcAjwPa07WqK6SHvANYCvy+pL3OfNk3uAzCz6ciZEnINMJ6mcUTSXmCYYp7fKcPAw2l5P/Coigl/h4G9EfEa8HdpzuA1qV7ZPmfNv9x9hOf/3/euxa6vK9/9h9cBuEEOADMrlxMAS4AzTa8ngPd2qpMmkb8ALE7l/7tl2yVpuWyfAEjaBGwCWL58ecbhvtnyt93Mgv7eeC7+Y7e8hdt+eMFcH4aZzQM5AdDu7WRk1ulU3u5u3LrPojBiJ7ATYGhoqG2dMls/6qdLZmatct4WTwDLml4vBc52qiOpH1gEnOuybc4+zczsGsoJgCPAKkkrJC2g6NQdbakzCmxIy+uAQxERqXwkjRJaAawCvpW5TzMzu4ZKHwGlZ/qbgYNAH/BYRJyQtA0Yi4hRYBewJ3XynqO4oZPqPUHRuVsDHoiIOkC7fc7+6ZmZWScq3qjPD0NDQzE2NjbXh2FmNq9IOhoRQ63lvTE0xszM3sQBYGbWoxwAZmY9ygFgZtaj5lUnsKRJ4Plr/GduA16+xn/jWvM5XB98DtcHnwO8IyIGWgvnVQD8IEgaa9dbPp/4HK4PPofrg8+hMz8CMjPrUQ4AM7Me5QB4s51zfQCzwOdwffA5XB98Dh24D8DMrEe5BWBm1qMcAGZmPcoBkFRhknpJpyUdl3RM0rz51jxJj0l6SdIzTWVvk/Rnkv5P+v0jc3mMZTqcw8OSXkjX45ikfzaXx1hG0jJJX5P0nKQTkn4jlc+ba9HlHObNtZB0k6RvSXo6ncPvpPIVkg6n67AvfZX+zP6W+wCuTHz/t8DdFJPVHAHuj4hrMkfxtSLpNDAUEfPqQy+SPgRcBL4UEXemst8FzkXEv02B/CMR8VtzeZzddDiHh4GLEfHv5/LYckm6Hbg9Iv5a0luBo8B9wL9gnlyLLufwy8yTa5HmU785Ii5KuhH4BvAbwGeAP4qIvZL+M/B0RHxhJn/LLYDClYnvI+IyMDVJvf0ARMRfUswj0WwY2J2Wd1P8J75udTiHeSUiXoyIv07LrwDPUczhPW+uRZdzmDeicDG9vDH9BPARYH8qn5Xr4AAotJv4fl79o0kC+Kqko5I2zfXBzNCPRsSLUPynBt4+x8dztTZL+pv0iOi6fXTSStIg8E+Aw8zTa9FyDjCProWkPknHgJeAPwO+DXw3ImqpyqzcoxwAhZyJ7+eD90fEu4F7gQfSYwmbO18A/hHwLuBF4D/M7eHkkfTDwB8CvxkRfz/Xx3M12pzDvLoWEVGPiHdRzJe+BvjpdtVm+nccAIVKTFIfEWfT75eAJyn+4cxX30nPc6ee6740x8czbRHxnfQfuQF8kXlwPdIz5z8E/ntE/FEqnlfXot05zMdrARAR3wW+DrwPuFXS1DS+s3KPcgAU5v0k9ZJuTp1eSLoZuAd4pvtW17VRYENa3gB8eQ6P5apM3TSTj3GdX4/U+bgLeC4i/mPTqnlzLTqdw3y6FpIGJN2alt8C/FOKvoyvAetStVm5Dh4FlKRhYf+JNyap//wcH9K0SPoJinf9AP3A4/PlHCT9D+DnKL7y9jvAvwH+J/AEsBz4v8D6iLhuO1k7nMPPUTxyCOA08KmpZ+nXI0kfAP4XcBxopOLfpniGPi+uRZdzuJ95ci0k/WOKTt4+ijfpT0TEtvR/fC/wNuAp4J9HxGsz+lsOADOz3uRHQGZmPcoBYGbWoxwAZmY9ygFgZtajHABmZj3KAWBm1qMcAGZmPer/A5VKrRZfQdQWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cuni = uniform(5, 25)  # want a number from 5 to 25 \n",
    "numrange = np.linspace(-1, 30, 100)\n",
    "plt.plot(numrange, cuni.pdf(numrange))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nominal Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = norm(0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff328699950>]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "numrange = np.linspace(-5, 5, 100)     #norm(0,1) # mean is 0 and 1 is the standard deviation\n",
    "plt.plot(numrange, normal.pdf(numrange))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff2f8726290>]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(numrange, normal.cdf(numrange))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = normal.rvs(size = 10000)\n",
    "plt.hist(X, bins = 100)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
